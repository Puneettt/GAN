{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed49d09-d4dc-4281-abc2-b4e2ee694984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from builtins import max as max_n\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext , HiveContext\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext, HiveContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6dfb64-3f3e-4c78-b4de-931d231700ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e8ce7f-d6c0-4fef-8efa-c645e2cf9f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 10:16:41.772673: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-14 10:16:41.804497: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-14 10:16:41.804552: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-14 10:16:41.804580: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-14 10:16:41.810024: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-14 10:16:41.810686: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-14 10:16:54.119274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026683b3-3e4a-43df-960a-8c3bab7dc4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config.load('we-offshore')\n",
    "conf = SparkConf().set(\"spark.hadoop.fs.s3a.endpoint\",'https://s3api-core.uhc.com')\\\n",
    "            .set(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    "            .set(\"spark.hadoop.fs.s3a.access.key\",'pQffiGbavztAv6oHYubm')\\\n",
    "            .set(\"spark.hadoop.fs.s3a.secret.key\", 'Mb8uUAIn58YWsalinBwDrkShBjNbv0zXiwa9jFR6')\\\n",
    "            .set(\"com.amazonaws.services.s3a.enableV4\", \"true\")\\\n",
    "            .set(\"spark.hadoop.fs.s3a.path.style.access\",\"true\")\\\n",
    "            .set(\"spark.hadoop.s3a.connection.ssl.enabled\",\"false\")\\\n",
    "            .set(\"fs.s3a.connection.ssl.enabled\",\"true\")\\\n",
    "            .set(\"spark.sql.shuffle.partitions\", \"1000\")\\\n",
    "            .set(\"spark.driver.memory\", \"64g\")\\\n",
    "            .set(\"spark.executor.memory\", \"8g\")\\\n",
    "            .set(\"spark.executor.cores\", \"4\") \\\n",
    "            .set(\"spark.executor.instances\", \"4\") \\\n",
    "            .set(\"spark.kubernetes.executor.limit.cores\", \"4\")\\\n",
    "            .set(\"spark.kubernetes.executor.request.cores\", \"2500m\")\\\n",
    "            .set(\"spark.driver.maxResultSize\",\"64g\")\\\n",
    "            .set(\"spark.executor.memoryOverhead\",\"4096\")\\\n",
    "            .set(\"spark.sql.broadcastTimeout\", \"36000\")\\\n",
    "            .set(\"spark.sql.crossJoin.enabled\" , \"true\")\\\n",
    "            .set(\"spark.sql.parquet.datetimeRebaseMode\", \"CORRECTED\")\\\n",
    "            .set(\"spark.sql.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\\\n",
    "            .set(\"spark.sql.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\\\n",
    "            .set(\"spark.sql.legacy.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\\\n",
    "            .set(\"spark.sql.legacy.parquet.datetimeRebaseModeInWrite\", \"CORRECTED\")\\\n",
    "            .set(\"spark.sql.legacy.parquet.int96RebaseModeInRead\", \"CORRECTED\")\\\n",
    "            .set(\"spark.sql.legacy.parquet.int96RebaseModeInWrite\", \"CORRECTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65789d98-59e0-4d82-8dd7-491e4232fd66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.connection.ssl.enabled\n",
      "Warning: Ignoring non-Spark config property: com.amazonaws.services.s3a.enableV4\n",
      "https://repo1.uhc.com/artifactory/repo added as a remote repository with the name: repo-1\n",
      "https://repo1.uhc.com/artifactory/UHG-Snapshots added as a remote repository with the name: repo-2\n",
      "https://repo1.uhc.com/artifactory/UHG-Releases added as a remote repository with the name: repo-3\n",
      "2023-11-14 10:17:19,616 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Starting spark session\n",
    "\n",
    "spark = SparkSession.builder.appName(\"mp-GAN\").config(conf = conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4bcf11-b08d-410c-a80a-6ce5273621a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log4j = spark._jvm.org.apache.log4j\n",
    "log4j.LogManager.getRootLogger().setLevel(log4j.Level.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e43120-fd63-49a7-a435-d39c4728f251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jlab-cgm-uh-p192-6e18-0.jlab-cgm-uh-p192-6e18-svc.dsw-rnd-we.svc.cluster.local:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>k8s://https://kubernetes.default.svc.cluster.local:443</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>mp-GAN</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff75e6f0040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "127edb0a-600b-4d1b-8149-9a64f7b060be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spark.stop()\n",
    "# spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfc2791-90a9-494e-a99e-1521d92bc6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_loc = \"s3a://ss-bucket/GAN_v5/\"\n",
    "data_loc = base_loc + 'data/'\n",
    "data_loc_1 = base_loc + 'data-1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45d55f-ae6c-43ab-ae17-65de1694b8b7",
   "metadata": {},
   "source": [
    "# Calculating Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15893705-8ab5-478b-8537-fd10869a6595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_cf_metrics (target, pred):\n",
    "    tp = 0 # True Positive\n",
    "    tn = 0 # True Negative\n",
    "    fp = 0 # False Positive\n",
    "    fn = 0 # False Negative\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        if (target[i] == 1) and (pred[i] == 1):\n",
    "            tp += 1\n",
    "        if (target[i] == 1) and (pred[i] == 0):\n",
    "            fn += 1\n",
    "        if (target[i] == 0) and (pred[i] == 0):\n",
    "            tn += 1\n",
    "        if (target[i] == 0) and (pred[i] == 1):\n",
    "            fp += 1\n",
    "    \n",
    "    if (tp + fn + tn + fp) != 0:\n",
    "        accuracy = (tp + tn) / (tp + fn + tn + fp)\n",
    "    else:\n",
    "        accuracy = 'zero den'\n",
    "    \n",
    "    if (tp + fp) != 0:\n",
    "        precision_pos_class = tp / (tp + fp)\n",
    "    else:\n",
    "        precision_pos_class = 'zero den'\n",
    "    \n",
    "    if (fn + tn) != 0:\n",
    "        precision_neg_class = tn / (fn + tn)\n",
    "    else:\n",
    "        precision_neg_class = 'zero den'\n",
    "    \n",
    "    if (tp + fn) != 0:\n",
    "        recall_pos_class = tp / (tp + fn)\n",
    "    else:\n",
    "        recall_pos_class = 'zero den'\n",
    "        \n",
    "    if (tn + fp) != 0:\n",
    "        recall_neg_class = tn / (tn + fp)\n",
    "    else:\n",
    "        recall_neg_class = 'zero den'\n",
    "    \n",
    "    if (precision_pos_class != 'zero den') and (recall_pos_class != 'zero den') and ((precision_pos_class + recall_pos_class) != 0):\n",
    "        f1_score_pos_class = (2 * precision_pos_class * recall_pos_class) / (precision_pos_class + recall_pos_class)\n",
    "    else:\n",
    "        f1_score_pos_class = 'zero den'\n",
    "\n",
    "    if (precision_neg_class != 'zero den') and (recall_neg_class != 'zero den') and ((precision_neg_class + recall_neg_class) != 0):\n",
    "        f1_score_neg_class = (2 * precision_neg_class * recall_neg_class) / (precision_neg_class + recall_neg_class)\n",
    "    else:\n",
    "        f1_score_neg_class = 'zero den'\n",
    "        \n",
    "    if (len(target) == (tp + fn + tn + fp)):\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Precision (Positive Class): {precision_pos_class}')\n",
    "        print(f'Recall (Positive Class): {recall_pos_class}')\n",
    "        print(f'F1 score (Positive Class): {f1_score_pos_class}')\n",
    "        print(f'Precision (Negative class): {precision_neg_class}')\n",
    "        print(f'Recall (Negative class): {recall_neg_class}')\n",
    "        print(f'F1 score (Negative class): {f1_score_neg_class}')\n",
    "        \n",
    "        return [accuracy, \n",
    "                precision_pos_class, recall_pos_class, f1_score_pos_class, \n",
    "                precision_neg_class, recall_neg_class, f1_score_neg_class]\n",
    "    else:\n",
    "        print('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61e366-30f6-44c0-8225-1077a79517a0",
   "metadata": {},
   "source": [
    "### Train test load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a2ccb86-af65-4efc-8900-4b96fc97c088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_loc = data_loc + 'train_claims_data_2/' # Train data location\n",
    "test_loc = data_loc + 'test_claims_data_1/' # Test data location\n",
    "\n",
    "train_data = spark.read.parquet(train_loc + '*.parquet') # Train data\n",
    "test_data = spark.read.parquet(test_loc + '*.parquet') # Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ea095f-6ef2-46cb-bcc0-bbd8345429f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1041514, 50, 253398, 253398)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count(), \\\n",
    "len(train_data.columns), \\\n",
    "train_data.select('cli_clm_id').distinct().count(), \\\n",
    "train_data.select('ufe_claim_id').distinct().count() # (1041514, 50, 253398, 253398)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef82f46e-fd11-4348-a88e-b05b60d0dc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912480, 47, 173520, 173520)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.count(), \\\n",
    "len(test_data.columns), \\\n",
    "test_data.select('cli_clm_id').distinct().count(), \\\n",
    "test_data.select('ufe_claim_id').distinct().count() # (912480, 47, 173520, 173520)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bb65c-d03b-4bba-9281-324e2dfbb370",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfed7965-2db2-4c53-9d31-1d072086738a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ufe_claim_id',\n",
       " 'cli_clm_id',\n",
       " 'clm_ln_nbr',\n",
       " 'lob',\n",
       " 'lob_flag',\n",
       " 'aso_buyup',\n",
       " 'clm_pl_of_srvc_cd',\n",
       " 'load_dt',\n",
       " 'load_dt_date',\n",
       " 'load_dt_month',\n",
       " 'load_dt_year',\n",
       " 'bil_prov_npi',\n",
       " 'bil_prov_city',\n",
       " 'bil_prov_st',\n",
       " 'bil_prov_zip_cd',\n",
       " 'bil_prov_txnmy_cd',\n",
       " 'ptnt_city',\n",
       " 'ptnt_st',\n",
       " 'ptnt_zip_cd',\n",
       " 'ptnt_gdr',\n",
       " 'ptnt_dob',\n",
       " 'clm_tot_bil_amt',\n",
       " 'ln_bil_amt',\n",
       " 'sbmt_proc_cd',\n",
       " 'sbmt_proc_mod_1_cd',\n",
       " 'sbmt_proc_mod_2_cd',\n",
       " 'sbmt_proc_mod_3_cd',\n",
       " 'sbmt_proc_mod_4_cd',\n",
       " 'sbmt_unit_of_srvc_qty',\n",
       " 'diag_cd1',\n",
       " 'diag_cd2',\n",
       " 'diag_cd3',\n",
       " 'diag_cd4',\n",
       " 'diag_cd5',\n",
       " 'diag_cd6',\n",
       " 'diag_cd7',\n",
       " 'diag_cd8',\n",
       " 'diag_cd9',\n",
       " 'diag_cd10',\n",
       " 'diag_cd11',\n",
       " 'diag_cd12',\n",
       " 'diag_cd_1',\n",
       " 'diag_cd_2',\n",
       " 'diag_cd_3',\n",
       " 'diag_cd_4',\n",
       " 'map_fwae_disposition',\n",
       " 'ln_lvl_adjd_disposition',\n",
       " 'net_range',\n",
       " 'clm_ln_nbr_int',\n",
       " 'paid_flag']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the existing data variables, which I have in S3\n",
    "\n",
    "# If you want to add any new feature other than these existing variables, \n",
    "# then you will be required to make new train/test data, which cannot be done using this code.\n",
    "\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b853ab4-2415-453f-aff3-02d47cb17329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff5fe2fc-ddca-4ca7-a70e-4d1d1aeee8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041514"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To add any new feature, you can add any of the existing column in this list.\n",
    "# Note: It will be automatically fetched in test data features also.\n",
    "\n",
    "# In this version of the code, adding a categorical variable is easy and possible.\n",
    "# But if you want to add any numerical variable it will require some extra changes, which might be confusing to do.\n",
    "# If time permits, I will share another version with that functionality as well.\n",
    "# Although I have only one numerical variable saved in data and that is claim/line level billed amount.\n",
    "# So it might not be of much help.\n",
    "train_data_cols = ['sbmt_proc_cd', 'sbmt_proc_mod_1_cd', 'sbmt_proc_mod_2_cd', \n",
    "                   'diag_cd1',\n",
    "                   'bil_prov_txnmy_cd', 'ln_bil_amt', 'aso_buyup', 'clm_pl_of_srvc_cd']\n",
    "train_data_1 = train_data.select(train_data_cols)\n",
    "train_data_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f1191f7-ab98-44f2-9f09-f33a25c9fb26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ufe_claim_id',\n",
       " 'cli_clm_id',\n",
       " 'sbmt_proc_cd',\n",
       " 'sbmt_proc_mod_1_cd',\n",
       " 'sbmt_proc_mod_2_cd',\n",
       " 'diag_cd1',\n",
       " 'bil_prov_txnmy_cd',\n",
       " 'ln_bil_amt',\n",
       " 'aso_buyup',\n",
       " 'clm_pl_of_srvc_cd',\n",
       " 'map_fwae_disposition']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting same features from test\n",
    "test_data_cols = ['ufe_claim_id', 'cli_clm_id'] + train_data_cols + ['map_fwae_disposition']\n",
    "test_data_1 = test_data.select(test_data_cols)\n",
    "test_data_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15b89568-0a96-4d90-8130-41566cc781c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491756"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_2 = train_data_1.dropDuplicates(train_data_cols)\n",
    "train_data_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b091b-aad4-4bec-b337-424826e499bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78373414-2df3-4d72-9132-9e7842276bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_mode(data):\n",
    "    # Function to find mode for all the columns of input data\n",
    "    # If multiple values has same count ie. multiple modes, then first value will be fetched\n",
    "    # This will return a dictionary, where keys are column names and values are corresponding mode\n",
    "    mode = {}\n",
    "    for col in data.columns:\n",
    "        print(f'Calculating mode for: {col}')\n",
    "        col_mode = data.groupBy(col).count().sort('count', ascending=False).collect()[0][0]\n",
    "        if col_mode is None:\n",
    "            col_mode = data.groupBy(col).count().sort('count', ascending=False).collect()[1][0]\n",
    "            mode[col] = col_mode\n",
    "        else:\n",
    "            mode[col] = col_mode\n",
    "        \n",
    "    return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50ebc1c9-3c7e-4efe-89f0-a52eabc08ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbmt_proc_cd:0.0\n",
      "sbmt_proc_mod_1_cd:69.0124777328594\n",
      "sbmt_proc_mod_2_cd:95.16040475357698\n",
      "diag_cd1:0.0\n",
      "bil_prov_txnmy_cd:0.954945135392349\n",
      "ln_bil_amt:0.0\n",
      "aso_buyup:0.0\n",
      "clm_pl_of_srvc_cd:0.0\n"
     ]
    }
   ],
   "source": [
    "# Checking % NULL count\n",
    "tot_lines = train_data_2.count()\n",
    "for col in train_data_2.columns:\n",
    "    null_pct = ((train_data_2.filter(train_data_2[col].isNull()).count()) / tot_lines) * 100\n",
    "    print(f'{col}:{null_pct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7df30f86-e2aa-4cb7-8f8c-f0b272f7599a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufe_claim_id:0.0\n",
      "cli_clm_id:0.0\n",
      "sbmt_proc_cd:0.0\n",
      "sbmt_proc_mod_1_cd:70.0037261090654\n",
      "sbmt_proc_mod_2_cd:94.40327459231983\n",
      "diag_cd1:0.0\n",
      "bil_prov_txnmy_cd:0.4997369805365597\n",
      "ln_bil_amt:0.0\n",
      "aso_buyup:0.0\n",
      "clm_pl_of_srvc_cd:0.0\n",
      "map_fwae_disposition:0.0\n"
     ]
    }
   ],
   "source": [
    "# Checking % NULL count\n",
    "tot_lines = test_data_1.count()\n",
    "\n",
    "for col in test_data_1.columns:\n",
    "    null_pct = ((test_data_1.filter(test_data_1[col].isNull()).count()) / tot_lines) * 100\n",
    "    print(f'{col}:{null_pct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4f6aabc-2b07-4485-b123-742d1b19445d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_2 = train_data_2.na.fill(value='0')\n",
    "test_data_2 = test_data_1.na.fill(value='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "637da2fa-de53-4b5c-b0a8-32e061acb380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbmt_proc_cd:0.0\n",
      "sbmt_proc_mod_1_cd:0.0\n",
      "sbmt_proc_mod_2_cd:0.0\n",
      "diag_cd1:0.0\n",
      "bil_prov_txnmy_cd:0.0\n",
      "ln_bil_amt:0.0\n",
      "aso_buyup:0.0\n",
      "clm_pl_of_srvc_cd:0.0\n"
     ]
    }
   ],
   "source": [
    "# Checking % NULL count\n",
    "tot_lines = train_data_2.count()\n",
    "for col in train_data_2.columns:\n",
    "    null_pct = ((train_data_2.filter(train_data_2[col].isNull()).count()) / tot_lines) * 100\n",
    "    print(f'{col}:{null_pct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38130400-5ac0-4cba-bbaf-3d9da2a9185e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufe_claim_id:0.0\n",
      "cli_clm_id:0.0\n",
      "sbmt_proc_cd:0.0\n",
      "sbmt_proc_mod_1_cd:0.0\n",
      "sbmt_proc_mod_2_cd:0.0\n",
      "diag_cd1:0.0\n",
      "bil_prov_txnmy_cd:0.0\n",
      "ln_bil_amt:0.0\n",
      "aso_buyup:0.0\n",
      "clm_pl_of_srvc_cd:0.0\n",
      "map_fwae_disposition:0.0\n"
     ]
    }
   ],
   "source": [
    "# Checking % NULL count\n",
    "tot_lines = test_data_2.count()\n",
    "\n",
    "for col in test_data_2.columns:\n",
    "    null_pct = ((test_data_2.filter(test_data_2[col].isNull()).count()) / tot_lines) * 100\n",
    "    print(f'{col}:{null_pct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ab593-36a1-46d5-a587-801d4de63dc2",
   "metadata": {},
   "source": [
    "## Converting these datas to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90347686-15e9-47b8-ba6a-66aafb735e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data_3_pd = train_data_2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "693a89e4-5ed3-4f9e-8b16-43d7b2a4159d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491756, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 491756 entries, 0 to 491755\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   sbmt_proc_cd        491756 non-null  object\n",
      " 1   sbmt_proc_mod_1_cd  491756 non-null  object\n",
      " 2   sbmt_proc_mod_2_cd  491756 non-null  object\n",
      " 3   diag_cd1            491756 non-null  object\n",
      " 4   bil_prov_txnmy_cd   491756 non-null  object\n",
      " 5   ln_bil_amt          491756 non-null  object\n",
      " 6   aso_buyup           491756 non-null  int32 \n",
      " 7   clm_pl_of_srvc_cd   491756 non-null  object\n",
      "dtypes: int32(1), object(7)\n",
      "memory usage: 28.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(train_data_3_pd.shape) # (491756, 8)\n",
    "train_data_3_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "315fd0ad-fccf-4efd-9a8c-7eb9a61bc7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912480, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 912480 entries, 0 to 912479\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   ufe_claim_id          912480 non-null  int64 \n",
      " 1   cli_clm_id            912480 non-null  object\n",
      " 2   sbmt_proc_cd          912480 non-null  object\n",
      " 3   sbmt_proc_mod_1_cd    912480 non-null  object\n",
      " 4   sbmt_proc_mod_2_cd    912480 non-null  object\n",
      " 5   diag_cd1              912480 non-null  object\n",
      " 6   bil_prov_txnmy_cd     912480 non-null  object\n",
      " 7   ln_bil_amt            912480 non-null  object\n",
      " 8   aso_buyup             912480 non-null  int32 \n",
      " 9   clm_pl_of_srvc_cd     912480 non-null  object\n",
      " 10  map_fwae_disposition  912480 non-null  object\n",
      "dtypes: int32(1), int64(1), object(9)\n",
      "memory usage: 73.1+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data_2_pd = test_data_2.toPandas()\n",
    "print(test_data_2_pd.shape) # (912480, 11)\n",
    "test_data_2_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7fce3-84ab-4241-ad02-bb83e9203f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757b4ea-a906-40d7-b09b-c68d5ce72441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c19bc8-320f-413a-bcb7-acbbacfd77b0",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2714050f-05a0-46fe-a583-91eb7fa7ec9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_3_pd['ln_bil_amt'] = train_data_3_pd['ln_bil_amt'].astype(float)\n",
    "test_data_2_pd['ln_bil_amt'] = test_data_2_pd['ln_bil_amt'].astype(float)\n",
    "\n",
    "train_data_3_pd['aso_buyup'] = train_data_3_pd['aso_buyup'].astype(str)\n",
    "test_data_2_pd['aso_buyup'] = test_data_2_pd['aso_buyup'].astype(str)\n",
    "\n",
    "#train\n",
    "train_data_3_pd.loc[(train_data_3_pd.ln_bil_amt>=0) & (train_data_3_pd.ln_bil_amt<=100), 'bill_amount_category'] = '0-100'\n",
    "train_data_3_pd.loc[(train_data_3_pd.ln_bil_amt>100) & (train_data_3_pd.ln_bil_amt<=200), 'bill_amount_category'] = '101-200'\n",
    "train_data_3_pd.loc[(train_data_3_pd.ln_bil_amt>200) & (train_data_3_pd.ln_bil_amt<=500), 'bill_amount_category'] = '201-500'\n",
    "train_data_3_pd.loc[(train_data_3_pd.ln_bil_amt>500) & (train_data_3_pd.ln_bil_amt<=1000), 'bill_amount_category'] = '501-1000'\n",
    "train_data_3_pd.loc[(train_data_3_pd.ln_bil_amt>1000) & (train_data_3_pd.ln_bil_amt<=2000), 'bill_amount_category'] = '1001-2000'\n",
    "train_data_3_pd.loc[(train_data_3_pd.ln_bil_amt>2000) & (train_data_3_pd.ln_bil_amt<=5000), 'bill_amount_category'] = '2001-5000'\n",
    "train_data_3_pd.loc[(train_data_3_pd.ln_bil_amt>5000), 'bill_amount_category'] = '5000+'\n",
    "\n",
    "#test\n",
    "test_data_2_pd.loc[(test_data_2_pd.ln_bil_amt>=0) & (test_data_2_pd.ln_bil_amt<=100), 'bill_amount_category'] = '0-100'\n",
    "test_data_2_pd.loc[(test_data_2_pd.ln_bil_amt>100) & (test_data_2_pd.ln_bil_amt<=200), 'bill_amount_category'] = '101-200'\n",
    "test_data_2_pd.loc[(test_data_2_pd.ln_bil_amt>200) & (test_data_2_pd.ln_bil_amt<=500), 'bill_amount_category'] = '201-500'\n",
    "test_data_2_pd.loc[(test_data_2_pd.ln_bil_amt>500) & (test_data_2_pd.ln_bil_amt<=1000), 'bill_amount_category'] = '501-1000'\n",
    "test_data_2_pd.loc[(test_data_2_pd.ln_bil_amt>1000) & (test_data_2_pd.ln_bil_amt<=2000), 'bill_amount_category'] = '1001-2000'\n",
    "test_data_2_pd.loc[(test_data_2_pd.ln_bil_amt>2000) & (test_data_2_pd.ln_bil_amt<=5000), 'bill_amount_category'] = '2001-5000'\n",
    "test_data_2_pd.loc[(test_data_2_pd.ln_bil_amt>5000), 'bill_amount_category'] = '5000+'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03337e44-45bf-4019-9e91-dbf61a3b4e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d75cefd7-7c55-448a-9b83-a4f4c9929ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorical columns list\n",
    "# All categorical columns are being label encoded\n",
    "# If you are adding any new categorical feature, \n",
    "# then that feature needs to be added here also, so as to perform label encoding on that.\n",
    "catCols = ['sbmt_proc_cd', 'sbmt_proc_mod_1_cd', 'sbmt_proc_mod_2_cd', 'diag_cd1',\n",
    "            'bil_prov_txnmy_cd', 'bill_amount_category', 'aso_buyup', 'clm_pl_of_srvc_cd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "340927f4-525a-45a9-9fe3-6d21c95106d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# headers of label encoded columns (output of label encoder)\n",
    "catCols_enc = [x + '_label_enc' for x in catCols]\n",
    "train_data_3_pd = train_data_3_pd.reset_index(drop=True)\n",
    "test_data_2_pd = test_data_2_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c8e40-781d-433c-a72a-8502ca280dcd",
   "metadata": {},
   "source": [
    "##### Splitting test data into two parts\n",
    "Test data is being split into two parts. One part contains identifer columns which are not to be label encoded. Other part is features that need to label encode.\n",
    "<br>Part-1: identifiers columns ['ufe_claim_id', 'cli_clm_id', 'map_fwae_disposition']\n",
    "<br>Part-2: features columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07764fc8-9df7-437e-b3b2-98b5ace22a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>cli_clm_id</th>\n",
       "      <th>map_fwae_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923223431728500</td>\n",
       "      <td>923223431728500</td>\n",
       "      <td>Denied after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>923223431728500</td>\n",
       "      <td>923223431728500</td>\n",
       "      <td>Denied after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>923223431727700</td>\n",
       "      <td>923223431727700</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>923223431727700</td>\n",
       "      <td>923223431727700</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>924223430407800</td>\n",
       "      <td>924223430407800</td>\n",
       "      <td>Denied after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>924223430407800</td>\n",
       "      <td>924223430407800</td>\n",
       "      <td>Denied after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>924223430383100</td>\n",
       "      <td>924223430383100</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>924223430383100</td>\n",
       "      <td>924223430383100</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>923223431380400</td>\n",
       "      <td>923223431380400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>923223431380400</td>\n",
       "      <td>923223431380400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>923223431380400</td>\n",
       "      <td>923223431380400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>923223431380400</td>\n",
       "      <td>923223431380400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>923223431380400</td>\n",
       "      <td>923223431380400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>923223431380400</td>\n",
       "      <td>923223431380400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>923223431728700</td>\n",
       "      <td>923223431728700</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ufe_claim_id       cli_clm_id        map_fwae_disposition\n",
       "0   923223431728500  923223431728500  Denied after Investigation\n",
       "1   923223431728500  923223431728500  Denied after Investigation\n",
       "2   923223431727700  923223431727700    Paid after Investigation\n",
       "3   923223431727700  923223431727700    Paid after Investigation\n",
       "4   924223430407800  924223430407800  Denied after Investigation\n",
       "5   924223430407800  924223430407800  Denied after Investigation\n",
       "6   924223430383100  924223430383100    Paid after Investigation\n",
       "7   924223430383100  924223430383100    Paid after Investigation\n",
       "8   923223431380400  923223431380400    Paid after Investigation\n",
       "9   923223431380400  923223431380400    Paid after Investigation\n",
       "10  923223431380400  923223431380400    Paid after Investigation\n",
       "11  923223431380400  923223431380400    Paid after Investigation\n",
       "12  923223431380400  923223431380400    Paid after Investigation\n",
       "13  923223431380400  923223431380400    Paid after Investigation\n",
       "14  923223431728700  923223431728700    Paid after Investigation"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_2_pd_p1 = test_data_2_pd[['ufe_claim_id', 'cli_clm_id', 'map_fwae_disposition']]\n",
    "test_data_2_pd_p2 = test_data_2_pd[catCols]\n",
    "test_data_2_pd_p1.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77795a26-07f4-4b8c-9530-7060030cb0f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Combine Train/Test data\n",
    "Before label encoding, we need to combine train/test data, to avoid missing any labels while encoding,\n",
    "<br> After encoding we will separate them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c17ede1-1e35-4ca4-a4f0-af29dcc22e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1404236, 9)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.concat((train_data_3_pd, test_data_2_pd_p2), axis=0)\n",
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a672d19d-efa3-42c5-b1fc-638165f1c4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_count = train_data_3_pd.shape[0]\n",
    "test_data_count = test_data_2_pd_p2.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c59a0e58-3da3-4d51-98e0-c7eb324cbb79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1404236"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_3_pd.shape[0] + test_data_2_pd_p2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71be2b-ad2c-4aa9-96b5-80cc9a25381e",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1c8461b-4c1d-40f2-8b53-d2d8fd31014d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding: sbmt_proc_cd\n",
      "Encoding: sbmt_proc_mod_1_cd\n",
      "Encoding: sbmt_proc_mod_2_cd\n",
      "Encoding: diag_cd1\n",
      "Encoding: bil_prov_txnmy_cd\n",
      "Encoding: bill_amount_category\n",
      "Encoding: aso_buyup\n",
      "Encoding: clm_pl_of_srvc_cd\n"
     ]
    }
   ],
   "source": [
    "label_enc_dict = {} # Saving labels, just as a backup for double check. Not a necessary step to do.\n",
    "label_encoders = {} # Saving trained encoders\n",
    "\n",
    "for i in range(0, len(catCols)):\n",
    "    print(f'Encoding: {catCols[i]}')\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    combined_data[catCols[i] + '_label_enc'] = label_encoder.fit_transform(combined_data[catCols[i]])\n",
    "    \n",
    "    label_encoders[catCols[i]] = label_encoder\n",
    "    \n",
    "    temp_labels = combined_data[[catCols[i], catCols[i] + '_label_enc']].drop_duplicates()\n",
    "    temp = []\n",
    "    for a, b in zip(list(temp_labels[catCols[i]]), list(temp_labels[catCols[i] + '_label_enc'])):\n",
    "        temp.append([a, b])\n",
    "\n",
    "    label_enc_dict[catCols[i]] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239aabe-c14b-4a2c-bbfa-04dfed9373f1",
   "metadata": {},
   "source": [
    "## separate train - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5eaa1868-9a6d-4d3b-aa4d-8f5b97935d32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491756, 17)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_4_pd = combined_data.iloc[:train_data_count, :]\n",
    "train_data_4_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c73a526f-4ac8-40c2-afad-58a4956704ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912480, 17)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3_pd_p2 = combined_data.iloc[train_data_count:, :]\n",
    "test_data_3_pd_p2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1cff8c01-d386-4060-a382-c1aeae9f8ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912480, 20)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3_pd_p2 = test_data_3_pd_p2.reset_index(drop=True)\n",
    "test_data_2_pd_p1 = test_data_2_pd_p1.reset_index(drop=True)\n",
    "test_data_3_pd = pd.concat((test_data_2_pd_p1, test_data_3_pd_p2), axis=1)\n",
    "test_data_3_pd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097cf21-27df-48f6-abbe-52610046d75e",
   "metadata": {},
   "source": [
    "### Read - Write this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fda15e5-5b14-437f-9b05-2ecb680d43bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491756, 17)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_4_pd.shape # (491756, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "777a94bd-d630-4d3e-9360-d2dde6d10ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbmt_proc_cd</th>\n",
       "      <th>sbmt_proc_mod_1_cd</th>\n",
       "      <th>sbmt_proc_mod_2_cd</th>\n",
       "      <th>diag_cd1</th>\n",
       "      <th>bil_prov_txnmy_cd</th>\n",
       "      <th>ln_bil_amt</th>\n",
       "      <th>aso_buyup</th>\n",
       "      <th>clm_pl_of_srvc_cd</th>\n",
       "      <th>bill_amount_category</th>\n",
       "      <th>sbmt_proc_cd_label_enc</th>\n",
       "      <th>sbmt_proc_mod_1_cd_label_enc</th>\n",
       "      <th>sbmt_proc_mod_2_cd_label_enc</th>\n",
       "      <th>diag_cd1_label_enc</th>\n",
       "      <th>bil_prov_txnmy_cd_label_enc</th>\n",
       "      <th>bill_amount_category_label_enc</th>\n",
       "      <th>aso_buyup_label_enc</th>\n",
       "      <th>clm_pl_of_srvc_cd_label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D649</td>\n",
       "      <td>291U00000X</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>0-100</td>\n",
       "      <td>3462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1056</td>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0562</td>\n",
       "      <td>NU</td>\n",
       "      <td>KX</td>\n",
       "      <td>G4733</td>\n",
       "      <td>332B00000X</td>\n",
       "      <td>490.70</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>201-500</td>\n",
       "      <td>5338</td>\n",
       "      <td>162</td>\n",
       "      <td>117</td>\n",
       "      <td>1975</td>\n",
       "      <td>466</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G0145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z01419</td>\n",
       "      <td>291U00000X</td>\n",
       "      <td>109.57</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>101-200</td>\n",
       "      <td>5477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10559</td>\n",
       "      <td>446</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0601</td>\n",
       "      <td>RR</td>\n",
       "      <td>0</td>\n",
       "      <td>G4733</td>\n",
       "      <td>207RS0012X</td>\n",
       "      <td>329.28</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>201-500</td>\n",
       "      <td>5342</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>1975</td>\n",
       "      <td>173</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J3490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>E103553</td>\n",
       "      <td>207W00000X</td>\n",
       "      <td>250.00</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>201-500</td>\n",
       "      <td>5964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1230</td>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sbmt_proc_cd sbmt_proc_mod_1_cd sbmt_proc_mod_2_cd diag_cd1  \\\n",
       "0        83540                  0                  0     D649   \n",
       "1        E0562                 NU                 KX    G4733   \n",
       "2        G0145                  0                  0   Z01419   \n",
       "3        E0601                 RR                  0    G4733   \n",
       "4        J3490                  0                  0  E103553   \n",
       "\n",
       "  bil_prov_txnmy_cd  ln_bil_amt aso_buyup clm_pl_of_srvc_cd  \\\n",
       "0        291U00000X        9.50         1                81   \n",
       "1        332B00000X      490.70         1                12   \n",
       "2        291U00000X      109.57         0                81   \n",
       "3        207RS0012X      329.28         1                12   \n",
       "4        207W00000X      250.00         0                11   \n",
       "\n",
       "  bill_amount_category  sbmt_proc_cd_label_enc  sbmt_proc_mod_1_cd_label_enc  \\\n",
       "0                0-100                    3462                             0   \n",
       "1              201-500                    5338                           162   \n",
       "2              101-200                    5477                             0   \n",
       "3              201-500                    5342                           190   \n",
       "4              201-500                    5964                             0   \n",
       "\n",
       "   sbmt_proc_mod_2_cd_label_enc  diag_cd1_label_enc  \\\n",
       "0                             0                1056   \n",
       "1                           117                1975   \n",
       "2                             0               10559   \n",
       "3                             0                1975   \n",
       "4                             0                1230   \n",
       "\n",
       "   bil_prov_txnmy_cd_label_enc  bill_amount_category_label_enc  \\\n",
       "0                          446                               0   \n",
       "1                          466                               4   \n",
       "2                          446                               2   \n",
       "3                          173                               4   \n",
       "4                          190                               4   \n",
       "\n",
       "   aso_buyup_label_enc  clm_pl_of_srvc_cd_label_enc  \n",
       "0                    1                           37  \n",
       "1                    1                            8  \n",
       "2                    0                           37  \n",
       "3                    1                            8  \n",
       "4                    0                            7  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_4_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "810bc487-1239-45e1-8ea5-68894701e285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This data will be saved in DSW. This is the final data being used for GAN training\n",
    "train_data_4_pd.to_csv('train_data_4_pd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "be3b94f1-ee8c-4c90-932e-4643b699e591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_430031/4178775987.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data_4_pd = pd.read_csv('train_data_4_pd.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(491756, 17)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_4_pd = pd.read_csv('train_data_4_pd.csv')\n",
    "train_data_4_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb5f65d2-f102-4df0-b099-8d9ee7f9347b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 491756 entries, 0 to 491755\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   sbmt_proc_cd                    491756 non-null  object \n",
      " 1   sbmt_proc_mod_1_cd              491756 non-null  object \n",
      " 2   sbmt_proc_mod_2_cd              491756 non-null  object \n",
      " 3   diag_cd1                        491756 non-null  object \n",
      " 4   bil_prov_txnmy_cd               491756 non-null  object \n",
      " 5   ln_bil_amt                      491756 non-null  float64\n",
      " 6   aso_buyup                       491756 non-null  int64  \n",
      " 7   clm_pl_of_srvc_cd               491756 non-null  object \n",
      " 8   bill_amount_category            491756 non-null  object \n",
      " 9   sbmt_proc_cd_label_enc          491756 non-null  int64  \n",
      " 10  sbmt_proc_mod_1_cd_label_enc    491756 non-null  int64  \n",
      " 11  sbmt_proc_mod_2_cd_label_enc    491756 non-null  int64  \n",
      " 12  diag_cd1_label_enc              491756 non-null  int64  \n",
      " 13  bil_prov_txnmy_cd_label_enc     491756 non-null  int64  \n",
      " 14  bill_amount_category_label_enc  491756 non-null  int64  \n",
      " 15  aso_buyup_label_enc             491756 non-null  int64  \n",
      " 16  clm_pl_of_srvc_cd_label_enc     491756 non-null  int64  \n",
      "dtypes: float64(1), int64(9), object(7)\n",
      "memory usage: 63.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_4_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "323f5de3-47eb-467b-9c5a-91f40f90e8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This data will be saved in DSW location. This is the final data being used for GAN testing\n",
    "test_data_3_pd.to_csv('test_data_3_pd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5dfcbf73-1c27-4413-b0e6-7651b01329af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912480, 20)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 912480 entries, 0 to 912479\n",
      "Data columns (total 20 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   ufe_claim_id                    912480 non-null  int64  \n",
      " 1   cli_clm_id                      912480 non-null  int64  \n",
      " 2   map_fwae_disposition            912480 non-null  object \n",
      " 3   sbmt_proc_cd                    912480 non-null  object \n",
      " 4   sbmt_proc_mod_1_cd              912476 non-null  object \n",
      " 5   sbmt_proc_mod_2_cd              912480 non-null  object \n",
      " 6   diag_cd1                        912480 non-null  object \n",
      " 7   bil_prov_txnmy_cd               912480 non-null  object \n",
      " 8   ln_bil_amt                      0 non-null       float64\n",
      " 9   aso_buyup                       912480 non-null  int64  \n",
      " 10  clm_pl_of_srvc_cd               912480 non-null  int64  \n",
      " 11  bill_amount_category            912480 non-null  object \n",
      " 12  sbmt_proc_cd_label_enc          912480 non-null  int64  \n",
      " 13  sbmt_proc_mod_1_cd_label_enc    912480 non-null  int64  \n",
      " 14  sbmt_proc_mod_2_cd_label_enc    912480 non-null  int64  \n",
      " 15  diag_cd1_label_enc              912480 non-null  int64  \n",
      " 16  bil_prov_txnmy_cd_label_enc     912480 non-null  int64  \n",
      " 17  bill_amount_category_label_enc  912480 non-null  int64  \n",
      " 18  aso_buyup_label_enc             912480 non-null  int64  \n",
      " 19  clm_pl_of_srvc_cd_label_enc     912480 non-null  int64  \n",
      "dtypes: float64(1), int64(12), object(7)\n",
      "memory usage: 139.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data_3_pd = pd.read_csv('test_data_3_pd.csv')\n",
    "print(test_data_3_pd.shape)\n",
    "test_data_3_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc029958-a63f-43f7-a78a-2a5b3362d622",
   "metadata": {},
   "source": [
    "### Encoding test data target labels to 1/0\n",
    "'map_fwae_disposition' is claim level disposition.\n",
    "<br>Test data has all types of claims, it can have claims where all lines have same FWAE tag, or it can have claims in which some lines are paid and some are denied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d543b06d-9bfb-4a63-8e3a-2bdeacfc5317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_target(x):\n",
    "    if x == 'Paid after Investigation':\n",
    "        return 1\n",
    "    if x == 'Denied after Investigation':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e5d42b2b-66f5-4e93-8214-2ff561107be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map_fwae_disposition</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denied after Investigation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denied after Investigation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paid after Investigation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paid after Investigation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denied after Investigation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         map_fwae_disposition  target\n",
       "0  Denied after Investigation       0\n",
       "1  Denied after Investigation       0\n",
       "2    Paid after Investigation       1\n",
       "3    Paid after Investigation       1\n",
       "4  Denied after Investigation       0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3_pd['target'] = test_data_3_pd['map_fwae_disposition'].apply(define_target)\n",
    "test_data_3_pd[['map_fwae_disposition', 'target']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fe35be6a-46f2-4e5e-8f3c-0236e2d3292e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map_fwae_disposition</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denied after Investigation</td>\n",
       "      <td>0</td>\n",
       "      <td>436696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paid after Investigation</td>\n",
       "      <td>1</td>\n",
       "      <td>475784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         map_fwae_disposition  target       0\n",
       "0  Denied after Investigation       0  436696\n",
       "1    Paid after Investigation       1  475784"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3_pd.groupby(['map_fwae_disposition', 'target']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7959bbb3-c114-4c3b-866a-6ca6f9e505ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 912480 entries, 0 to 912479\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   map_fwae_disposition  912480 non-null  object\n",
      " 1   target                912480 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data_3_pd[['map_fwae_disposition', 'target']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f8bd8da-b45e-47f3-bd89-e19370a2a380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     68235\n",
       "1    105285\n",
       "Name: ufe_claim_id, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3_pd.groupby('target')['ufe_claim_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2700e-7cba-4325-837d-a931704a8476",
   "metadata": {},
   "source": [
    "# GAN\n",
    "Code is written in two setting. If you want to train/test a single GAN, then use this code block\n",
    "<br>If you want to try multiple GAN settings in a loop, then use \"GAN: Loop\" code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b72250-7255-4de5-a514-f3899e3cbf9e",
   "metadata": {},
   "source": [
    "### Model\n",
    "GAN consists of a generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de5b76f1-a234-4709-8d58-a64819b2e1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    \n",
    "    def __init__(self, gan_args):\n",
    "        \n",
    "        # Batch size, learning rate, noise dimension, data dimension, layer dimension\n",
    "        [self.batch_size, lr, self.noise_dim, self.data_dim, layers_dim] = gan_args\n",
    "        \n",
    "        # Generator input: noise dimension, layer dimension, data dimension\n",
    "        self.generator = Generator(self.batch_size).build_model(input_shape=(self.noise_dim,), \n",
    "                                                                dim=layers_dim, \n",
    "                                                                data_dim=self.data_dim)\n",
    "        \n",
    "        # Discriminator input: data dimension, layers dimension\n",
    "        self.discriminator = Discriminator(self.batch_size).build_model(input_shape=(self.data_dim,), \n",
    "                                                                        dim=layers_dim)\n",
    "        \n",
    "        # Adam Optimizer with learning rate as input, beta = 0.5\n",
    "        optimizer = Adam(lr, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.noise_dim,))\n",
    "        record = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(record)\n",
    "\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def get_data_batch(self, train, batch_size, seed=0):\n",
    "        # # random sampling - some samples will have excessively low or high sampling, but easy to implement\n",
    "        # np.random.seed(seed)\n",
    "        # x = train.loc[ np.random.choice(train.index, batch_size) ].values\n",
    "        # iterate through shuffled indices, so every sample gets covered evenly\n",
    "\n",
    "        start_i = (batch_size * seed) % len(train)\n",
    "        stop_i = start_i + batch_size\n",
    "        \n",
    "        shuffle_seed = (batch_size * seed) // len(train)\n",
    "        \n",
    "        np.random.seed(shuffle_seed)\n",
    "        \n",
    "        train_ix = np.random.choice(list(train.index), \n",
    "                                    replace=False, size=len(train))  # wasteful to shuffle every time\n",
    "        train_ix = list(train_ix) + list(train_ix)  # duplicate to cover ranges past the end of the set\n",
    "        \n",
    "        x = train.loc[train_ix[start_i: stop_i]].values\n",
    "        \n",
    "        return np.reshape(x, (batch_size, -1))\n",
    "        \n",
    "    def train(self, data, train_arguments):\n",
    "        [cache_prefix, epochs, sample_interval, model_loop_count] = train_arguments\n",
    "        \n",
    "        data_cols = data.columns\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((self.batch_size, 1))\n",
    "        fake = np.zeros((self.batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):    \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            batch_data = self.get_data_batch(data, self.batch_size)\n",
    "            \n",
    "            noise = tf.random.normal((self.batch_size, self.noise_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_data = self.generator.predict(noise)\n",
    "    \n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(batch_data, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_data, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            noise = tf.random.normal((self.batch_size, self.noise_dim))\n",
    "            # Train the generator (to have the discriminator label samples as valid)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "    \n",
    "            # Plot the progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "    \n",
    "            # If at save interval => save generated events\n",
    "            if epoch % sample_interval == 0:\n",
    "                #Test here data generation step\n",
    "                # save model checkpoints\n",
    "                model_checkpoint_base_name = 'model-' + str(model_loop_count) + '/' + cache_prefix + '_{}_model_weights_step_{}.h5'\n",
    "                self.generator.save_weights(model_checkpoint_base_name.format('generator', epoch))\n",
    "                self.discriminator.save_weights(model_checkpoint_base_name.format('discriminator', epoch))\n",
    "\n",
    "                #Here is generating the data\n",
    "                z = tf.random.normal((432, self.noise_dim))\n",
    "                gen_data = self.generator(z)\n",
    "                print('generated_data')\n",
    "\n",
    "    def save(self, path, name):\n",
    "        assert os.path.isdir(path) == True, \"Please provide a valid path. Path must be a directory.\"\n",
    "        model_path = os.path.join(path, name)\n",
    "        self.generator.save_weights(model_path)  # Load the generator\n",
    "        return\n",
    "    \n",
    "    def load(self, path):\n",
    "        assert os.path.isdir(path) == True, \"Please provide a valid path. Path must be a directory.\"\n",
    "        self.generator = Generator(self.batch_size)\n",
    "        self.generator = self.generator.load_weights(path)\n",
    "        return self.generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d35b2-39ff-485b-83d8-15a22a132f65",
   "metadata": {},
   "source": [
    "### Generator\n",
    "If you want to add/change any layer of generator neural network then, it is to be done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a04b43bc-7b8a-4b76-bca3-d7cafc7fb9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "    def build_model(self, input_shape, dim, data_dim):\n",
    "        # Input layer\n",
    "        input = Input(shape=input_shape, batch_size=self.batch_size)\n",
    "\n",
    "        # 3 hidden layers\n",
    "        x = Dense(dim, activation='relu')(input) # dim = number of neurons in this layer\n",
    "        x = Dense(dim * 2, activation='relu')(x)\n",
    "        x = Dense(dim * 4, activation='relu')(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = Dense(data_dim)(x) # data_dim = number of neurons in O/P layer. Dimension of output data.\n",
    "        \n",
    "        return Model(inputs=input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95231a00-7d35-4fbb-aac0-b51e64f491ef",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "If you want to add/change any layer of discriminator neural network then, it is to be done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "53013f3f-4d88-4f2d-b159-6bce1ea968e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator():\n",
    "    def __init__(self,batch_size):\n",
    "        self.batch_size=batch_size\n",
    "    \n",
    "    def build_model(self, input_shape, dim):\n",
    "        \n",
    "        # Input layer\n",
    "        input = Input(shape=input_shape, batch_size=self.batch_size)\n",
    "\n",
    "        # Hidden layers\n",
    "        x = Dense(dim * 4, activation='relu')(input)\n",
    "        x = Dropout(0.1)(x) # Dropout regularization\n",
    "        \n",
    "        x = Dense(dim * 2, activation='relu')(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        \n",
    "        x = Dense(dim, activation='relu')(x)\n",
    "        \n",
    "        # Output layer with single neuron\n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        return Model(inputs=input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfd710-e1bc-43e0-930e-4f1de9b33845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "46f6cd07-9285-45cc-a7a7-810c121e02db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory for saving training results/model. \n",
    "\n",
    "# Change 'model_loop_count' variable if you want to keep a copy of previous results, \n",
    "# else it will overwrite in the same location.\n",
    "# Changing 'model_loop_count' to n, will save the new results in 'model-n' named folder\n",
    "model_loop_count = 5\n",
    "models_dir = 'model-' + str(model_loop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "697c20d5-55ee-46f9-a7d7-ce1a0190eefd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If directory exists, then delete it. And then make it again.\n",
    "if os.path.exists(models_dir):\n",
    "    print('True')\n",
    "    shutil.rmtree(models_dir)\n",
    "os.makedirs(models_dir + '/gan/saved/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ff707-4d45-45eb-9387-a3d9ba7ac668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f480784d-2012-4613-bf3b-621bfd51845a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64 # Training batch size\n",
    "noise_dim = 100 # Dimension of noise vector which is given as initial random input to the generator\n",
    "dim = 256 # To increase/decrease units in GAN layers change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6d7fef60-1b9c-4d1c-b3f2-a6b023aa24aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 2e-4 # Learning rate\n",
    "log_step = 100\n",
    "epochs = 4000+1 # To change number of epochs for which training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "651c0894-d278-4dc8-944e-b1c973d1eba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "noise_dim = 100  \n",
    "dim = 128\n",
    "learning_rate = 2e-4\n",
    "log_step = 100\n",
    "epochs = 2000+1 \n",
    "\n",
    "# batch_size = 64 \n",
    "# noise_dim = 100  \n",
    "# dim = 256\n",
    "# learning_rate = 2e-4  \n",
    "# log_step = 100\n",
    "# epochs = 4000+1 \n",
    "\n",
    "# batch_size = 64 \n",
    "# noise_dim = 100  \n",
    "# dim = 28\n",
    "# learning_rate = 0.00001\n",
    "# log_step = 100\n",
    "# epochs = 1000+1 \n",
    "\n",
    "# batch_size = 64 \n",
    "# noise_dim = 100  \n",
    "# dim = 128\n",
    "# learning_rate = 0.000001\n",
    "# log_step = 100\n",
    "# epochs = 4000+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b71dbfee-ed7c-4ec9-99d5-a5e95ad73416",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbmt_proc_cd</th>\n",
       "      <th>sbmt_proc_mod_1_cd</th>\n",
       "      <th>sbmt_proc_mod_2_cd</th>\n",
       "      <th>diag_cd1</th>\n",
       "      <th>bil_prov_txnmy_cd</th>\n",
       "      <th>ln_bil_amt</th>\n",
       "      <th>aso_buyup</th>\n",
       "      <th>clm_pl_of_srvc_cd</th>\n",
       "      <th>bill_amount_category</th>\n",
       "      <th>sbmt_proc_cd_label_enc</th>\n",
       "      <th>sbmt_proc_mod_1_cd_label_enc</th>\n",
       "      <th>sbmt_proc_mod_2_cd_label_enc</th>\n",
       "      <th>diag_cd1_label_enc</th>\n",
       "      <th>bil_prov_txnmy_cd_label_enc</th>\n",
       "      <th>bill_amount_category_label_enc</th>\n",
       "      <th>aso_buyup_label_enc</th>\n",
       "      <th>clm_pl_of_srvc_cd_label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D649</td>\n",
       "      <td>291U00000X</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>0-100</td>\n",
       "      <td>3462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1056</td>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0562</td>\n",
       "      <td>NU</td>\n",
       "      <td>KX</td>\n",
       "      <td>G4733</td>\n",
       "      <td>332B00000X</td>\n",
       "      <td>490.70</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>201-500</td>\n",
       "      <td>5338</td>\n",
       "      <td>162</td>\n",
       "      <td>117</td>\n",
       "      <td>1975</td>\n",
       "      <td>466</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G0145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z01419</td>\n",
       "      <td>291U00000X</td>\n",
       "      <td>109.57</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>101-200</td>\n",
       "      <td>5477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10559</td>\n",
       "      <td>446</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0601</td>\n",
       "      <td>RR</td>\n",
       "      <td>0</td>\n",
       "      <td>G4733</td>\n",
       "      <td>207RS0012X</td>\n",
       "      <td>329.28</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>201-500</td>\n",
       "      <td>5342</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>1975</td>\n",
       "      <td>173</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J3490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>E103553</td>\n",
       "      <td>207W00000X</td>\n",
       "      <td>250.00</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>201-500</td>\n",
       "      <td>5964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1230</td>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sbmt_proc_cd sbmt_proc_mod_1_cd sbmt_proc_mod_2_cd diag_cd1  \\\n",
       "0        83540                  0                  0     D649   \n",
       "1        E0562                 NU                 KX    G4733   \n",
       "2        G0145                  0                  0   Z01419   \n",
       "3        E0601                 RR                  0    G4733   \n",
       "4        J3490                  0                  0  E103553   \n",
       "\n",
       "  bil_prov_txnmy_cd  ln_bil_amt  aso_buyup clm_pl_of_srvc_cd  \\\n",
       "0        291U00000X        9.50          1                81   \n",
       "1        332B00000X      490.70          1                12   \n",
       "2        291U00000X      109.57          0                81   \n",
       "3        207RS0012X      329.28          1                12   \n",
       "4        207W00000X      250.00          0                11   \n",
       "\n",
       "  bill_amount_category  sbmt_proc_cd_label_enc  sbmt_proc_mod_1_cd_label_enc  \\\n",
       "0                0-100                    3462                             0   \n",
       "1              201-500                    5338                           162   \n",
       "2              101-200                    5477                             0   \n",
       "3              201-500                    5342                           190   \n",
       "4              201-500                    5964                             0   \n",
       "\n",
       "   sbmt_proc_mod_2_cd_label_enc  diag_cd1_label_enc  \\\n",
       "0                             0                1056   \n",
       "1                           117                1975   \n",
       "2                             0               10559   \n",
       "3                             0                1975   \n",
       "4                             0                1230   \n",
       "\n",
       "   bil_prov_txnmy_cd_label_enc  bill_amount_category_label_enc  \\\n",
       "0                          446                               0   \n",
       "1                          466                               4   \n",
       "2                          446                               2   \n",
       "3                          173                               4   \n",
       "4                          190                               4   \n",
       "\n",
       "   aso_buyup_label_enc  clm_pl_of_srvc_cd_label_enc  \n",
       "0                    1                           37  \n",
       "1                    1                            8  \n",
       "2                    0                           37  \n",
       "3                    1                            8  \n",
       "4                    0                            7  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_4_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "4eaeef86-73b5-4831-b864-2ae8faff04e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['', 2001, 100, 5], [64, 0.0002, 100, 8, 128])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just joining the parameters into an array to pass into the model\n",
    "gan_args = [batch_size, learning_rate, noise_dim, train_data_4_pd.iloc[:, 9:].shape[1], dim]\n",
    "train_args = ['', epochs, log_step, model_loop_count]\n",
    "train_args, gan_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cee806-f683-4644-9ce1-8b145dbed2de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "993007e0-8f27-4430-985e-8537e736d4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "cf2ebe7f-cc6e-40f8-adce-c4bd6a4ca6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "synthesizer = model(gan_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "44385c9b-cd11-438d-bb5f-d5827d87619f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "0 [D loss: 46.234216, acc.: 28.91%] [G loss: 0.686216]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1 [D loss: 1.898987, acc.: 52.34%] [G loss: 0.686360]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2 [D loss: 0.555629, acc.: 53.12%] [G loss: 0.680689]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "3 [D loss: 0.357581, acc.: 53.12%] [G loss: 0.681886]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "4 [D loss: 0.360756, acc.: 50.00%] [G loss: 0.670897]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "5 [D loss: 0.364781, acc.: 50.78%] [G loss: 0.667528]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "6 [D loss: 0.367333, acc.: 50.00%] [G loss: 0.666360]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "7 [D loss: 2.157322, acc.: 51.56%] [G loss: 0.656958]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "8 [D loss: 0.368623, acc.: 50.00%] [G loss: 0.652843]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "9 [D loss: 0.373273, acc.: 50.78%] [G loss: 0.660546]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "10 [D loss: 0.366233, acc.: 53.91%] [G loss: 0.674109]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "11 [D loss: 1.686216, acc.: 52.34%] [G loss: 0.659493]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "12 [D loss: 0.374310, acc.: 50.78%] [G loss: 0.647893]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "13 [D loss: 0.370960, acc.: 54.69%] [G loss: 0.657767]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "14 [D loss: 0.665265, acc.: 56.25%] [G loss: 0.654604]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "15 [D loss: 0.451416, acc.: 56.25%] [G loss: 0.637642]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "16 [D loss: 0.989268, acc.: 50.00%] [G loss: 0.590411]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "17 [D loss: 0.421390, acc.: 50.00%] [G loss: 0.563924]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "18 [D loss: 0.436073, acc.: 50.00%] [G loss: 0.550937]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "19 [D loss: 0.442939, acc.: 50.78%] [G loss: 0.536917]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20 [D loss: 0.730701, acc.: 49.22%] [G loss: 0.508663]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "21 [D loss: 0.494648, acc.: 50.00%] [G loss: 0.483365]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "22 [D loss: 0.491490, acc.: 50.00%] [G loss: 0.497651]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "23 [D loss: 0.512442, acc.: 50.78%] [G loss: 0.454484]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "24 [D loss: 0.522597, acc.: 50.78%] [G loss: 0.474122]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "25 [D loss: 0.489014, acc.: 53.12%] [G loss: 0.483681]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "26 [D loss: 0.488478, acc.: 52.34%] [G loss: 0.512055]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "27 [D loss: 0.507257, acc.: 52.34%] [G loss: 0.549678]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "28 [D loss: 0.448420, acc.: 57.81%] [G loss: 0.567120]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "29 [D loss: 0.822186, acc.: 55.47%] [G loss: 0.527707]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "30 [D loss: 0.517187, acc.: 57.81%] [G loss: 0.518991]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "31 [D loss: 1.121117, acc.: 48.44%] [G loss: 0.302419]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "32 [D loss: 0.804802, acc.: 50.00%] [G loss: 0.242706]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "33 [D loss: 0.865983, acc.: 50.00%] [G loss: 0.240823]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "34 [D loss: 0.842085, acc.: 50.78%] [G loss: 0.259351]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "35 [D loss: 0.841992, acc.: 50.78%] [G loss: 0.288289]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "36 [D loss: 0.769310, acc.: 50.78%] [G loss: 0.337721]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "37 [D loss: 0.645775, acc.: 52.34%] [G loss: 0.436284]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "38 [D loss: 2.950636, acc.: 49.22%] [G loss: 0.181987]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "39 [D loss: 1.234496, acc.: 50.00%] [G loss: 0.120828]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "40 [D loss: 1.223026, acc.: 50.00%] [G loss: 0.116582]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "41 [D loss: 1.258047, acc.: 50.00%] [G loss: 0.121960]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "42 [D loss: 1.301603, acc.: 50.00%] [G loss: 0.147723]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "43 [D loss: 1.296028, acc.: 50.00%] [G loss: 0.194147]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "44 [D loss: 1.132110, acc.: 50.78%] [G loss: 0.228262]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "45 [D loss: 1.059052, acc.: 50.78%] [G loss: 0.241753]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "46 [D loss: 0.854232, acc.: 51.56%] [G loss: 0.381795]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "47 [D loss: 1.247896, acc.: 48.44%] [G loss: 0.155903]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "48 [D loss: 1.279399, acc.: 50.78%] [G loss: 0.141886]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "49 [D loss: 1.353343, acc.: 50.00%] [G loss: 0.198043]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "50 [D loss: 1.297742, acc.: 49.22%] [G loss: 0.194437]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "51 [D loss: 1.157241, acc.: 52.34%] [G loss: 0.217018]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "52 [D loss: 1.735952, acc.: 50.78%] [G loss: 0.209489]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "53 [D loss: 1.183051, acc.: 51.56%] [G loss: 0.314463]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "54 [D loss: 5.131503, acc.: 46.88%] [G loss: 0.018237]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "55 [D loss: 2.857047, acc.: 50.00%] [G loss: 0.009880]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "56 [D loss: 2.632942, acc.: 50.00%] [G loss: 0.014927]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "57 [D loss: 2.419918, acc.: 50.00%] [G loss: 0.025620]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "58 [D loss: 2.157196, acc.: 50.00%] [G loss: 0.053551]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "59 [D loss: 1.824120, acc.: 50.00%] [G loss: 0.058803]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "60 [D loss: 1.568521, acc.: 50.78%] [G loss: 0.187331]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "61 [D loss: 1.695575, acc.: 51.56%] [G loss: 0.138357]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "62 [D loss: 1.443888, acc.: 50.00%] [G loss: 0.214870]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "63 [D loss: 2.713282, acc.: 50.00%] [G loss: 0.108769]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "64 [D loss: 1.758346, acc.: 50.78%] [G loss: 0.174271]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "65 [D loss: 2.455871, acc.: 49.22%] [G loss: 0.057417]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "66 [D loss: 1.824507, acc.: 50.00%] [G loss: 0.108431]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "67 [D loss: 1.662503, acc.: 50.78%] [G loss: 0.215073]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "68 [D loss: 2.418953, acc.: 50.78%] [G loss: 0.060197]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "69 [D loss: 1.940209, acc.: 50.78%] [G loss: 0.100973]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "70 [D loss: 4.195116, acc.: 47.66%] [G loss: 0.018688]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "71 [D loss: 2.723785, acc.: 50.00%] [G loss: 0.015891]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "72 [D loss: 2.730006, acc.: 49.22%] [G loss: 0.030356]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "73 [D loss: 2.347907, acc.: 50.00%] [G loss: 0.078405]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "74 [D loss: 1.605841, acc.: 50.78%] [G loss: 0.264234]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "75 [D loss: 1.061792, acc.: 56.25%] [G loss: 0.619037]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "76 [D loss: 6.581912, acc.: 42.97%] [G loss: 0.000196]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "77 [D loss: 5.704693, acc.: 50.00%] [G loss: 0.000148]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "78 [D loss: 5.969584, acc.: 50.00%] [G loss: 0.000079]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "79 [D loss: 5.413012, acc.: 50.00%] [G loss: 0.000219]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "80 [D loss: 4.813201, acc.: 50.00%] [G loss: 0.000895]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "81 [D loss: 4.245978, acc.: 50.00%] [G loss: 0.005657]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "82 [D loss: 3.234589, acc.: 50.00%] [G loss: 0.009681]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "83 [D loss: 2.698384, acc.: 50.00%] [G loss: 0.028112]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "84 [D loss: 2.270735, acc.: 50.00%] [G loss: 0.061277]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "85 [D loss: 1.965309, acc.: 50.78%] [G loss: 0.122987]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "86 [D loss: 1.559170, acc.: 53.12%] [G loss: 0.197393]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "87 [D loss: 1.592250, acc.: 51.56%] [G loss: 0.226532]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "88 [D loss: 4.237611, acc.: 48.44%] [G loss: 0.042938]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "89 [D loss: 2.798704, acc.: 50.00%] [G loss: 0.028439]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "90 [D loss: 2.646238, acc.: 50.00%] [G loss: 0.097413]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "91 [D loss: 4.356170, acc.: 49.22%] [G loss: 0.037603]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "92 [D loss: 2.593211, acc.: 49.22%] [G loss: 0.037125]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "93 [D loss: 2.496716, acc.: 50.00%] [G loss: 0.075145]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "94 [D loss: 2.297477, acc.: 50.00%] [G loss: 0.100409]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "95 [D loss: 1.605431, acc.: 51.56%] [G loss: 0.383127]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "96 [D loss: 2.658028, acc.: 51.56%] [G loss: 0.172381]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "97 [D loss: 3.187750, acc.: 48.44%] [G loss: 0.029808]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "98 [D loss: 2.476780, acc.: 50.78%] [G loss: 0.060322]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "99 [D loss: 1.895672, acc.: 51.56%] [G loss: 0.170812]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "100 [D loss: 1.134687, acc.: 57.03%] [G loss: 0.560344]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "101 [D loss: 2.370547, acc.: 49.22%] [G loss: 0.119630]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "102 [D loss: 3.882820, acc.: 49.22%] [G loss: 0.043756]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "103 [D loss: 2.591814, acc.: 50.00%] [G loss: 0.095067]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "104 [D loss: 2.032441, acc.: 51.56%] [G loss: 0.207547]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "105 [D loss: 1.700066, acc.: 50.78%] [G loss: 0.347255]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "106 [D loss: 6.134405, acc.: 45.31%] [G loss: 0.000449]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "107 [D loss: 5.020468, acc.: 50.00%] [G loss: 0.000686]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "108 [D loss: 4.562504, acc.: 50.00%] [G loss: 0.001308]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "109 [D loss: 4.007239, acc.: 50.00%] [G loss: 0.026049]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "110 [D loss: 2.614006, acc.: 50.00%] [G loss: 0.109539]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "111 [D loss: 1.521585, acc.: 55.47%] [G loss: 0.380402]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "112 [D loss: 8.299310, acc.: 44.53%] [G loss: 0.000751]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "113 [D loss: 5.353554, acc.: 50.00%] [G loss: 0.000286]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "114 [D loss: 4.585890, acc.: 50.00%] [G loss: 0.002742]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "115 [D loss: 3.788020, acc.: 50.00%] [G loss: 0.009202]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "116 [D loss: 2.823426, acc.: 50.00%] [G loss: 0.082522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "117 [D loss: 1.843511, acc.: 54.69%] [G loss: 0.194587]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "118 [D loss: 3.973916, acc.: 46.88%] [G loss: 0.027829]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "119 [D loss: 3.095784, acc.: 49.22%] [G loss: 0.016807]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "120 [D loss: 2.620165, acc.: 50.00%] [G loss: 0.108540]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "121 [D loss: 1.942139, acc.: 51.56%] [G loss: 0.229878]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "122 [D loss: 1.203497, acc.: 56.25%] [G loss: 0.985081]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "123 [D loss: 5.026382, acc.: 46.88%] [G loss: 0.024413]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "124 [D loss: 2.725036, acc.: 50.00%] [G loss: 0.049173]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "125 [D loss: 2.314270, acc.: 50.78%] [G loss: 0.113707]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "126 [D loss: 1.599761, acc.: 53.91%] [G loss: 0.438439]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "127 [D loss: 2.571880, acc.: 50.00%] [G loss: 0.157606]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "128 [D loss: 2.245376, acc.: 49.22%] [G loss: 0.157993]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "129 [D loss: 1.779969, acc.: 51.56%] [G loss: 0.293589]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "130 [D loss: 2.149869, acc.: 50.78%] [G loss: 0.160081]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "131 [D loss: 3.247431, acc.: 46.88%] [G loss: 0.055325]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "132 [D loss: 2.473198, acc.: 50.00%] [G loss: 0.094997]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "133 [D loss: 1.936173, acc.: 51.56%] [G loss: 0.417573]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "134 [D loss: 3.033626, acc.: 47.66%] [G loss: 0.066624]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "135 [D loss: 2.201003, acc.: 50.78%] [G loss: 0.143257]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "136 [D loss: 1.636843, acc.: 53.91%] [G loss: 0.441231]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "137 [D loss: 1.320299, acc.: 60.16%] [G loss: 0.553490]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "138 [D loss: 4.755093, acc.: 46.09%] [G loss: 0.023762]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "139 [D loss: 3.737830, acc.: 50.00%] [G loss: 0.016646]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "140 [D loss: 2.407801, acc.: 50.00%] [G loss: 0.101471]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "141 [D loss: 1.659210, acc.: 55.47%] [G loss: 0.405474]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "142 [D loss: 3.400900, acc.: 45.31%] [G loss: 0.024070]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "143 [D loss: 3.487371, acc.: 50.00%] [G loss: 0.019198]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "144 [D loss: 2.316048, acc.: 50.00%] [G loss: 0.068910]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "145 [D loss: 1.726899, acc.: 51.56%] [G loss: 0.497372]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "146 [D loss: 5.383760, acc.: 44.53%] [G loss: 0.004493]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "147 [D loss: 3.930822, acc.: 50.00%] [G loss: 0.019389]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "148 [D loss: 3.376626, acc.: 50.00%] [G loss: 0.034969]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "149 [D loss: 2.510590, acc.: 49.22%] [G loss: 0.040961]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "150 [D loss: 2.183748, acc.: 50.78%] [G loss: 0.168481]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "151 [D loss: 1.504091, acc.: 52.34%] [G loss: 0.676559]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "152 [D loss: 3.836980, acc.: 45.31%] [G loss: 0.051697]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "153 [D loss: 2.423291, acc.: 50.00%] [G loss: 0.082744]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "154 [D loss: 1.589501, acc.: 50.78%] [G loss: 0.222902]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "155 [D loss: 2.768817, acc.: 48.44%] [G loss: 0.129293]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "156 [D loss: 2.165744, acc.: 50.78%] [G loss: 0.115532]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "157 [D loss: 2.261383, acc.: 51.56%] [G loss: 0.298385]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "158 [D loss: 2.902979, acc.: 50.78%] [G loss: 0.229438]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "159 [D loss: 1.477829, acc.: 53.12%] [G loss: 0.240023]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "160 [D loss: 2.218096, acc.: 50.00%] [G loss: 0.304609]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "161 [D loss: 2.178221, acc.: 53.12%] [G loss: 0.298924]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "162 [D loss: 1.554009, acc.: 56.25%] [G loss: 0.733280]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "163 [D loss: 1.303110, acc.: 54.69%] [G loss: 0.668948]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "164 [D loss: 5.516754, acc.: 46.09%] [G loss: 0.020073]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "165 [D loss: 3.121185, acc.: 50.00%] [G loss: 0.043926]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "166 [D loss: 2.254820, acc.: 51.56%] [G loss: 0.179375]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "167 [D loss: 1.843523, acc.: 51.56%] [G loss: 0.528538]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "168 [D loss: 3.177733, acc.: 50.78%] [G loss: 0.253306]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "169 [D loss: 3.703648, acc.: 48.44%] [G loss: 0.038286]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "170 [D loss: 2.506951, acc.: 50.00%] [G loss: 0.154223]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "171 [D loss: 2.178418, acc.: 50.00%] [G loss: 0.321973]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "172 [D loss: 1.737565, acc.: 51.56%] [G loss: 0.282185]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "173 [D loss: 4.324744, acc.: 46.09%] [G loss: 0.015861]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "174 [D loss: 2.848370, acc.: 50.00%] [G loss: 0.113169]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "175 [D loss: 1.811315, acc.: 54.69%] [G loss: 0.606572]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "176 [D loss: 3.069108, acc.: 52.34%] [G loss: 0.575470]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "177 [D loss: 1.954631, acc.: 50.78%] [G loss: 0.232185]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "178 [D loss: 1.243372, acc.: 53.91%] [G loss: 0.656054]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "179 [D loss: 2.937898, acc.: 51.56%] [G loss: 0.224073]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "180 [D loss: 1.545551, acc.: 55.47%] [G loss: 0.610894]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "181 [D loss: 1.854032, acc.: 57.03%] [G loss: 0.330581]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "182 [D loss: 2.428607, acc.: 50.00%] [G loss: 0.320186]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "183 [D loss: 2.357947, acc.: 51.56%] [G loss: 0.320122]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "184 [D loss: 1.663872, acc.: 57.03%] [G loss: 0.472184]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "185 [D loss: 1.510784, acc.: 54.69%] [G loss: 0.462182]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "186 [D loss: 1.986471, acc.: 50.78%] [G loss: 0.211382]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "187 [D loss: 1.723037, acc.: 51.56%] [G loss: 0.578003]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "188 [D loss: 2.329266, acc.: 53.91%] [G loss: 0.611892]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "189 [D loss: 3.390313, acc.: 47.66%] [G loss: 0.091325]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "190 [D loss: 1.731104, acc.: 51.56%] [G loss: 0.339026]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "191 [D loss: 1.041271, acc.: 60.94%] [G loss: 1.023185]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "192 [D loss: 7.512651, acc.: 42.97%] [G loss: 0.001156]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "193 [D loss: 4.861281, acc.: 50.00%] [G loss: 0.004083]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "194 [D loss: 3.767091, acc.: 50.00%] [G loss: 0.035144]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "195 [D loss: 2.160157, acc.: 51.56%] [G loss: 0.367911]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "196 [D loss: 1.482991, acc.: 50.78%] [G loss: 1.147392]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "197 [D loss: 4.676076, acc.: 45.31%] [G loss: 0.036613]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "198 [D loss: 3.303619, acc.: 50.00%] [G loss: 0.034555]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "199 [D loss: 1.850207, acc.: 50.78%] [G loss: 0.454420]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "200 [D loss: 3.273075, acc.: 47.66%] [G loss: 0.064299]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "201 [D loss: 2.792088, acc.: 49.22%] [G loss: 0.084282]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "202 [D loss: 1.528370, acc.: 54.69%] [G loss: 0.557215]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "203 [D loss: 3.759389, acc.: 47.66%] [G loss: 0.051280]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "204 [D loss: 2.437767, acc.: 50.00%] [G loss: 0.133233]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "205 [D loss: 1.662548, acc.: 53.91%] [G loss: 0.520599]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "206 [D loss: 1.814584, acc.: 53.91%] [G loss: 0.332167]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "207 [D loss: 1.374948, acc.: 60.94%] [G loss: 0.497796]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "208 [D loss: 1.694260, acc.: 52.34%] [G loss: 0.399073]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "209 [D loss: 2.671032, acc.: 48.44%] [G loss: 0.244512]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "210 [D loss: 2.124746, acc.: 50.00%] [G loss: 0.212685]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "211 [D loss: 1.095606, acc.: 55.47%] [G loss: 0.547521]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "212 [D loss: 2.753683, acc.: 44.53%] [G loss: 0.058928]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "213 [D loss: 2.922081, acc.: 49.22%] [G loss: 0.054537]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "214 [D loss: 1.813558, acc.: 51.56%] [G loss: 0.275847]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "215 [D loss: 0.829645, acc.: 67.19%] [G loss: 1.118702]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "216 [D loss: 4.573606, acc.: 44.53%] [G loss: 0.025453]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "217 [D loss: 2.952291, acc.: 50.00%] [G loss: 0.036713]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "218 [D loss: 2.198493, acc.: 50.00%] [G loss: 0.314828]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "219 [D loss: 1.145361, acc.: 57.81%] [G loss: 1.048875]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "220 [D loss: 1.966181, acc.: 46.09%] [G loss: 0.163055]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "221 [D loss: 1.428442, acc.: 53.91%] [G loss: 0.386286]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "222 [D loss: 2.339457, acc.: 49.22%] [G loss: 0.151260]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "223 [D loss: 1.712147, acc.: 52.34%] [G loss: 0.453018]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "224 [D loss: 1.358203, acc.: 53.91%] [G loss: 0.427206]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "225 [D loss: 2.305871, acc.: 48.44%] [G loss: 0.118842]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "226 [D loss: 1.835663, acc.: 50.78%] [G loss: 0.263232]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "227 [D loss: 1.543628, acc.: 53.91%] [G loss: 0.560618]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "228 [D loss: 2.339548, acc.: 48.44%] [G loss: 0.085144]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "229 [D loss: 1.720757, acc.: 50.78%] [G loss: 0.317761]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "230 [D loss: 1.273020, acc.: 57.03%] [G loss: 1.059447]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "231 [D loss: 5.488674, acc.: 43.75%] [G loss: 0.043903]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "232 [D loss: 1.994740, acc.: 50.00%] [G loss: 0.147469]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "233 [D loss: 1.597178, acc.: 53.12%] [G loss: 0.642479]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "234 [D loss: 4.737106, acc.: 42.97%] [G loss: 0.004307]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "235 [D loss: 3.876613, acc.: 50.00%] [G loss: 0.010434]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "236 [D loss: 2.737696, acc.: 50.00%] [G loss: 0.096842]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "237 [D loss: 1.780709, acc.: 51.56%] [G loss: 0.497623]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "238 [D loss: 1.236204, acc.: 57.81%] [G loss: 0.722360]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "239 [D loss: 3.913474, acc.: 47.66%] [G loss: 0.090326]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "240 [D loss: 2.412539, acc.: 50.00%] [G loss: 0.122316]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "241 [D loss: 1.157975, acc.: 57.03%] [G loss: 0.425587]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "242 [D loss: 2.425714, acc.: 49.22%] [G loss: 0.349062]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "243 [D loss: 1.269755, acc.: 53.91%] [G loss: 0.862032]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "244 [D loss: 2.651508, acc.: 50.78%] [G loss: 0.379430]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "245 [D loss: 1.718350, acc.: 53.91%] [G loss: 0.586280]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "246 [D loss: 2.375434, acc.: 46.88%] [G loss: 0.156943]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "247 [D loss: 1.645736, acc.: 53.91%] [G loss: 0.548100]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "248 [D loss: 2.832550, acc.: 49.22%] [G loss: 0.186958]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "249 [D loss: 1.302909, acc.: 54.69%] [G loss: 0.741123]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "250 [D loss: 1.380857, acc.: 60.94%] [G loss: 1.014797]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "251 [D loss: 3.567423, acc.: 43.75%] [G loss: 0.019371]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "252 [D loss: 2.828610, acc.: 50.00%] [G loss: 0.071464]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "253 [D loss: 1.631271, acc.: 54.69%] [G loss: 0.434122]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "254 [D loss: 0.815368, acc.: 70.31%] [G loss: 1.063025]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "255 [D loss: 1.052163, acc.: 62.50%] [G loss: 0.957158]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "256 [D loss: 2.874543, acc.: 49.22%] [G loss: 0.212456]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "257 [D loss: 1.405620, acc.: 52.34%] [G loss: 0.436606]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "258 [D loss: 1.350699, acc.: 53.12%] [G loss: 0.714936]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "259 [D loss: 1.026002, acc.: 60.16%] [G loss: 0.724657]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "260 [D loss: 1.370611, acc.: 50.78%] [G loss: 0.568146]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "261 [D loss: 1.779585, acc.: 55.47%] [G loss: 0.516950]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "262 [D loss: 0.859522, acc.: 60.94%] [G loss: 1.214062]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "263 [D loss: 3.234138, acc.: 48.44%] [G loss: 0.192797]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "264 [D loss: 1.570715, acc.: 51.56%] [G loss: 0.518903]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "265 [D loss: 2.447948, acc.: 46.09%] [G loss: 0.074690]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "266 [D loss: 2.297777, acc.: 50.00%] [G loss: 0.189696]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "267 [D loss: 1.533583, acc.: 55.47%] [G loss: 0.342497]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "268 [D loss: 1.423515, acc.: 55.47%] [G loss: 0.951270]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "269 [D loss: 2.182007, acc.: 49.22%] [G loss: 0.439777]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "270 [D loss: 1.494869, acc.: 53.91%] [G loss: 0.437694]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "271 [D loss: 2.286743, acc.: 50.78%] [G loss: 0.201756]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "272 [D loss: 1.982856, acc.: 50.78%] [G loss: 0.222850]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "273 [D loss: 1.371239, acc.: 52.34%] [G loss: 0.721277]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "274 [D loss: 1.171725, acc.: 60.16%] [G loss: 0.540285]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "275 [D loss: 2.919202, acc.: 44.53%] [G loss: 0.058060]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "276 [D loss: 2.189308, acc.: 50.78%] [G loss: 0.131552]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "277 [D loss: 1.807536, acc.: 53.12%] [G loss: 0.280370]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "278 [D loss: 1.120753, acc.: 54.69%] [G loss: 0.760949]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "279 [D loss: 1.947819, acc.: 51.56%] [G loss: 0.202017]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "280 [D loss: 1.958514, acc.: 50.78%] [G loss: 0.410167]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "281 [D loss: 2.431897, acc.: 49.22%] [G loss: 0.203107]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "282 [D loss: 1.804995, acc.: 50.00%] [G loss: 0.182639]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "283 [D loss: 1.163586, acc.: 55.47%] [G loss: 0.575474]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "284 [D loss: 1.194045, acc.: 53.12%] [G loss: 0.366283]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "285 [D loss: 1.003320, acc.: 56.25%] [G loss: 0.605493]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "286 [D loss: 1.783442, acc.: 47.66%] [G loss: 0.356946]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "287 [D loss: 1.731048, acc.: 52.34%] [G loss: 0.418470]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "288 [D loss: 2.017996, acc.: 48.44%] [G loss: 0.186779]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "289 [D loss: 1.099620, acc.: 53.91%] [G loss: 0.530912]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "290 [D loss: 1.316941, acc.: 54.69%] [G loss: 0.619870]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "291 [D loss: 1.205401, acc.: 55.47%] [G loss: 0.681141]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "292 [D loss: 1.347551, acc.: 58.59%] [G loss: 0.238769]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "293 [D loss: 1.032560, acc.: 57.81%] [G loss: 0.560044]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "294 [D loss: 0.580551, acc.: 66.41%] [G loss: 1.387193]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "295 [D loss: 3.931008, acc.: 42.97%] [G loss: 0.103962]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "296 [D loss: 2.037631, acc.: 50.00%] [G loss: 0.185916]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "297 [D loss: 1.246176, acc.: 54.69%] [G loss: 0.686572]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "298 [D loss: 1.423107, acc.: 53.12%] [G loss: 0.489904]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "299 [D loss: 1.743086, acc.: 47.66%] [G loss: 0.270569]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "300 [D loss: 1.289986, acc.: 56.25%] [G loss: 0.457685]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "301 [D loss: 2.228776, acc.: 45.31%] [G loss: 0.115491]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "302 [D loss: 1.627039, acc.: 51.56%] [G loss: 0.334022]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "303 [D loss: 0.834603, acc.: 60.94%] [G loss: 0.873243]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "304 [D loss: 1.564457, acc.: 52.34%] [G loss: 0.394310]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "305 [D loss: 1.094348, acc.: 57.81%] [G loss: 0.479273]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "306 [D loss: 2.095823, acc.: 48.44%] [G loss: 0.392726]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "307 [D loss: 1.219627, acc.: 52.34%] [G loss: 0.591251]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "308 [D loss: 0.649260, acc.: 67.97%] [G loss: 1.130916]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "309 [D loss: 2.874693, acc.: 46.88%] [G loss: 0.224256]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "310 [D loss: 1.677119, acc.: 52.34%] [G loss: 0.400682]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "311 [D loss: 1.304799, acc.: 55.47%] [G loss: 0.512673]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "312 [D loss: 2.113744, acc.: 47.66%] [G loss: 0.208840]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "313 [D loss: 1.327615, acc.: 53.12%] [G loss: 0.246281]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "314 [D loss: 1.647674, acc.: 53.12%] [G loss: 0.255312]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "315 [D loss: 1.454873, acc.: 50.00%] [G loss: 0.358944]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "316 [D loss: 1.889276, acc.: 46.09%] [G loss: 0.388320]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "317 [D loss: 1.653018, acc.: 52.34%] [G loss: 0.421722]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "318 [D loss: 0.953863, acc.: 57.03%] [G loss: 0.735022]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "319 [D loss: 1.523334, acc.: 53.91%] [G loss: 0.466080]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "320 [D loss: 1.283757, acc.: 53.12%] [G loss: 0.722806]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "321 [D loss: 2.447155, acc.: 47.66%] [G loss: 0.130930]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "322 [D loss: 1.423536, acc.: 50.78%] [G loss: 0.315834]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "323 [D loss: 1.091207, acc.: 56.25%] [G loss: 1.020328]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "324 [D loss: 3.589227, acc.: 40.62%] [G loss: 0.038013]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "325 [D loss: 2.231745, acc.: 50.00%] [G loss: 0.087652]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "326 [D loss: 1.881271, acc.: 52.34%] [G loss: 0.345820]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "327 [D loss: 1.426066, acc.: 53.12%] [G loss: 0.535574]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "328 [D loss: 0.848714, acc.: 64.84%] [G loss: 0.981174]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "329 [D loss: 2.377237, acc.: 50.00%] [G loss: 0.292707]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "330 [D loss: 1.251272, acc.: 52.34%] [G loss: 0.370309]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "331 [D loss: 1.108988, acc.: 59.38%] [G loss: 0.635586]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "332 [D loss: 2.270874, acc.: 46.88%] [G loss: 0.187425]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "333 [D loss: 1.825330, acc.: 50.00%] [G loss: 0.268631]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "334 [D loss: 0.992391, acc.: 56.25%] [G loss: 1.083331]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "335 [D loss: 2.100311, acc.: 56.25%] [G loss: 0.455346]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "336 [D loss: 1.037301, acc.: 57.03%] [G loss: 0.606444]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "337 [D loss: 1.265321, acc.: 54.69%] [G loss: 0.711566]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "338 [D loss: 1.788007, acc.: 53.91%] [G loss: 0.696058]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "339 [D loss: 1.166765, acc.: 57.03%] [G loss: 0.866801]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "340 [D loss: 1.449790, acc.: 58.59%] [G loss: 0.849628]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "341 [D loss: 2.315647, acc.: 50.78%] [G loss: 0.385931]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "342 [D loss: 1.061236, acc.: 57.81%] [G loss: 0.607371]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "343 [D loss: 1.171380, acc.: 64.06%] [G loss: 0.793191]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "344 [D loss: 2.458065, acc.: 47.66%] [G loss: 0.417946]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "345 [D loss: 1.124506, acc.: 57.81%] [G loss: 1.014891]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "346 [D loss: 1.320111, acc.: 62.50%] [G loss: 0.592889]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "347 [D loss: 1.117446, acc.: 58.59%] [G loss: 0.861231]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "348 [D loss: 1.577210, acc.: 50.78%] [G loss: 0.620280]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "349 [D loss: 1.054860, acc.: 57.03%] [G loss: 0.977546]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "350 [D loss: 0.872582, acc.: 68.75%] [G loss: 1.089046]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "351 [D loss: 1.015533, acc.: 58.59%] [G loss: 1.029620]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "352 [D loss: 1.844040, acc.: 50.78%] [G loss: 0.504488]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "353 [D loss: 2.333366, acc.: 46.09%] [G loss: 0.136477]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "354 [D loss: 1.302406, acc.: 53.12%] [G loss: 0.538341]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "355 [D loss: 1.129346, acc.: 59.38%] [G loss: 0.751101]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "356 [D loss: 1.637049, acc.: 53.12%] [G loss: 0.497557]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "357 [D loss: 2.440388, acc.: 45.31%] [G loss: 0.204886]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "358 [D loss: 1.742964, acc.: 49.22%] [G loss: 0.245070]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "359 [D loss: 1.394990, acc.: 53.12%] [G loss: 0.503176]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "360 [D loss: 1.756119, acc.: 50.78%] [G loss: 0.420508]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "361 [D loss: 1.448003, acc.: 50.78%] [G loss: 0.517817]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "362 [D loss: 1.313065, acc.: 55.47%] [G loss: 0.382181]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "363 [D loss: 1.394494, acc.: 53.91%] [G loss: 0.449259]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "364 [D loss: 1.617510, acc.: 52.34%] [G loss: 0.349655]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "365 [D loss: 1.530885, acc.: 53.12%] [G loss: 0.336705]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "366 [D loss: 1.503412, acc.: 50.78%] [G loss: 0.570313]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "367 [D loss: 1.112966, acc.: 57.03%] [G loss: 0.590280]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "368 [D loss: 1.792577, acc.: 50.00%] [G loss: 0.287743]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "369 [D loss: 1.147040, acc.: 52.34%] [G loss: 0.593666]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "370 [D loss: 1.002940, acc.: 62.50%] [G loss: 0.776084]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "371 [D loss: 1.198465, acc.: 54.69%] [G loss: 0.546323]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "372 [D loss: 1.161459, acc.: 53.12%] [G loss: 0.438382]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "373 [D loss: 1.789842, acc.: 47.66%] [G loss: 0.483824]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "374 [D loss: 1.257903, acc.: 53.91%] [G loss: 0.614649]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "375 [D loss: 1.098625, acc.: 60.94%] [G loss: 0.753740]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "376 [D loss: 1.064055, acc.: 62.50%] [G loss: 0.735627]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "377 [D loss: 1.044844, acc.: 54.69%] [G loss: 0.572261]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "378 [D loss: 1.048225, acc.: 51.56%] [G loss: 0.642733]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "379 [D loss: 1.851422, acc.: 49.22%] [G loss: 0.278067]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "380 [D loss: 1.252169, acc.: 54.69%] [G loss: 0.438895]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "381 [D loss: 1.257697, acc.: 50.00%] [G loss: 0.458387]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "382 [D loss: 1.060402, acc.: 55.47%] [G loss: 0.566468]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "383 [D loss: 0.993676, acc.: 58.59%] [G loss: 0.630715]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "384 [D loss: 1.321438, acc.: 52.34%] [G loss: 0.678160]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "385 [D loss: 0.922137, acc.: 61.72%] [G loss: 0.799238]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "386 [D loss: 1.539955, acc.: 55.47%] [G loss: 0.769466]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "387 [D loss: 0.999302, acc.: 54.69%] [G loss: 0.785005]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "388 [D loss: 0.810098, acc.: 57.81%] [G loss: 0.566515]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "389 [D loss: 1.222981, acc.: 58.59%] [G loss: 0.572536]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "390 [D loss: 1.666811, acc.: 54.69%] [G loss: 0.543550]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "391 [D loss: 0.963495, acc.: 60.16%] [G loss: 0.733125]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "392 [D loss: 1.381036, acc.: 51.56%] [G loss: 0.462094]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "393 [D loss: 1.308408, acc.: 53.91%] [G loss: 0.566705]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "394 [D loss: 0.930995, acc.: 57.03%] [G loss: 0.835738]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "395 [D loss: 1.539697, acc.: 51.56%] [G loss: 0.449794]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "396 [D loss: 1.231288, acc.: 58.59%] [G loss: 0.613378]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "397 [D loss: 0.716806, acc.: 67.19%] [G loss: 1.039848]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "398 [D loss: 1.732422, acc.: 46.88%] [G loss: 0.304943]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "399 [D loss: 1.095068, acc.: 53.91%] [G loss: 0.415521]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "400 [D loss: 0.860961, acc.: 59.38%] [G loss: 0.985569]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "401 [D loss: 1.751463, acc.: 49.22%] [G loss: 0.271214]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "402 [D loss: 1.279245, acc.: 53.91%] [G loss: 0.540076]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "403 [D loss: 1.534677, acc.: 53.12%] [G loss: 0.478595]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "404 [D loss: 1.347279, acc.: 50.78%] [G loss: 0.454060]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "405 [D loss: 1.481033, acc.: 49.22%] [G loss: 0.553928]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "406 [D loss: 1.185402, acc.: 51.56%] [G loss: 0.402656]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "407 [D loss: 1.453538, acc.: 50.78%] [G loss: 0.332358]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "408 [D loss: 1.282157, acc.: 57.81%] [G loss: 0.857378]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "409 [D loss: 2.254567, acc.: 46.09%] [G loss: 0.205207]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "410 [D loss: 1.462639, acc.: 50.78%] [G loss: 0.288426]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "411 [D loss: 1.080579, acc.: 50.00%] [G loss: 0.518817]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "412 [D loss: 1.023121, acc.: 61.72%] [G loss: 0.865169]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "413 [D loss: 1.633268, acc.: 49.22%] [G loss: 0.436955]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "414 [D loss: 1.393420, acc.: 53.12%] [G loss: 0.362096]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "415 [D loss: 1.767568, acc.: 50.00%] [G loss: 0.278315]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "416 [D loss: 1.026713, acc.: 57.81%] [G loss: 0.539872]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "417 [D loss: 1.145660, acc.: 57.81%] [G loss: 0.736989]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "418 [D loss: 2.558651, acc.: 39.84%] [G loss: 0.127940]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "419 [D loss: 1.458572, acc.: 50.00%] [G loss: 0.321625]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "420 [D loss: 1.387517, acc.: 51.56%] [G loss: 0.720972]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "421 [D loss: 1.205279, acc.: 56.25%] [G loss: 0.670828]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "422 [D loss: 1.290998, acc.: 57.03%] [G loss: 0.600448]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "423 [D loss: 1.668231, acc.: 48.44%] [G loss: 0.316489]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "424 [D loss: 1.141353, acc.: 54.69%] [G loss: 0.618665]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "425 [D loss: 1.305067, acc.: 59.38%] [G loss: 0.529159]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "426 [D loss: 1.575356, acc.: 49.22%] [G loss: 0.446882]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "427 [D loss: 1.290157, acc.: 54.69%] [G loss: 0.588683]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "428 [D loss: 1.266020, acc.: 53.91%] [G loss: 0.365150]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "429 [D loss: 1.009107, acc.: 54.69%] [G loss: 0.735620]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "430 [D loss: 1.110233, acc.: 64.84%] [G loss: 0.866124]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "431 [D loss: 1.251631, acc.: 53.91%] [G loss: 0.487341]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "432 [D loss: 0.899379, acc.: 61.72%] [G loss: 0.900157]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "433 [D loss: 1.054897, acc.: 63.28%] [G loss: 0.717330]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "434 [D loss: 1.117734, acc.: 53.12%] [G loss: 0.621451]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "435 [D loss: 0.918963, acc.: 67.97%] [G loss: 0.768504]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "436 [D loss: 1.209822, acc.: 60.16%] [G loss: 0.708539]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "437 [D loss: 0.764932, acc.: 60.94%] [G loss: 0.999457]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "438 [D loss: 0.388952, acc.: 76.56%] [G loss: 1.320143]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "439 [D loss: 1.323465, acc.: 55.47%] [G loss: 0.458754]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "440 [D loss: 0.876561, acc.: 57.81%] [G loss: 0.841873]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "441 [D loss: 1.086704, acc.: 60.94%] [G loss: 0.628386]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "442 [D loss: 1.007428, acc.: 60.16%] [G loss: 0.649096]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "443 [D loss: 1.322630, acc.: 50.00%] [G loss: 0.462933]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "444 [D loss: 1.355139, acc.: 52.34%] [G loss: 0.665387]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "445 [D loss: 1.169991, acc.: 56.25%] [G loss: 0.773490]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "446 [D loss: 0.948128, acc.: 64.06%] [G loss: 0.552196]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "447 [D loss: 0.884625, acc.: 63.28%] [G loss: 0.662836]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "448 [D loss: 1.211852, acc.: 53.12%] [G loss: 0.432121]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "449 [D loss: 1.122543, acc.: 56.25%] [G loss: 0.809593]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "450 [D loss: 1.242557, acc.: 55.47%] [G loss: 0.651706]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "451 [D loss: 0.623791, acc.: 70.31%] [G loss: 0.994385]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "452 [D loss: 1.311433, acc.: 59.38%] [G loss: 0.871811]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "453 [D loss: 0.960593, acc.: 60.16%] [G loss: 0.601200]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "454 [D loss: 0.615142, acc.: 68.75%] [G loss: 0.872178]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "455 [D loss: 1.439361, acc.: 53.91%] [G loss: 0.252023]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "456 [D loss: 1.299414, acc.: 51.56%] [G loss: 0.587745]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "457 [D loss: 1.457527, acc.: 52.34%] [G loss: 0.910153]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "458 [D loss: 1.061897, acc.: 57.03%] [G loss: 0.525750]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "459 [D loss: 0.700265, acc.: 68.75%] [G loss: 0.719578]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "460 [D loss: 1.289938, acc.: 56.25%] [G loss: 0.677211]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "461 [D loss: 0.804595, acc.: 64.06%] [G loss: 0.723239]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "462 [D loss: 2.034306, acc.: 44.53%] [G loss: 0.422590]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "463 [D loss: 1.737833, acc.: 48.44%] [G loss: 0.333096]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "464 [D loss: 0.898720, acc.: 60.94%] [G loss: 0.928556]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "465 [D loss: 0.931022, acc.: 62.50%] [G loss: 0.756130]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "466 [D loss: 1.093493, acc.: 60.16%] [G loss: 0.742159]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "467 [D loss: 0.890637, acc.: 58.59%] [G loss: 0.744500]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "468 [D loss: 1.239171, acc.: 58.59%] [G loss: 0.688725]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "469 [D loss: 0.945645, acc.: 57.03%] [G loss: 0.518436]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "470 [D loss: 1.003229, acc.: 60.16%] [G loss: 0.606139]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "471 [D loss: 0.840801, acc.: 61.72%] [G loss: 0.924071]\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "472 [D loss: 0.899976, acc.: 57.03%] [G loss: 0.664124]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "473 [D loss: 1.439600, acc.: 54.69%] [G loss: 0.567238]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "474 [D loss: 0.760122, acc.: 60.94%] [G loss: 0.938942]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "475 [D loss: 1.299739, acc.: 50.00%] [G loss: 0.519827]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "476 [D loss: 0.831545, acc.: 63.28%] [G loss: 0.727593]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "477 [D loss: 0.857701, acc.: 60.94%] [G loss: 0.806394]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "478 [D loss: 1.236362, acc.: 50.78%] [G loss: 0.538597]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "479 [D loss: 1.009417, acc.: 59.38%] [G loss: 0.851572]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "480 [D loss: 0.756348, acc.: 63.28%] [G loss: 0.824819]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "481 [D loss: 1.272664, acc.: 56.25%] [G loss: 0.547362]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "482 [D loss: 0.727513, acc.: 59.38%] [G loss: 1.169007]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "483 [D loss: 1.235382, acc.: 60.16%] [G loss: 1.007014]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "484 [D loss: 1.374214, acc.: 52.34%] [G loss: 0.372282]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "485 [D loss: 0.963010, acc.: 55.47%] [G loss: 0.585259]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "486 [D loss: 0.832642, acc.: 64.84%] [G loss: 0.838983]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "487 [D loss: 0.875874, acc.: 64.06%] [G loss: 0.905015]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "488 [D loss: 0.900434, acc.: 62.50%] [G loss: 0.724084]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "489 [D loss: 0.618296, acc.: 71.88%] [G loss: 0.733702]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "490 [D loss: 1.161225, acc.: 56.25%] [G loss: 0.801667]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "491 [D loss: 0.699375, acc.: 62.50%] [G loss: 0.903845]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "492 [D loss: 0.493941, acc.: 74.22%] [G loss: 1.023014]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "493 [D loss: 1.425638, acc.: 50.78%] [G loss: 0.406694]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "494 [D loss: 1.064581, acc.: 54.69%] [G loss: 0.617397]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "495 [D loss: 1.295643, acc.: 53.12%] [G loss: 0.520086]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "496 [D loss: 0.638144, acc.: 67.19%] [G loss: 0.704196]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "497 [D loss: 0.964891, acc.: 68.75%] [G loss: 0.858370]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "498 [D loss: 0.922974, acc.: 61.72%] [G loss: 0.717764]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "499 [D loss: 0.809042, acc.: 62.50%] [G loss: 0.657272]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "500 [D loss: 1.029203, acc.: 54.69%] [G loss: 0.658749]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "501 [D loss: 0.654678, acc.: 67.19%] [G loss: 0.880438]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "502 [D loss: 1.070224, acc.: 54.69%] [G loss: 0.590194]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "503 [D loss: 1.145344, acc.: 55.47%] [G loss: 0.751963]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "504 [D loss: 0.896904, acc.: 66.41%] [G loss: 0.750095]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "505 [D loss: 1.113172, acc.: 46.88%] [G loss: 0.402866]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "506 [D loss: 0.922359, acc.: 58.59%] [G loss: 0.491271]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "507 [D loss: 0.743816, acc.: 61.72%] [G loss: 0.870083]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "508 [D loss: 1.302540, acc.: 50.78%] [G loss: 0.387903]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "509 [D loss: 1.530450, acc.: 53.12%] [G loss: 0.508089]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "510 [D loss: 0.809654, acc.: 62.50%] [G loss: 1.034256]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "511 [D loss: 1.726195, acc.: 47.66%] [G loss: 0.655345]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "512 [D loss: 0.771527, acc.: 58.59%] [G loss: 0.778601]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "513 [D loss: 1.259859, acc.: 55.47%] [G loss: 0.778506]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "514 [D loss: 1.181280, acc.: 53.12%] [G loss: 0.808502]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "515 [D loss: 1.344780, acc.: 52.34%] [G loss: 0.626503]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "516 [D loss: 1.107985, acc.: 52.34%] [G loss: 0.512094]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "517 [D loss: 1.583924, acc.: 50.00%] [G loss: 0.494681]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "518 [D loss: 0.803625, acc.: 61.72%] [G loss: 0.792827]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "519 [D loss: 0.931536, acc.: 57.81%] [G loss: 0.632713]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "520 [D loss: 1.464316, acc.: 47.66%] [G loss: 0.359512]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "521 [D loss: 1.154045, acc.: 55.47%] [G loss: 0.726148]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "522 [D loss: 1.537487, acc.: 51.56%] [G loss: 0.602228]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "523 [D loss: 1.461694, acc.: 50.78%] [G loss: 0.582710]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "524 [D loss: 1.112775, acc.: 60.16%] [G loss: 0.783877]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "525 [D loss: 1.628365, acc.: 57.03%] [G loss: 0.571840]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "526 [D loss: 1.141715, acc.: 57.03%] [G loss: 0.884626]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "527 [D loss: 0.797502, acc.: 64.06%] [G loss: 1.215933]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "528 [D loss: 0.800353, acc.: 66.41%] [G loss: 0.921176]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "529 [D loss: 1.063953, acc.: 57.03%] [G loss: 0.627801]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "530 [D loss: 0.717807, acc.: 64.06%] [G loss: 0.953308]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "531 [D loss: 1.467973, acc.: 53.91%] [G loss: 0.768625]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "532 [D loss: 0.979243, acc.: 61.72%] [G loss: 1.023520]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "533 [D loss: 0.877188, acc.: 62.50%] [G loss: 1.209775]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "534 [D loss: 0.741793, acc.: 65.62%] [G loss: 1.243109]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "535 [D loss: 1.946797, acc.: 46.09%] [G loss: 0.361388]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "536 [D loss: 0.834131, acc.: 56.25%] [G loss: 0.668185]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "537 [D loss: 0.560195, acc.: 71.88%] [G loss: 1.118019]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "538 [D loss: 1.269978, acc.: 53.91%] [G loss: 0.718217]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "539 [D loss: 0.941799, acc.: 58.59%] [G loss: 0.736522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "540 [D loss: 0.954200, acc.: 60.16%] [G loss: 0.731388]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "541 [D loss: 0.810156, acc.: 60.94%] [G loss: 0.854209]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "542 [D loss: 1.221418, acc.: 61.72%] [G loss: 0.802402]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "543 [D loss: 1.530594, acc.: 46.88%] [G loss: 0.597327]\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "544 [D loss: 1.196481, acc.: 53.12%] [G loss: 0.689336]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "545 [D loss: 0.825580, acc.: 58.59%] [G loss: 0.858167]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "546 [D loss: 0.934781, acc.: 59.38%] [G loss: 0.777343]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "547 [D loss: 0.979106, acc.: 64.06%] [G loss: 0.861986]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "548 [D loss: 1.080099, acc.: 53.91%] [G loss: 0.603718]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "549 [D loss: 0.773524, acc.: 66.41%] [G loss: 0.993723]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "550 [D loss: 1.139561, acc.: 57.81%] [G loss: 0.621305]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "551 [D loss: 0.685863, acc.: 62.50%] [G loss: 0.931231]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "552 [D loss: 0.769449, acc.: 69.53%] [G loss: 1.203948]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "553 [D loss: 0.682269, acc.: 74.22%] [G loss: 1.096456]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "554 [D loss: 0.827850, acc.: 77.34%] [G loss: 1.198153]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "555 [D loss: 1.779583, acc.: 42.19%] [G loss: 0.298810]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "556 [D loss: 1.092327, acc.: 53.91%] [G loss: 0.492837]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "557 [D loss: 0.928680, acc.: 60.16%] [G loss: 1.046685]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "558 [D loss: 0.960306, acc.: 55.47%] [G loss: 0.809960]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "559 [D loss: 0.754209, acc.: 65.62%] [G loss: 0.854734]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "560 [D loss: 1.255009, acc.: 56.25%] [G loss: 0.631534]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "561 [D loss: 0.584231, acc.: 62.50%] [G loss: 0.924425]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "562 [D loss: 0.592080, acc.: 71.09%] [G loss: 1.079520]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "563 [D loss: 1.115573, acc.: 54.69%] [G loss: 0.601624]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "564 [D loss: 0.681164, acc.: 59.38%] [G loss: 1.017866]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "565 [D loss: 0.981183, acc.: 48.44%] [G loss: 0.553847]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "566 [D loss: 0.663368, acc.: 67.19%] [G loss: 0.917121]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "567 [D loss: 0.678607, acc.: 71.88%] [G loss: 1.178824]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "568 [D loss: 1.228349, acc.: 53.12%] [G loss: 0.556703]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "569 [D loss: 1.080707, acc.: 53.12%] [G loss: 0.536639]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "570 [D loss: 1.118512, acc.: 56.25%] [G loss: 0.860806]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "571 [D loss: 0.534398, acc.: 78.12%] [G loss: 1.116311]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "572 [D loss: 0.923960, acc.: 56.25%] [G loss: 0.542020]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "573 [D loss: 0.576137, acc.: 66.41%] [G loss: 0.890198]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "574 [D loss: 0.625137, acc.: 70.31%] [G loss: 0.828562]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "575 [D loss: 0.626724, acc.: 64.06%] [G loss: 1.152291]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "576 [D loss: 0.614240, acc.: 71.09%] [G loss: 1.029207]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "577 [D loss: 1.126192, acc.: 58.59%] [G loss: 0.676762]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "578 [D loss: 0.577313, acc.: 62.50%] [G loss: 0.929694]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "579 [D loss: 0.558974, acc.: 75.00%] [G loss: 1.264618]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "580 [D loss: 1.090988, acc.: 57.03%] [G loss: 0.482310]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "581 [D loss: 1.004235, acc.: 50.78%] [G loss: 0.568471]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "582 [D loss: 0.683346, acc.: 64.06%] [G loss: 0.937546]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "583 [D loss: 0.885035, acc.: 63.28%] [G loss: 0.785587]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "584 [D loss: 0.800739, acc.: 60.94%] [G loss: 0.892830]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "585 [D loss: 0.994615, acc.: 52.34%] [G loss: 0.734252]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "586 [D loss: 0.828581, acc.: 61.72%] [G loss: 0.796114]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "587 [D loss: 0.748838, acc.: 58.59%] [G loss: 0.809886]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "588 [D loss: 0.746657, acc.: 62.50%] [G loss: 0.886071]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "589 [D loss: 0.571359, acc.: 71.09%] [G loss: 1.001957]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "590 [D loss: 0.868945, acc.: 66.41%] [G loss: 0.781127]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "591 [D loss: 0.727561, acc.: 64.84%] [G loss: 0.774787]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "592 [D loss: 1.051717, acc.: 51.56%] [G loss: 0.514802]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "593 [D loss: 0.831129, acc.: 55.47%] [G loss: 0.787024]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "594 [D loss: 0.615881, acc.: 75.00%] [G loss: 1.069717]\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "595 [D loss: 0.984646, acc.: 57.81%] [G loss: 0.779979]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "596 [D loss: 0.927774, acc.: 58.59%] [G loss: 0.864457]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "597 [D loss: 0.934345, acc.: 60.16%] [G loss: 0.718466]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "598 [D loss: 0.857394, acc.: 65.62%] [G loss: 0.918407]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "599 [D loss: 0.845759, acc.: 64.84%] [G loss: 0.920122]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "600 [D loss: 0.953022, acc.: 64.84%] [G loss: 0.839473]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "601 [D loss: 0.889090, acc.: 56.25%] [G loss: 0.892606]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "602 [D loss: 0.690010, acc.: 64.06%] [G loss: 1.116880]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "603 [D loss: 0.645180, acc.: 72.66%] [G loss: 1.295617]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "604 [D loss: 1.322303, acc.: 57.81%] [G loss: 0.777090]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "605 [D loss: 0.683280, acc.: 64.84%] [G loss: 1.003982]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "606 [D loss: 0.709095, acc.: 66.41%] [G loss: 0.958982]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "607 [D loss: 0.883299, acc.: 66.41%] [G loss: 0.985314]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "608 [D loss: 0.762582, acc.: 62.50%] [G loss: 1.011214]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "609 [D loss: 0.623520, acc.: 71.88%] [G loss: 1.255796]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "610 [D loss: 0.689071, acc.: 67.97%] [G loss: 0.969438]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "611 [D loss: 0.957518, acc.: 62.50%] [G loss: 0.769026]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "612 [D loss: 1.332700, acc.: 51.56%] [G loss: 0.450359]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "613 [D loss: 0.963306, acc.: 57.03%] [G loss: 1.020112]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "614 [D loss: 0.736717, acc.: 75.78%] [G loss: 1.302704]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "615 [D loss: 1.108913, acc.: 62.50%] [G loss: 0.791921]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "616 [D loss: 0.577979, acc.: 75.78%] [G loss: 0.966822]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "617 [D loss: 0.804657, acc.: 67.19%] [G loss: 0.886809]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "618 [D loss: 0.836375, acc.: 60.16%] [G loss: 0.653473]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "619 [D loss: 0.698921, acc.: 67.19%] [G loss: 0.997529]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "620 [D loss: 0.958493, acc.: 59.38%] [G loss: 0.817190]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "621 [D loss: 0.713283, acc.: 65.62%] [G loss: 0.806452]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "622 [D loss: 0.730282, acc.: 64.06%] [G loss: 0.994390]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "623 [D loss: 0.491968, acc.: 80.47%] [G loss: 1.350067]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "624 [D loss: 0.914516, acc.: 65.62%] [G loss: 0.933868]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "625 [D loss: 0.633780, acc.: 74.22%] [G loss: 1.156748]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "626 [D loss: 0.528140, acc.: 73.44%] [G loss: 1.117379]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "627 [D loss: 0.624835, acc.: 67.97%] [G loss: 1.207731]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "628 [D loss: 0.632900, acc.: 73.44%] [G loss: 1.151242]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "629 [D loss: 1.239217, acc.: 58.59%] [G loss: 0.801552]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "630 [D loss: 0.896517, acc.: 62.50%] [G loss: 0.910311]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "631 [D loss: 0.593354, acc.: 71.88%] [G loss: 1.166083]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "632 [D loss: 0.523715, acc.: 75.00%] [G loss: 1.244023]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "633 [D loss: 0.791428, acc.: 59.38%] [G loss: 0.940719]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "634 [D loss: 1.111175, acc.: 57.81%] [G loss: 1.112082]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "635 [D loss: 0.893168, acc.: 67.19%] [G loss: 0.731811]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "636 [D loss: 0.705254, acc.: 67.19%] [G loss: 1.009206]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "637 [D loss: 0.659169, acc.: 66.41%] [G loss: 0.939054]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "638 [D loss: 0.620787, acc.: 65.62%] [G loss: 0.908018]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "639 [D loss: 0.695924, acc.: 71.88%] [G loss: 1.153278]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "640 [D loss: 0.974391, acc.: 59.38%] [G loss: 0.738640]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "641 [D loss: 0.743577, acc.: 67.19%] [G loss: 1.022166]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "642 [D loss: 0.733135, acc.: 68.75%] [G loss: 0.982126]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "643 [D loss: 0.892712, acc.: 60.94%] [G loss: 0.736637]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "644 [D loss: 0.797033, acc.: 65.62%] [G loss: 0.981438]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "645 [D loss: 0.934618, acc.: 61.72%] [G loss: 0.977186]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "646 [D loss: 0.895134, acc.: 58.59%] [G loss: 0.836800]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "647 [D loss: 0.853534, acc.: 64.84%] [G loss: 1.040774]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "648 [D loss: 1.297704, acc.: 57.81%] [G loss: 0.907876]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "649 [D loss: 0.643199, acc.: 62.50%] [G loss: 0.942341]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "650 [D loss: 1.155088, acc.: 53.91%] [G loss: 0.728234]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "651 [D loss: 0.930300, acc.: 60.94%] [G loss: 0.873139]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "652 [D loss: 0.775668, acc.: 62.50%] [G loss: 1.127948]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "653 [D loss: 0.987493, acc.: 61.72%] [G loss: 0.997395]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "654 [D loss: 1.093246, acc.: 49.22%] [G loss: 0.508719]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "655 [D loss: 0.518362, acc.: 70.31%] [G loss: 1.226487]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "656 [D loss: 0.623172, acc.: 78.91%] [G loss: 1.437238]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "657 [D loss: 0.942348, acc.: 67.19%] [G loss: 0.815188]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "658 [D loss: 0.626015, acc.: 66.41%] [G loss: 1.178481]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "659 [D loss: 0.437059, acc.: 77.34%] [G loss: 1.496774]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "660 [D loss: 0.541565, acc.: 81.25%] [G loss: 1.317989]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "661 [D loss: 0.476098, acc.: 79.69%] [G loss: 1.179502]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "662 [D loss: 0.588554, acc.: 73.44%] [G loss: 1.181802]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "663 [D loss: 0.633192, acc.: 72.66%] [G loss: 1.259029]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "664 [D loss: 0.559412, acc.: 82.03%] [G loss: 1.328527]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "665 [D loss: 0.547306, acc.: 78.91%] [G loss: 1.399366]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "666 [D loss: 0.343946, acc.: 83.59%] [G loss: 1.592285]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "667 [D loss: 1.432969, acc.: 66.41%] [G loss: 0.778604]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "668 [D loss: 0.775627, acc.: 58.59%] [G loss: 0.876755]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "669 [D loss: 0.877882, acc.: 58.59%] [G loss: 0.834993]\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "670 [D loss: 0.510810, acc.: 74.22%] [G loss: 1.212134]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "671 [D loss: 0.885554, acc.: 53.12%] [G loss: 0.696039]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "672 [D loss: 0.939083, acc.: 61.72%] [G loss: 0.739040]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "673 [D loss: 1.010796, acc.: 62.50%] [G loss: 0.779930]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "674 [D loss: 0.516430, acc.: 73.44%] [G loss: 0.954485]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "675 [D loss: 0.835126, acc.: 62.50%] [G loss: 1.049524]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "676 [D loss: 0.543821, acc.: 69.53%] [G loss: 1.020813]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "677 [D loss: 1.006749, acc.: 63.28%] [G loss: 1.158802]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "678 [D loss: 0.669026, acc.: 67.19%] [G loss: 0.720800]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "679 [D loss: 1.257890, acc.: 49.22%] [G loss: 0.666976]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "680 [D loss: 0.642784, acc.: 61.72%] [G loss: 0.995777]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "681 [D loss: 0.783022, acc.: 67.97%] [G loss: 0.903399]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "682 [D loss: 0.792180, acc.: 65.62%] [G loss: 0.832507]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "683 [D loss: 0.751936, acc.: 57.81%] [G loss: 0.744575]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "684 [D loss: 0.649781, acc.: 71.88%] [G loss: 1.113323]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "685 [D loss: 0.637541, acc.: 67.19%] [G loss: 1.189188]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "686 [D loss: 0.593443, acc.: 67.19%] [G loss: 1.069897]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "687 [D loss: 0.814406, acc.: 60.94%] [G loss: 0.829386]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "688 [D loss: 0.578506, acc.: 69.53%] [G loss: 0.768248]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "689 [D loss: 0.795890, acc.: 56.25%] [G loss: 0.783537]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "690 [D loss: 0.786802, acc.: 60.16%] [G loss: 0.917400]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "691 [D loss: 0.535482, acc.: 72.66%] [G loss: 1.154532]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "692 [D loss: 0.533962, acc.: 71.88%] [G loss: 0.992812]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "693 [D loss: 0.831185, acc.: 60.94%] [G loss: 0.822346]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "694 [D loss: 0.573780, acc.: 69.53%] [G loss: 1.271802]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "695 [D loss: 0.935103, acc.: 54.69%] [G loss: 0.644004]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "696 [D loss: 0.728800, acc.: 64.06%] [G loss: 0.874241]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "697 [D loss: 0.379325, acc.: 81.25%] [G loss: 1.475057]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "698 [D loss: 0.736133, acc.: 72.66%] [G loss: 0.864477]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "699 [D loss: 0.817709, acc.: 62.50%] [G loss: 0.649498]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "700 [D loss: 0.781694, acc.: 63.28%] [G loss: 1.093558]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "701 [D loss: 0.490459, acc.: 75.78%] [G loss: 1.217428]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "702 [D loss: 0.793002, acc.: 65.62%] [G loss: 0.828247]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "703 [D loss: 0.689612, acc.: 61.72%] [G loss: 0.927160]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "704 [D loss: 0.587047, acc.: 70.31%] [G loss: 1.208781]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "705 [D loss: 0.598778, acc.: 75.00%] [G loss: 0.890879]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "706 [D loss: 0.556040, acc.: 71.09%] [G loss: 1.032506]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "707 [D loss: 0.824997, acc.: 55.47%] [G loss: 0.873803]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "708 [D loss: 0.722207, acc.: 57.81%] [G loss: 0.717937]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "709 [D loss: 0.490661, acc.: 73.44%] [G loss: 1.272342]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "710 [D loss: 0.813278, acc.: 60.94%] [G loss: 0.694422]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "711 [D loss: 0.602934, acc.: 66.41%] [G loss: 0.943853]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "712 [D loss: 0.733450, acc.: 65.62%] [G loss: 1.047654]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "713 [D loss: 0.736088, acc.: 64.84%] [G loss: 0.828334]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "714 [D loss: 0.641769, acc.: 71.09%] [G loss: 1.064259]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "715 [D loss: 0.952757, acc.: 54.69%] [G loss: 0.770996]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "716 [D loss: 0.505042, acc.: 71.09%] [G loss: 1.321095]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "717 [D loss: 0.777536, acc.: 64.06%] [G loss: 0.655729]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "718 [D loss: 0.608520, acc.: 70.31%] [G loss: 1.295133]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "719 [D loss: 0.608226, acc.: 72.66%] [G loss: 1.165294]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "720 [D loss: 0.756794, acc.: 66.41%] [G loss: 0.994930]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "721 [D loss: 1.111317, acc.: 50.78%] [G loss: 0.807051]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "722 [D loss: 0.477468, acc.: 75.78%] [G loss: 1.186589]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "723 [D loss: 1.048417, acc.: 60.16%] [G loss: 0.834404]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "724 [D loss: 0.728495, acc.: 60.16%] [G loss: 0.782480]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "725 [D loss: 0.629389, acc.: 62.50%] [G loss: 0.964961]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "726 [D loss: 0.741966, acc.: 66.41%] [G loss: 0.916751]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "727 [D loss: 0.575391, acc.: 75.78%] [G loss: 1.164802]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "728 [D loss: 0.779507, acc.: 62.50%] [G loss: 1.079909]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "729 [D loss: 0.523138, acc.: 77.34%] [G loss: 0.890363]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "730 [D loss: 0.500238, acc.: 71.09%] [G loss: 1.002247]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "731 [D loss: 0.499784, acc.: 71.88%] [G loss: 1.070032]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "732 [D loss: 0.618465, acc.: 71.09%] [G loss: 1.062292]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "733 [D loss: 0.676070, acc.: 64.06%] [G loss: 1.020767]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "734 [D loss: 0.699381, acc.: 62.50%] [G loss: 0.832427]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "735 [D loss: 0.569692, acc.: 65.62%] [G loss: 1.131774]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "736 [D loss: 0.566997, acc.: 75.00%] [G loss: 1.024030]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "737 [D loss: 0.935479, acc.: 56.25%] [G loss: 0.755374]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "738 [D loss: 0.771202, acc.: 60.16%] [G loss: 1.029851]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "739 [D loss: 0.562097, acc.: 74.22%] [G loss: 0.937478]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "740 [D loss: 0.655465, acc.: 61.72%] [G loss: 1.254984]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "741 [D loss: 0.586971, acc.: 76.56%] [G loss: 1.248654]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "742 [D loss: 0.975537, acc.: 57.03%] [G loss: 0.853549]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "743 [D loss: 0.954837, acc.: 60.94%] [G loss: 0.699647]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "744 [D loss: 0.504641, acc.: 81.25%] [G loss: 1.375526]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "745 [D loss: 0.674620, acc.: 73.44%] [G loss: 1.102788]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "746 [D loss: 0.513977, acc.: 74.22%] [G loss: 0.952386]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "747 [D loss: 0.419593, acc.: 78.91%] [G loss: 1.524996]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "748 [D loss: 0.582389, acc.: 75.00%] [G loss: 1.104281]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "749 [D loss: 0.595470, acc.: 73.44%] [G loss: 1.248484]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "750 [D loss: 0.467449, acc.: 79.69%] [G loss: 1.293850]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "751 [D loss: 0.550058, acc.: 73.44%] [G loss: 1.258928]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "752 [D loss: 0.535150, acc.: 79.69%] [G loss: 1.291904]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "753 [D loss: 0.921331, acc.: 60.16%] [G loss: 0.872461]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "754 [D loss: 0.686872, acc.: 64.06%] [G loss: 1.098012]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "755 [D loss: 0.419193, acc.: 76.56%] [G loss: 1.063284]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "756 [D loss: 0.559405, acc.: 71.88%] [G loss: 1.017705]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "757 [D loss: 0.413890, acc.: 76.56%] [G loss: 1.202467]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "758 [D loss: 0.463919, acc.: 85.16%] [G loss: 1.211362]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "759 [D loss: 0.474277, acc.: 76.56%] [G loss: 1.226231]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "760 [D loss: 0.648698, acc.: 77.34%] [G loss: 1.100810]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "761 [D loss: 1.002916, acc.: 53.12%] [G loss: 0.761552]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "762 [D loss: 0.484221, acc.: 72.66%] [G loss: 1.166125]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "763 [D loss: 0.546100, acc.: 71.88%] [G loss: 1.129755]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "764 [D loss: 0.431146, acc.: 75.78%] [G loss: 1.122807]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "765 [D loss: 0.623834, acc.: 74.22%] [G loss: 1.150367]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "766 [D loss: 0.561870, acc.: 78.91%] [G loss: 1.341267]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "767 [D loss: 0.823254, acc.: 60.16%] [G loss: 0.852647]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "768 [D loss: 0.472273, acc.: 74.22%] [G loss: 1.280129]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "769 [D loss: 0.946749, acc.: 58.59%] [G loss: 0.850725]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "770 [D loss: 0.542464, acc.: 74.22%] [G loss: 1.210063]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "771 [D loss: 0.716273, acc.: 63.28%] [G loss: 0.926613]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "772 [D loss: 0.661516, acc.: 71.88%] [G loss: 0.832285]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "773 [D loss: 0.801192, acc.: 60.94%] [G loss: 0.761447]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "774 [D loss: 0.764375, acc.: 65.62%] [G loss: 0.952135]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "775 [D loss: 0.534288, acc.: 71.09%] [G loss: 1.064086]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "776 [D loss: 0.807794, acc.: 57.81%] [G loss: 0.945047]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "777 [D loss: 0.534381, acc.: 70.31%] [G loss: 1.207884]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "778 [D loss: 0.385901, acc.: 80.47%] [G loss: 1.263597]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "779 [D loss: 0.975941, acc.: 53.12%] [G loss: 0.790620]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "780 [D loss: 0.556677, acc.: 71.88%] [G loss: 1.199287]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "781 [D loss: 0.585663, acc.: 72.66%] [G loss: 1.023887]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "782 [D loss: 0.678048, acc.: 64.06%] [G loss: 0.916590]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "783 [D loss: 0.576936, acc.: 67.97%] [G loss: 1.162032]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "784 [D loss: 0.731693, acc.: 61.72%] [G loss: 0.830725]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "785 [D loss: 0.652251, acc.: 75.78%] [G loss: 1.222646]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "786 [D loss: 0.755926, acc.: 57.81%] [G loss: 0.893691]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "787 [D loss: 0.542477, acc.: 71.09%] [G loss: 1.171495]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "788 [D loss: 0.701927, acc.: 64.06%] [G loss: 0.886096]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "789 [D loss: 0.586923, acc.: 65.62%] [G loss: 1.084667]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "790 [D loss: 0.496378, acc.: 75.00%] [G loss: 1.305517]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "791 [D loss: 0.667974, acc.: 68.75%] [G loss: 1.169217]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "792 [D loss: 0.581711, acc.: 73.44%] [G loss: 1.152427]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "793 [D loss: 0.681949, acc.: 67.19%] [G loss: 1.066187]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "794 [D loss: 0.734900, acc.: 64.06%] [G loss: 1.049044]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "795 [D loss: 0.601484, acc.: 66.41%] [G loss: 1.140838]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "796 [D loss: 0.581836, acc.: 71.09%] [G loss: 1.108020]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "797 [D loss: 0.923453, acc.: 57.81%] [G loss: 0.786229]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "798 [D loss: 0.995402, acc.: 54.69%] [G loss: 0.901876]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "799 [D loss: 0.479180, acc.: 75.00%] [G loss: 1.368697]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "800 [D loss: 0.734323, acc.: 64.06%] [G loss: 0.997784]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "801 [D loss: 0.544437, acc.: 71.88%] [G loss: 1.113725]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "802 [D loss: 0.727365, acc.: 63.28%] [G loss: 0.959954]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "803 [D loss: 0.652778, acc.: 63.28%] [G loss: 1.057328]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "804 [D loss: 0.392647, acc.: 77.34%] [G loss: 1.431495]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "805 [D loss: 0.829006, acc.: 69.53%] [G loss: 1.019434]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "806 [D loss: 0.482039, acc.: 81.25%] [G loss: 1.362509]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "807 [D loss: 0.534293, acc.: 75.00%] [G loss: 1.296990]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "808 [D loss: 0.689198, acc.: 64.06%] [G loss: 1.068124]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "809 [D loss: 0.818162, acc.: 60.16%] [G loss: 0.992786]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "810 [D loss: 0.613514, acc.: 67.97%] [G loss: 1.008807]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "811 [D loss: 0.514443, acc.: 76.56%] [G loss: 1.460970]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "812 [D loss: 0.937469, acc.: 67.19%] [G loss: 0.948344]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "813 [D loss: 0.838905, acc.: 65.62%] [G loss: 1.020189]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "814 [D loss: 0.513802, acc.: 78.91%] [G loss: 1.536957]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "815 [D loss: 0.485050, acc.: 82.03%] [G loss: 1.339380]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "816 [D loss: 0.774162, acc.: 66.41%] [G loss: 0.861359]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "817 [D loss: 0.523652, acc.: 75.00%] [G loss: 1.136249]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "818 [D loss: 0.590001, acc.: 71.88%] [G loss: 1.100760]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "819 [D loss: 0.589538, acc.: 66.41%] [G loss: 1.106059]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "820 [D loss: 0.527907, acc.: 78.12%] [G loss: 0.985998]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "821 [D loss: 0.394885, acc.: 79.69%] [G loss: 1.441336]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "822 [D loss: 0.672838, acc.: 75.78%] [G loss: 1.133411]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "823 [D loss: 0.508868, acc.: 83.59%] [G loss: 1.464139]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "824 [D loss: 0.526245, acc.: 82.03%] [G loss: 1.060338]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "825 [D loss: 0.664267, acc.: 64.06%] [G loss: 1.079593]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "826 [D loss: 0.396944, acc.: 83.59%] [G loss: 1.323284]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "827 [D loss: 0.361752, acc.: 84.38%] [G loss: 1.645140]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "828 [D loss: 0.564760, acc.: 84.38%] [G loss: 1.076373]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "829 [D loss: 0.351093, acc.: 85.16%] [G loss: 1.202925]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "830 [D loss: 0.517543, acc.: 73.44%] [G loss: 1.154040]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "831 [D loss: 0.474182, acc.: 77.34%] [G loss: 1.312431]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "832 [D loss: 0.492883, acc.: 82.81%] [G loss: 1.205818]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "833 [D loss: 0.627369, acc.: 80.47%] [G loss: 1.236239]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "834 [D loss: 0.516405, acc.: 75.78%] [G loss: 1.034079]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "835 [D loss: 0.461480, acc.: 81.25%] [G loss: 1.508056]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "836 [D loss: 0.851387, acc.: 63.28%] [G loss: 0.912035]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "837 [D loss: 0.482340, acc.: 71.88%] [G loss: 1.348471]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "838 [D loss: 0.445937, acc.: 78.12%] [G loss: 1.285876]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "839 [D loss: 0.585824, acc.: 76.56%] [G loss: 1.103806]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "840 [D loss: 0.874185, acc.: 73.44%] [G loss: 1.127068]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "841 [D loss: 0.449038, acc.: 78.12%] [G loss: 1.190365]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "842 [D loss: 0.560181, acc.: 78.91%] [G loss: 1.102048]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "843 [D loss: 0.618332, acc.: 74.22%] [G loss: 1.127182]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "844 [D loss: 0.697482, acc.: 71.88%] [G loss: 1.197069]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "845 [D loss: 0.437264, acc.: 80.47%] [G loss: 1.270020]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "846 [D loss: 0.954521, acc.: 48.44%] [G loss: 0.714541]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "847 [D loss: 0.973535, acc.: 53.12%] [G loss: 0.932965]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "848 [D loss: 0.417709, acc.: 75.78%] [G loss: 1.373881]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "849 [D loss: 1.012829, acc.: 54.69%] [G loss: 0.802375]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "850 [D loss: 0.502604, acc.: 71.09%] [G loss: 1.328299]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "851 [D loss: 0.548119, acc.: 80.47%] [G loss: 1.387140]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "852 [D loss: 0.876740, acc.: 57.81%] [G loss: 0.936214]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "853 [D loss: 0.469450, acc.: 73.44%] [G loss: 1.380327]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "854 [D loss: 0.424296, acc.: 83.59%] [G loss: 1.455476]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "855 [D loss: 0.798349, acc.: 67.97%] [G loss: 0.971145]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "856 [D loss: 0.611464, acc.: 66.41%] [G loss: 1.015982]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "857 [D loss: 0.528570, acc.: 71.88%] [G loss: 1.352969]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "858 [D loss: 0.716468, acc.: 61.72%] [G loss: 0.928401]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "859 [D loss: 0.477682, acc.: 76.56%] [G loss: 1.021138]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "860 [D loss: 0.551645, acc.: 74.22%] [G loss: 1.185613]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "861 [D loss: 0.459439, acc.: 78.91%] [G loss: 1.201912]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "862 [D loss: 0.629089, acc.: 73.44%] [G loss: 1.305368]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "863 [D loss: 0.559639, acc.: 74.22%] [G loss: 1.326439]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "864 [D loss: 1.001497, acc.: 60.94%] [G loss: 0.864111]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "865 [D loss: 1.252130, acc.: 46.09%] [G loss: 0.736873]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "866 [D loss: 0.433655, acc.: 80.47%] [G loss: 1.463518]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "867 [D loss: 0.680278, acc.: 72.66%] [G loss: 1.116275]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "868 [D loss: 0.698014, acc.: 71.09%] [G loss: 1.133825]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "869 [D loss: 0.715774, acc.: 66.41%] [G loss: 0.992411]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "870 [D loss: 0.501356, acc.: 79.69%] [G loss: 1.358064]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "871 [D loss: 0.921354, acc.: 57.81%] [G loss: 0.978402]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "872 [D loss: 0.533031, acc.: 71.09%] [G loss: 1.251800]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "873 [D loss: 0.565100, acc.: 75.00%] [G loss: 1.105584]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "874 [D loss: 0.594787, acc.: 66.41%] [G loss: 1.107185]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "875 [D loss: 0.594217, acc.: 74.22%] [G loss: 1.266012]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "876 [D loss: 0.726212, acc.: 56.25%] [G loss: 0.998716]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "877 [D loss: 0.452128, acc.: 78.12%] [G loss: 1.441225]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "878 [D loss: 0.592507, acc.: 76.56%] [G loss: 1.310716]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "879 [D loss: 0.624625, acc.: 73.44%] [G loss: 1.017070]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "880 [D loss: 0.432423, acc.: 75.00%] [G loss: 1.205925]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "881 [D loss: 0.444116, acc.: 82.03%] [G loss: 1.547179]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "882 [D loss: 0.849145, acc.: 56.25%] [G loss: 0.779512]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "883 [D loss: 0.533799, acc.: 68.75%] [G loss: 1.219920]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "884 [D loss: 0.404507, acc.: 78.12%] [G loss: 1.228116]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "885 [D loss: 0.781432, acc.: 50.78%] [G loss: 0.657112]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "886 [D loss: 0.724417, acc.: 57.03%] [G loss: 0.965570]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "887 [D loss: 0.556307, acc.: 75.78%] [G loss: 1.261991]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "888 [D loss: 0.624969, acc.: 71.88%] [G loss: 0.850936]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "889 [D loss: 0.676819, acc.: 64.84%] [G loss: 0.995804]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "890 [D loss: 0.648384, acc.: 70.31%] [G loss: 1.169885]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "891 [D loss: 0.487548, acc.: 82.03%] [G loss: 1.224751]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "892 [D loss: 0.791891, acc.: 59.38%] [G loss: 0.963113]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "893 [D loss: 0.450615, acc.: 72.66%] [G loss: 1.279407]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "894 [D loss: 0.554706, acc.: 81.25%] [G loss: 1.253846]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "895 [D loss: 0.526623, acc.: 69.53%] [G loss: 1.053679]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "896 [D loss: 0.410192, acc.: 82.03%] [G loss: 1.342862]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "897 [D loss: 0.370905, acc.: 83.59%] [G loss: 1.366498]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "898 [D loss: 0.644305, acc.: 70.31%] [G loss: 0.977496]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "899 [D loss: 0.380201, acc.: 84.38%] [G loss: 1.225166]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "900 [D loss: 0.543607, acc.: 72.66%] [G loss: 1.224891]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "901 [D loss: 0.568623, acc.: 78.12%] [G loss: 1.246546]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "902 [D loss: 0.330867, acc.: 87.50%] [G loss: 1.303263]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "903 [D loss: 0.525253, acc.: 78.91%] [G loss: 1.135643]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "904 [D loss: 0.347367, acc.: 88.28%] [G loss: 1.591041]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "905 [D loss: 0.715104, acc.: 68.75%] [G loss: 1.013116]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "906 [D loss: 0.520631, acc.: 74.22%] [G loss: 0.882530]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "907 [D loss: 0.717490, acc.: 64.84%] [G loss: 1.330668]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "908 [D loss: 0.455110, acc.: 82.03%] [G loss: 1.270800]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "909 [D loss: 0.657633, acc.: 66.41%] [G loss: 1.046851]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "910 [D loss: 0.562899, acc.: 63.28%] [G loss: 1.284437]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "911 [D loss: 0.487384, acc.: 71.88%] [G loss: 1.239621]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "912 [D loss: 0.431818, acc.: 73.44%] [G loss: 1.105520]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "913 [D loss: 0.630381, acc.: 69.53%] [G loss: 1.405634]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "914 [D loss: 0.658898, acc.: 67.19%] [G loss: 1.220714]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "915 [D loss: 0.445872, acc.: 78.91%] [G loss: 1.418194]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "916 [D loss: 0.708736, acc.: 57.03%] [G loss: 0.904891]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "917 [D loss: 0.742577, acc.: 55.47%] [G loss: 0.983949]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "918 [D loss: 0.587241, acc.: 69.53%] [G loss: 1.105189]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "919 [D loss: 0.512024, acc.: 75.78%] [G loss: 1.324730]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "920 [D loss: 0.497191, acc.: 78.12%] [G loss: 1.451787]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "921 [D loss: 0.853854, acc.: 53.91%] [G loss: 0.836611]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "922 [D loss: 0.592010, acc.: 67.97%] [G loss: 1.202582]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "923 [D loss: 0.487753, acc.: 78.91%] [G loss: 1.350667]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "924 [D loss: 0.817682, acc.: 62.50%] [G loss: 1.019599]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "925 [D loss: 0.548716, acc.: 71.88%] [G loss: 1.302488]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "926 [D loss: 0.589157, acc.: 70.31%] [G loss: 1.225578]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "927 [D loss: 0.836192, acc.: 72.66%] [G loss: 1.042758]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "928 [D loss: 0.378928, acc.: 82.81%] [G loss: 1.392757]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "929 [D loss: 0.671531, acc.: 59.38%] [G loss: 0.883768]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "930 [D loss: 0.643179, acc.: 60.16%] [G loss: 0.925326]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "931 [D loss: 0.342166, acc.: 83.59%] [G loss: 1.418423]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "932 [D loss: 0.685660, acc.: 71.09%] [G loss: 1.242477]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "933 [D loss: 0.619588, acc.: 76.56%] [G loss: 1.424639]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "934 [D loss: 0.590251, acc.: 67.19%] [G loss: 1.039764]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "935 [D loss: 0.503976, acc.: 76.56%] [G loss: 1.365701]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "936 [D loss: 1.246986, acc.: 49.22%] [G loss: 0.717788]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "937 [D loss: 0.531427, acc.: 67.97%] [G loss: 1.189334]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "938 [D loss: 0.685871, acc.: 76.56%] [G loss: 1.196616]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "939 [D loss: 0.619609, acc.: 65.62%] [G loss: 1.114518]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "940 [D loss: 0.653566, acc.: 62.50%] [G loss: 1.217247]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "941 [D loss: 0.618751, acc.: 67.19%] [G loss: 1.248055]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "942 [D loss: 0.520183, acc.: 80.47%] [G loss: 1.472144]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "943 [D loss: 0.367436, acc.: 88.28%] [G loss: 1.640758]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "944 [D loss: 0.600677, acc.: 67.19%] [G loss: 1.021017]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "945 [D loss: 0.640517, acc.: 62.50%] [G loss: 1.191774]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "946 [D loss: 0.316348, acc.: 88.28%] [G loss: 1.654527]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "947 [D loss: 0.827805, acc.: 64.06%] [G loss: 1.046116]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "948 [D loss: 0.358188, acc.: 82.03%] [G loss: 1.253445]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "949 [D loss: 0.503790, acc.: 77.34%] [G loss: 1.270751]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "950 [D loss: 0.653754, acc.: 67.19%] [G loss: 1.200324]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "951 [D loss: 0.601327, acc.: 70.31%] [G loss: 1.105621]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "952 [D loss: 0.607280, acc.: 75.78%] [G loss: 1.287287]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "953 [D loss: 0.441472, acc.: 77.34%] [G loss: 1.557056]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "954 [D loss: 0.690979, acc.: 70.31%] [G loss: 1.312954]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "955 [D loss: 0.575201, acc.: 70.31%] [G loss: 1.165546]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "956 [D loss: 0.473727, acc.: 81.25%] [G loss: 1.308691]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "957 [D loss: 0.457381, acc.: 77.34%] [G loss: 1.464959]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "958 [D loss: 0.752199, acc.: 56.25%] [G loss: 0.832815]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "959 [D loss: 0.576191, acc.: 70.31%] [G loss: 1.453801]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "960 [D loss: 0.620406, acc.: 71.09%] [G loss: 1.110834]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "961 [D loss: 0.783602, acc.: 60.16%] [G loss: 1.412658]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "962 [D loss: 0.711069, acc.: 62.50%] [G loss: 0.877672]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "963 [D loss: 0.714437, acc.: 59.38%] [G loss: 0.970563]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "964 [D loss: 0.417056, acc.: 79.69%] [G loss: 1.629099]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "965 [D loss: 0.823966, acc.: 63.28%] [G loss: 0.980116]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "966 [D loss: 0.560956, acc.: 64.06%] [G loss: 1.094035]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "967 [D loss: 0.421927, acc.: 81.25%] [G loss: 1.336222]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "968 [D loss: 0.771034, acc.: 68.75%] [G loss: 1.183147]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "969 [D loss: 0.515980, acc.: 72.66%] [G loss: 1.244807]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "970 [D loss: 0.397717, acc.: 82.03%] [G loss: 1.408736]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "971 [D loss: 0.416714, acc.: 85.94%] [G loss: 1.350104]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "972 [D loss: 0.514933, acc.: 77.34%] [G loss: 1.116425]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "973 [D loss: 0.443231, acc.: 78.12%] [G loss: 1.339327]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "974 [D loss: 0.462407, acc.: 83.59%] [G loss: 1.350495]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "975 [D loss: 0.297932, acc.: 87.50%] [G loss: 1.399149]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "976 [D loss: 0.672347, acc.: 73.44%] [G loss: 1.289966]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "977 [D loss: 0.454100, acc.: 81.25%] [G loss: 1.430084]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "978 [D loss: 0.437926, acc.: 85.16%] [G loss: 1.797198]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "979 [D loss: 0.736586, acc.: 72.66%] [G loss: 1.005596]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "980 [D loss: 0.426189, acc.: 78.12%] [G loss: 1.361884]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "981 [D loss: 0.717171, acc.: 76.56%] [G loss: 1.300269]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "982 [D loss: 0.466678, acc.: 74.22%] [G loss: 1.415251]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "983 [D loss: 0.339160, acc.: 85.94%] [G loss: 1.784481]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "984 [D loss: 0.772099, acc.: 74.22%] [G loss: 1.088149]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "985 [D loss: 0.868246, acc.: 66.41%] [G loss: 1.332791]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "986 [D loss: 0.508346, acc.: 79.69%] [G loss: 1.519381]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "987 [D loss: 0.552915, acc.: 75.78%] [G loss: 1.405333]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "988 [D loss: 0.775150, acc.: 71.09%] [G loss: 1.398266]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "989 [D loss: 0.861074, acc.: 63.28%] [G loss: 1.070227]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "990 [D loss: 0.480460, acc.: 77.34%] [G loss: 1.252686]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "991 [D loss: 0.476658, acc.: 75.00%] [G loss: 2.313338]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "992 [D loss: 1.494503, acc.: 42.19%] [G loss: 0.639290]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "993 [D loss: 0.514262, acc.: 64.84%] [G loss: 1.275932]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "994 [D loss: 0.413040, acc.: 85.16%] [G loss: 1.414844]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "995 [D loss: 0.653870, acc.: 67.19%] [G loss: 1.109477]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "996 [D loss: 0.690882, acc.: 67.97%] [G loss: 1.260705]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "997 [D loss: 0.453270, acc.: 77.34%] [G loss: 1.437048]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "998 [D loss: 0.502711, acc.: 77.34%] [G loss: 1.179285]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "999 [D loss: 0.568151, acc.: 81.25%] [G loss: 1.481530]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1000 [D loss: 0.598018, acc.: 71.09%] [G loss: 1.261013]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1001 [D loss: 0.440723, acc.: 77.34%] [G loss: 1.401277]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1002 [D loss: 0.438389, acc.: 82.81%] [G loss: 1.188531]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1003 [D loss: 0.456852, acc.: 79.69%] [G loss: 1.381522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1004 [D loss: 0.557197, acc.: 70.31%] [G loss: 1.200150]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1005 [D loss: 0.556671, acc.: 75.00%] [G loss: 1.189908]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1006 [D loss: 0.366870, acc.: 82.03%] [G loss: 1.359004]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1007 [D loss: 0.649619, acc.: 72.66%] [G loss: 1.374699]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1008 [D loss: 0.518056, acc.: 75.00%] [G loss: 1.212478]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1009 [D loss: 0.471734, acc.: 78.91%] [G loss: 1.147673]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1010 [D loss: 0.653315, acc.: 82.81%] [G loss: 1.443872]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1011 [D loss: 0.640348, acc.: 78.12%] [G loss: 1.036806]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1012 [D loss: 0.319209, acc.: 85.94%] [G loss: 1.576789]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1013 [D loss: 0.483327, acc.: 81.25%] [G loss: 1.392609]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1014 [D loss: 0.503190, acc.: 80.47%] [G loss: 1.141800]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1015 [D loss: 0.530478, acc.: 70.31%] [G loss: 1.358395]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1016 [D loss: 0.531529, acc.: 75.00%] [G loss: 1.326683]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1017 [D loss: 0.656974, acc.: 76.56%] [G loss: 1.274390]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1018 [D loss: 0.481266, acc.: 75.78%] [G loss: 1.091060]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1019 [D loss: 0.644056, acc.: 66.41%] [G loss: 1.185912]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1020 [D loss: 0.549434, acc.: 82.81%] [G loss: 1.378668]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1021 [D loss: 0.508945, acc.: 85.94%] [G loss: 1.241354]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1022 [D loss: 0.525210, acc.: 74.22%] [G loss: 1.116968]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1023 [D loss: 0.480069, acc.: 71.88%] [G loss: 1.219769]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1024 [D loss: 0.427006, acc.: 77.34%] [G loss: 1.494688]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1025 [D loss: 0.543288, acc.: 73.44%] [G loss: 1.145189]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1026 [D loss: 0.488286, acc.: 82.03%] [G loss: 1.593371]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1027 [D loss: 0.526175, acc.: 76.56%] [G loss: 1.370480]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1028 [D loss: 0.738349, acc.: 56.25%] [G loss: 1.013146]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1029 [D loss: 0.375943, acc.: 81.25%] [G loss: 1.351220]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1030 [D loss: 0.518981, acc.: 78.91%] [G loss: 1.407163]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1031 [D loss: 0.586514, acc.: 76.56%] [G loss: 1.067086]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1032 [D loss: 0.438753, acc.: 84.38%] [G loss: 1.261946]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1033 [D loss: 0.481655, acc.: 81.25%] [G loss: 1.537518]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1034 [D loss: 0.628111, acc.: 78.91%] [G loss: 1.114550]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1035 [D loss: 0.436146, acc.: 82.81%] [G loss: 1.465431]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1036 [D loss: 0.508977, acc.: 78.91%] [G loss: 1.392265]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1037 [D loss: 0.465486, acc.: 82.81%] [G loss: 1.417747]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1038 [D loss: 0.625871, acc.: 81.25%] [G loss: 1.237898]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1039 [D loss: 0.361441, acc.: 85.16%] [G loss: 1.770516]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1040 [D loss: 0.897135, acc.: 75.78%] [G loss: 1.441984]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1041 [D loss: 0.689749, acc.: 78.91%] [G loss: 1.579604]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1042 [D loss: 0.682382, acc.: 68.75%] [G loss: 1.145577]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1043 [D loss: 0.303480, acc.: 83.59%] [G loss: 1.682891]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1044 [D loss: 0.585968, acc.: 76.56%] [G loss: 1.391083]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1045 [D loss: 0.475677, acc.: 81.25%] [G loss: 1.273941]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1046 [D loss: 0.593829, acc.: 66.41%] [G loss: 1.396538]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1047 [D loss: 0.601887, acc.: 69.53%] [G loss: 1.378094]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1048 [D loss: 0.563896, acc.: 70.31%] [G loss: 1.314727]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1049 [D loss: 0.571090, acc.: 79.69%] [G loss: 1.375454]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1050 [D loss: 0.714670, acc.: 67.19%] [G loss: 1.394602]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1051 [D loss: 0.608961, acc.: 69.53%] [G loss: 1.252133]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1052 [D loss: 0.523682, acc.: 74.22%] [G loss: 1.166285]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1053 [D loss: 0.442601, acc.: 79.69%] [G loss: 1.445941]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1054 [D loss: 0.542363, acc.: 71.09%] [G loss: 1.251714]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1055 [D loss: 0.546515, acc.: 77.34%] [G loss: 1.275182]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1056 [D loss: 0.579604, acc.: 76.56%] [G loss: 1.108753]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1057 [D loss: 0.414748, acc.: 82.03%] [G loss: 1.326651]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1058 [D loss: 0.448988, acc.: 74.22%] [G loss: 1.323022]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1059 [D loss: 0.347631, acc.: 85.16%] [G loss: 1.262084]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1060 [D loss: 0.612499, acc.: 74.22%] [G loss: 1.179574]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1061 [D loss: 0.568741, acc.: 80.47%] [G loss: 1.304415]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1062 [D loss: 0.530902, acc.: 75.00%] [G loss: 1.178857]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1063 [D loss: 0.466926, acc.: 81.25%] [G loss: 1.421014]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1064 [D loss: 0.609794, acc.: 75.78%] [G loss: 1.331687]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1065 [D loss: 0.333571, acc.: 86.72%] [G loss: 1.969650]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1066 [D loss: 0.589457, acc.: 85.16%] [G loss: 1.310293]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1067 [D loss: 0.534541, acc.: 75.78%] [G loss: 1.269282]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1068 [D loss: 0.694143, acc.: 65.62%] [G loss: 1.228340]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1069 [D loss: 0.673119, acc.: 75.00%] [G loss: 1.537518]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1070 [D loss: 0.295925, acc.: 90.62%] [G loss: 1.628547]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1071 [D loss: 0.502724, acc.: 78.91%] [G loss: 1.508167]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1072 [D loss: 0.384690, acc.: 85.16%] [G loss: 1.299696]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1073 [D loss: 0.724037, acc.: 60.16%] [G loss: 1.218338]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1074 [D loss: 0.313570, acc.: 89.84%] [G loss: 1.708849]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1075 [D loss: 0.362855, acc.: 87.50%] [G loss: 1.607440]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1076 [D loss: 0.666759, acc.: 64.06%] [G loss: 0.929154]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1077 [D loss: 0.327243, acc.: 84.38%] [G loss: 1.478243]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1078 [D loss: 0.271423, acc.: 89.84%] [G loss: 1.647111]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1079 [D loss: 0.409223, acc.: 90.62%] [G loss: 1.519443]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1080 [D loss: 0.545718, acc.: 79.69%] [G loss: 1.313495]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1081 [D loss: 0.485837, acc.: 75.78%] [G loss: 1.209319]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1082 [D loss: 0.368066, acc.: 86.72%] [G loss: 1.514987]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1083 [D loss: 0.467526, acc.: 84.38%] [G loss: 1.722188]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1084 [D loss: 0.386089, acc.: 82.81%] [G loss: 1.309850]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1085 [D loss: 0.363983, acc.: 87.50%] [G loss: 1.699973]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1086 [D loss: 0.429537, acc.: 85.16%] [G loss: 1.760511]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1087 [D loss: 0.276573, acc.: 89.84%] [G loss: 1.587044]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1088 [D loss: 0.317221, acc.: 90.62%] [G loss: 1.876129]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1089 [D loss: 0.384912, acc.: 84.38%] [G loss: 1.667924]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1090 [D loss: 0.481043, acc.: 89.06%] [G loss: 1.395793]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1091 [D loss: 0.422180, acc.: 83.59%] [G loss: 1.544577]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1092 [D loss: 0.353967, acc.: 92.19%] [G loss: 1.769619]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1093 [D loss: 0.343533, acc.: 86.72%] [G loss: 1.744731]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1094 [D loss: 0.492227, acc.: 85.16%] [G loss: 1.844339]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1095 [D loss: 0.336382, acc.: 89.06%] [G loss: 1.773857]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1096 [D loss: 0.362895, acc.: 85.94%] [G loss: 1.726722]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1097 [D loss: 0.338598, acc.: 88.28%] [G loss: 1.726689]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1098 [D loss: 0.489234, acc.: 84.38%] [G loss: 1.619961]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1099 [D loss: 0.342663, acc.: 89.06%] [G loss: 1.571293]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1100 [D loss: 0.494959, acc.: 84.38%] [G loss: 1.508095]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1101 [D loss: 0.355107, acc.: 85.94%] [G loss: 1.852668]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1102 [D loss: 0.451473, acc.: 87.50%] [G loss: 1.813094]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1103 [D loss: 0.278867, acc.: 91.41%] [G loss: 1.829604]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1104 [D loss: 0.340768, acc.: 92.19%] [G loss: 1.736766]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1105 [D loss: 0.400020, acc.: 85.16%] [G loss: 1.740266]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1106 [D loss: 0.298106, acc.: 92.19%] [G loss: 1.951412]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1107 [D loss: 0.339140, acc.: 91.41%] [G loss: 2.030156]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1108 [D loss: 0.425868, acc.: 90.62%] [G loss: 1.964252]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1109 [D loss: 0.388106, acc.: 87.50%] [G loss: 1.598484]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1110 [D loss: 0.346974, acc.: 93.75%] [G loss: 1.758829]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1111 [D loss: 0.393875, acc.: 84.38%] [G loss: 1.632016]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1112 [D loss: 0.197919, acc.: 95.31%] [G loss: 1.813840]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1113 [D loss: 0.233360, acc.: 94.53%] [G loss: 1.999049]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1114 [D loss: 0.503102, acc.: 90.62%] [G loss: 1.553080]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1115 [D loss: 0.372870, acc.: 87.50%] [G loss: 1.761499]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1116 [D loss: 0.273470, acc.: 94.53%] [G loss: 1.790197]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1117 [D loss: 0.402204, acc.: 90.62%] [G loss: 1.672306]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1118 [D loss: 0.278932, acc.: 92.97%] [G loss: 1.882146]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1119 [D loss: 0.383520, acc.: 90.62%] [G loss: 1.532556]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1120 [D loss: 0.289888, acc.: 86.72%] [G loss: 1.595821]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1121 [D loss: 0.672930, acc.: 79.69%] [G loss: 1.330261]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1122 [D loss: 0.353109, acc.: 86.72%] [G loss: 1.656957]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1123 [D loss: 0.375590, acc.: 90.62%] [G loss: 1.579810]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1124 [D loss: 0.551148, acc.: 84.38%] [G loss: 1.531599]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1125 [D loss: 0.472247, acc.: 78.91%] [G loss: 1.412595]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1126 [D loss: 0.415499, acc.: 84.38%] [G loss: 1.450921]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1127 [D loss: 0.481850, acc.: 82.03%] [G loss: 1.458929]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1128 [D loss: 0.640595, acc.: 72.66%] [G loss: 1.577493]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1129 [D loss: 0.658063, acc.: 71.88%] [G loss: 1.211661]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1130 [D loss: 0.482521, acc.: 76.56%] [G loss: 1.217800]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1131 [D loss: 0.478573, acc.: 80.47%] [G loss: 1.213364]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1132 [D loss: 0.444592, acc.: 78.91%] [G loss: 1.351533]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1133 [D loss: 0.403998, acc.: 83.59%] [G loss: 1.465067]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1134 [D loss: 0.704705, acc.: 63.28%] [G loss: 0.890599]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1135 [D loss: 0.632384, acc.: 64.06%] [G loss: 1.023780]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1136 [D loss: 0.502813, acc.: 79.69%] [G loss: 1.534350]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1137 [D loss: 0.859089, acc.: 59.38%] [G loss: 0.963333]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1138 [D loss: 0.577323, acc.: 65.62%] [G loss: 1.126488]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1139 [D loss: 0.512935, acc.: 69.53%] [G loss: 1.146954]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1140 [D loss: 0.358433, acc.: 85.16%] [G loss: 1.393977]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1141 [D loss: 0.734299, acc.: 64.06%] [G loss: 0.948369]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1142 [D loss: 0.335074, acc.: 84.38%] [G loss: 1.509704]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1143 [D loss: 0.574495, acc.: 71.88%] [G loss: 0.978726]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1144 [D loss: 0.432616, acc.: 82.81%] [G loss: 1.370174]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1145 [D loss: 0.367760, acc.: 87.50%] [G loss: 1.569489]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1146 [D loss: 0.542142, acc.: 73.44%] [G loss: 1.086190]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1147 [D loss: 0.398945, acc.: 79.69%] [G loss: 1.108417]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1148 [D loss: 0.646593, acc.: 67.97%] [G loss: 1.216407]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1149 [D loss: 0.386179, acc.: 85.16%] [G loss: 1.587473]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1150 [D loss: 0.545333, acc.: 74.22%] [G loss: 0.961451]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1151 [D loss: 0.469753, acc.: 72.66%] [G loss: 1.270760]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1152 [D loss: 0.319541, acc.: 90.62%] [G loss: 1.498021]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1153 [D loss: 0.415149, acc.: 87.50%] [G loss: 1.364833]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1154 [D loss: 0.419457, acc.: 85.16%] [G loss: 1.164172]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1155 [D loss: 0.473679, acc.: 79.69%] [G loss: 1.251332]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1156 [D loss: 0.465218, acc.: 79.69%] [G loss: 1.163751]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1157 [D loss: 0.374581, acc.: 85.94%] [G loss: 1.329676]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1158 [D loss: 0.548384, acc.: 73.44%] [G loss: 1.093542]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1159 [D loss: 0.465866, acc.: 75.78%] [G loss: 1.233403]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1160 [D loss: 0.547823, acc.: 78.12%] [G loss: 1.190671]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1161 [D loss: 0.425633, acc.: 81.25%] [G loss: 1.226180]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1162 [D loss: 0.387412, acc.: 89.84%] [G loss: 1.337281]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1163 [D loss: 0.368946, acc.: 85.16%] [G loss: 1.333100]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1164 [D loss: 0.498597, acc.: 86.72%] [G loss: 1.161305]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1165 [D loss: 0.442742, acc.: 84.38%] [G loss: 1.190459]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1166 [D loss: 0.433319, acc.: 88.28%] [G loss: 1.332085]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1167 [D loss: 0.393154, acc.: 85.94%] [G loss: 1.185980]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1168 [D loss: 0.493558, acc.: 80.47%] [G loss: 1.532008]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1169 [D loss: 0.478143, acc.: 82.81%] [G loss: 1.408000]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1170 [D loss: 0.384552, acc.: 87.50%] [G loss: 1.223088]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1171 [D loss: 0.536791, acc.: 75.78%] [G loss: 1.214147]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1172 [D loss: 0.414081, acc.: 82.03%] [G loss: 1.590799]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1173 [D loss: 0.486236, acc.: 84.38%] [G loss: 1.133509]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1174 [D loss: 0.469478, acc.: 83.59%] [G loss: 1.259592]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1175 [D loss: 0.517136, acc.: 75.78%] [G loss: 1.319172]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1176 [D loss: 0.444038, acc.: 76.56%] [G loss: 1.130818]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1177 [D loss: 0.524155, acc.: 78.91%] [G loss: 1.200915]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1178 [D loss: 0.433344, acc.: 80.47%] [G loss: 1.483990]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1179 [D loss: 0.450458, acc.: 79.69%] [G loss: 1.237139]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1180 [D loss: 0.422820, acc.: 79.69%] [G loss: 1.247119]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1181 [D loss: 0.501161, acc.: 78.91%] [G loss: 1.136532]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1182 [D loss: 0.505606, acc.: 73.44%] [G loss: 1.269804]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1183 [D loss: 0.298437, acc.: 92.19%] [G loss: 1.472932]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1184 [D loss: 0.564531, acc.: 74.22%] [G loss: 1.146468]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1185 [D loss: 0.367122, acc.: 82.81%] [G loss: 1.358339]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1186 [D loss: 0.344822, acc.: 88.28%] [G loss: 1.503201]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1187 [D loss: 0.532942, acc.: 79.69%] [G loss: 1.339587]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1188 [D loss: 0.408184, acc.: 85.94%] [G loss: 1.280076]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1189 [D loss: 0.362224, acc.: 82.81%] [G loss: 1.263701]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1190 [D loss: 0.634618, acc.: 80.47%] [G loss: 1.194476]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1191 [D loss: 0.488442, acc.: 78.91%] [G loss: 1.423321]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1192 [D loss: 0.405942, acc.: 86.72%] [G loss: 1.509132]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1193 [D loss: 0.538993, acc.: 70.31%] [G loss: 1.271028]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1194 [D loss: 0.377419, acc.: 89.84%] [G loss: 1.563762]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1195 [D loss: 0.722753, acc.: 72.66%] [G loss: 1.207522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1196 [D loss: 0.351324, acc.: 86.72%] [G loss: 1.433939]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1197 [D loss: 0.482744, acc.: 82.03%] [G loss: 1.477343]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1198 [D loss: 0.452403, acc.: 77.34%] [G loss: 1.148106]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1199 [D loss: 0.282974, acc.: 88.28%] [G loss: 1.726187]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1200 [D loss: 0.444569, acc.: 86.72%] [G loss: 1.462866]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1201 [D loss: 0.509804, acc.: 76.56%] [G loss: 1.467574]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1202 [D loss: 0.423183, acc.: 89.84%] [G loss: 1.298676]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1203 [D loss: 0.382166, acc.: 89.06%] [G loss: 1.660707]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1204 [D loss: 0.448914, acc.: 85.94%] [G loss: 1.399676]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1205 [D loss: 0.314033, acc.: 86.72%] [G loss: 1.528905]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1206 [D loss: 0.610391, acc.: 77.34%] [G loss: 1.624683]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1207 [D loss: 0.627821, acc.: 74.22%] [G loss: 1.275910]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1208 [D loss: 0.433717, acc.: 81.25%] [G loss: 1.533647]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1209 [D loss: 0.698608, acc.: 61.72%] [G loss: 1.056378]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1210 [D loss: 0.708631, acc.: 53.91%] [G loss: 1.147706]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1211 [D loss: 0.731963, acc.: 60.94%] [G loss: 1.224911]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1212 [D loss: 0.539917, acc.: 77.34%] [G loss: 1.377734]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1213 [D loss: 0.384512, acc.: 85.94%] [G loss: 1.681653]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1214 [D loss: 0.600870, acc.: 71.09%] [G loss: 1.260664]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1215 [D loss: 0.481487, acc.: 72.66%] [G loss: 1.388267]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1216 [D loss: 0.586782, acc.: 69.53%] [G loss: 1.304386]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1217 [D loss: 0.505344, acc.: 81.25%] [G loss: 1.486713]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1218 [D loss: 0.769125, acc.: 60.16%] [G loss: 1.286630]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1219 [D loss: 0.389355, acc.: 79.69%] [G loss: 1.558058]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1220 [D loss: 0.600791, acc.: 66.41%] [G loss: 1.249288]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1221 [D loss: 0.453583, acc.: 82.03%] [G loss: 1.399829]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1222 [D loss: 0.429146, acc.: 82.03%] [G loss: 1.492102]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1223 [D loss: 0.661504, acc.: 74.22%] [G loss: 1.094529]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1224 [D loss: 0.408610, acc.: 78.91%] [G loss: 1.598167]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1225 [D loss: 0.467090, acc.: 84.38%] [G loss: 1.503473]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1226 [D loss: 0.498191, acc.: 75.78%] [G loss: 1.498770]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1227 [D loss: 0.503838, acc.: 84.38%] [G loss: 1.592184]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1228 [D loss: 0.637803, acc.: 72.66%] [G loss: 1.335614]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1229 [D loss: 0.399758, acc.: 84.38%] [G loss: 1.700723]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1230 [D loss: 0.467800, acc.: 78.91%] [G loss: 1.410872]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1231 [D loss: 0.520925, acc.: 72.66%] [G loss: 1.328268]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1232 [D loss: 0.365126, acc.: 89.06%] [G loss: 1.557893]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1233 [D loss: 0.396381, acc.: 83.59%] [G loss: 1.504825]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1234 [D loss: 0.498087, acc.: 78.91%] [G loss: 1.390920]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1235 [D loss: 0.427476, acc.: 82.81%] [G loss: 1.437112]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1236 [D loss: 0.371030, acc.: 90.62%] [G loss: 1.712572]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1237 [D loss: 0.480711, acc.: 80.47%] [G loss: 1.599203]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1238 [D loss: 0.444535, acc.: 87.50%] [G loss: 1.649732]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1239 [D loss: 0.532867, acc.: 74.22%] [G loss: 1.253543]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1240 [D loss: 0.445710, acc.: 78.12%] [G loss: 1.503389]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1241 [D loss: 0.493197, acc.: 82.81%] [G loss: 1.345712]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1242 [D loss: 0.481448, acc.: 81.25%] [G loss: 1.375098]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1243 [D loss: 0.530150, acc.: 79.69%] [G loss: 1.580188]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1244 [D loss: 0.499202, acc.: 82.03%] [G loss: 1.422154]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1245 [D loss: 0.443779, acc.: 84.38%] [G loss: 1.496021]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1246 [D loss: 0.389421, acc.: 82.81%] [G loss: 1.345725]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1247 [D loss: 0.341772, acc.: 85.16%] [G loss: 1.641488]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1248 [D loss: 0.601283, acc.: 78.91%] [G loss: 1.086820]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1249 [D loss: 0.411564, acc.: 81.25%] [G loss: 1.324443]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1250 [D loss: 0.749540, acc.: 69.53%] [G loss: 1.305517]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1251 [D loss: 0.477934, acc.: 78.91%] [G loss: 1.269885]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1252 [D loss: 0.491980, acc.: 77.34%] [G loss: 1.440034]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1253 [D loss: 0.477825, acc.: 78.12%] [G loss: 1.310760]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1254 [D loss: 0.348209, acc.: 91.41%] [G loss: 1.793581]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1255 [D loss: 0.725145, acc.: 75.00%] [G loss: 1.256931]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1256 [D loss: 0.409641, acc.: 84.38%] [G loss: 1.408932]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1257 [D loss: 0.365636, acc.: 88.28%] [G loss: 1.575260]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1258 [D loss: 0.594953, acc.: 74.22%] [G loss: 1.402955]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1259 [D loss: 0.413452, acc.: 82.81%] [G loss: 1.453479]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1260 [D loss: 0.365376, acc.: 87.50%] [G loss: 1.428450]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1261 [D loss: 0.671233, acc.: 75.00%] [G loss: 1.370207]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1262 [D loss: 0.342654, acc.: 86.72%] [G loss: 1.463829]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1263 [D loss: 0.477097, acc.: 78.91%] [G loss: 1.307997]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1264 [D loss: 0.578538, acc.: 80.47%] [G loss: 1.436006]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1265 [D loss: 0.458148, acc.: 83.59%] [G loss: 1.418284]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1266 [D loss: 0.338924, acc.: 86.72%] [G loss: 1.718545]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1267 [D loss: 0.587021, acc.: 74.22%] [G loss: 1.395949]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1268 [D loss: 0.422667, acc.: 86.72%] [G loss: 1.449599]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1269 [D loss: 0.348450, acc.: 85.94%] [G loss: 1.503826]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1270 [D loss: 0.678845, acc.: 78.12%] [G loss: 1.409237]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1271 [D loss: 0.325399, acc.: 91.41%] [G loss: 1.766525]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1272 [D loss: 0.533818, acc.: 82.81%] [G loss: 1.597985]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1273 [D loss: 0.375224, acc.: 88.28%] [G loss: 1.646864]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1274 [D loss: 0.341673, acc.: 88.28%] [G loss: 1.459774]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1275 [D loss: 0.458597, acc.: 79.69%] [G loss: 1.338723]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1276 [D loss: 0.402224, acc.: 82.03%] [G loss: 1.606650]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1277 [D loss: 0.434007, acc.: 85.16%] [G loss: 1.562313]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1278 [D loss: 0.553343, acc.: 85.94%] [G loss: 1.331799]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1279 [D loss: 0.587488, acc.: 74.22%] [G loss: 1.129874]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1280 [D loss: 0.367877, acc.: 85.16%] [G loss: 1.624617]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1281 [D loss: 0.367575, acc.: 87.50%] [G loss: 1.458152]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1282 [D loss: 0.505289, acc.: 82.81%] [G loss: 1.621527]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1283 [D loss: 0.321063, acc.: 90.62%] [G loss: 1.588975]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1284 [D loss: 0.392733, acc.: 90.62%] [G loss: 1.247318]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1285 [D loss: 0.334397, acc.: 89.06%] [G loss: 1.373469]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1286 [D loss: 0.347028, acc.: 92.19%] [G loss: 1.644332]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1287 [D loss: 0.445796, acc.: 86.72%] [G loss: 1.383745]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1288 [D loss: 0.368458, acc.: 89.06%] [G loss: 1.679959]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1289 [D loss: 0.429497, acc.: 82.03%] [G loss: 1.610479]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1290 [D loss: 0.566923, acc.: 76.56%] [G loss: 1.361965]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1291 [D loss: 0.404587, acc.: 82.81%] [G loss: 1.467525]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1292 [D loss: 0.659699, acc.: 75.00%] [G loss: 1.106771]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1293 [D loss: 0.420798, acc.: 76.56%] [G loss: 1.400997]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1294 [D loss: 0.591013, acc.: 81.25%] [G loss: 1.587511]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1295 [D loss: 0.590318, acc.: 68.75%] [G loss: 1.555493]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1296 [D loss: 0.273867, acc.: 90.62%] [G loss: 1.652404]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1297 [D loss: 0.558765, acc.: 74.22%] [G loss: 1.237226]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1298 [D loss: 0.393224, acc.: 91.41%] [G loss: 1.750385]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1299 [D loss: 0.475800, acc.: 85.16%] [G loss: 1.596980]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1300 [D loss: 0.461878, acc.: 77.34%] [G loss: 1.213450]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1301 [D loss: 0.489457, acc.: 75.00%] [G loss: 1.197276]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1302 [D loss: 0.422649, acc.: 83.59%] [G loss: 1.569414]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1303 [D loss: 0.527454, acc.: 78.91%] [G loss: 1.500618]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1304 [D loss: 0.525976, acc.: 75.78%] [G loss: 1.211195]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1305 [D loss: 0.483485, acc.: 82.81%] [G loss: 1.531172]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1306 [D loss: 0.446408, acc.: 84.38%] [G loss: 1.760639]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1307 [D loss: 0.598797, acc.: 74.22%] [G loss: 1.651456]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1308 [D loss: 0.421521, acc.: 85.94%] [G loss: 1.405892]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1309 [D loss: 0.634185, acc.: 71.09%] [G loss: 1.193504]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1310 [D loss: 0.417525, acc.: 84.38%] [G loss: 1.683242]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1311 [D loss: 0.369994, acc.: 87.50%] [G loss: 1.586161]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1312 [D loss: 0.390506, acc.: 87.50%] [G loss: 1.647880]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1313 [D loss: 0.477127, acc.: 83.59%] [G loss: 1.296833]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1314 [D loss: 0.352674, acc.: 86.72%] [G loss: 1.668513]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1315 [D loss: 0.364800, acc.: 83.59%] [G loss: 1.658253]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1316 [D loss: 0.433450, acc.: 78.12%] [G loss: 1.569262]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1317 [D loss: 0.371850, acc.: 79.69%] [G loss: 1.680821]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1318 [D loss: 0.495781, acc.: 76.56%] [G loss: 1.739292]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1319 [D loss: 0.538947, acc.: 85.16%] [G loss: 1.474718]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1320 [D loss: 0.603611, acc.: 72.66%] [G loss: 1.403364]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1321 [D loss: 0.329011, acc.: 86.72%] [G loss: 1.576088]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1322 [D loss: 0.391268, acc.: 80.47%] [G loss: 1.281691]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1323 [D loss: 0.551410, acc.: 71.88%] [G loss: 1.423134]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1324 [D loss: 0.456025, acc.: 85.16%] [G loss: 1.714953]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1325 [D loss: 0.369832, acc.: 88.28%] [G loss: 1.481239]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1326 [D loss: 0.492445, acc.: 80.47%] [G loss: 1.318409]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1327 [D loss: 0.321970, acc.: 88.28%] [G loss: 1.877692]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1328 [D loss: 0.489878, acc.: 84.38%] [G loss: 1.644116]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1329 [D loss: 0.323514, acc.: 89.84%] [G loss: 1.580974]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1330 [D loss: 0.526920, acc.: 82.81%] [G loss: 1.466846]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1331 [D loss: 0.311649, acc.: 91.41%] [G loss: 1.578464]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1332 [D loss: 0.514442, acc.: 77.34%] [G loss: 1.143144]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1333 [D loss: 0.509468, acc.: 81.25%] [G loss: 1.560518]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1334 [D loss: 0.364810, acc.: 89.06%] [G loss: 1.625420]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1335 [D loss: 0.467401, acc.: 75.78%] [G loss: 1.334494]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1336 [D loss: 0.405612, acc.: 85.94%] [G loss: 1.361293]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1337 [D loss: 0.478928, acc.: 75.78%] [G loss: 1.151429]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1338 [D loss: 0.437426, acc.: 85.94%] [G loss: 1.490651]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1339 [D loss: 0.371553, acc.: 89.84%] [G loss: 1.440794]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1340 [D loss: 0.382808, acc.: 84.38%] [G loss: 1.611370]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1341 [D loss: 0.501788, acc.: 79.69%] [G loss: 1.405119]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1342 [D loss: 0.414994, acc.: 78.91%] [G loss: 1.369620]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1343 [D loss: 0.405994, acc.: 82.81%] [G loss: 1.311807]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1344 [D loss: 0.311259, acc.: 89.84%] [G loss: 1.487777]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1345 [D loss: 0.334481, acc.: 88.28%] [G loss: 1.523029]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1346 [D loss: 0.387438, acc.: 88.28%] [G loss: 1.535841]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1347 [D loss: 0.552414, acc.: 70.31%] [G loss: 1.308050]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1348 [D loss: 0.340830, acc.: 88.28%] [G loss: 1.632625]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1349 [D loss: 0.456573, acc.: 89.84%] [G loss: 1.749896]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1350 [D loss: 0.413346, acc.: 82.03%] [G loss: 1.588614]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1351 [D loss: 0.512528, acc.: 86.72%] [G loss: 1.499355]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1352 [D loss: 0.382123, acc.: 87.50%] [G loss: 1.715351]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1353 [D loss: 0.346029, acc.: 88.28%] [G loss: 1.524355]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1354 [D loss: 0.333597, acc.: 88.28%] [G loss: 1.557227]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1355 [D loss: 0.439529, acc.: 86.72%] [G loss: 1.761467]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1356 [D loss: 0.519520, acc.: 76.56%] [G loss: 1.481189]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1357 [D loss: 0.465335, acc.: 83.59%] [G loss: 1.482323]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1358 [D loss: 0.423307, acc.: 85.94%] [G loss: 1.300050]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1359 [D loss: 0.361100, acc.: 82.81%] [G loss: 1.482811]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1360 [D loss: 0.604805, acc.: 73.44%] [G loss: 1.476532]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1361 [D loss: 0.394944, acc.: 83.59%] [G loss: 1.478012]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1362 [D loss: 0.359869, acc.: 83.59%] [G loss: 1.679633]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1363 [D loss: 0.513510, acc.: 76.56%] [G loss: 1.234773]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1364 [D loss: 0.496210, acc.: 78.91%] [G loss: 1.419280]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1365 [D loss: 0.432196, acc.: 83.59%] [G loss: 1.599518]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1366 [D loss: 0.421508, acc.: 80.47%] [G loss: 1.478076]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1367 [D loss: 0.714360, acc.: 82.81%] [G loss: 1.587529]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1368 [D loss: 0.552946, acc.: 79.69%] [G loss: 1.398035]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1369 [D loss: 0.393683, acc.: 83.59%] [G loss: 1.310643]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1370 [D loss: 0.477555, acc.: 76.56%] [G loss: 1.351120]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1371 [D loss: 0.422405, acc.: 84.38%] [G loss: 1.359450]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1372 [D loss: 0.519429, acc.: 83.59%] [G loss: 1.212156]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1373 [D loss: 0.471110, acc.: 82.03%] [G loss: 1.439039]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1374 [D loss: 0.521529, acc.: 84.38%] [G loss: 1.539341]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1375 [D loss: 0.521168, acc.: 77.34%] [G loss: 1.449495]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1376 [D loss: 0.383707, acc.: 85.16%] [G loss: 1.524421]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1377 [D loss: 0.392885, acc.: 82.81%] [G loss: 1.435208]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1378 [D loss: 0.482376, acc.: 87.50%] [G loss: 1.577517]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1379 [D loss: 0.518660, acc.: 85.16%] [G loss: 1.596128]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1380 [D loss: 0.454699, acc.: 77.34%] [G loss: 1.381190]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1381 [D loss: 0.387851, acc.: 84.38%] [G loss: 1.357996]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1382 [D loss: 0.405939, acc.: 82.81%] [G loss: 1.683434]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1383 [D loss: 0.630614, acc.: 79.69%] [G loss: 1.629605]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1384 [D loss: 0.375005, acc.: 87.50%] [G loss: 1.444811]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1385 [D loss: 0.377100, acc.: 89.84%] [G loss: 1.551844]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1386 [D loss: 0.433898, acc.: 85.94%] [G loss: 1.626475]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1387 [D loss: 0.340895, acc.: 89.84%] [G loss: 1.573805]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1388 [D loss: 0.468569, acc.: 78.91%] [G loss: 1.250001]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1389 [D loss: 0.333350, acc.: 88.28%] [G loss: 1.475929]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1390 [D loss: 0.600286, acc.: 75.00%] [G loss: 1.398010]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1391 [D loss: 0.398187, acc.: 80.47%] [G loss: 1.537317]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1392 [D loss: 0.450919, acc.: 87.50%] [G loss: 1.748728]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1393 [D loss: 0.360829, acc.: 89.06%] [G loss: 1.591315]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1394 [D loss: 0.458082, acc.: 82.81%] [G loss: 1.475801]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1395 [D loss: 0.433338, acc.: 84.38%] [G loss: 1.573271]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1396 [D loss: 0.423380, acc.: 82.81%] [G loss: 1.524483]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1397 [D loss: 0.426228, acc.: 87.50%] [G loss: 1.480536]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1398 [D loss: 0.521469, acc.: 85.94%] [G loss: 1.721866]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1399 [D loss: 0.398138, acc.: 86.72%] [G loss: 1.522727]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1400 [D loss: 0.509094, acc.: 78.91%] [G loss: 1.288331]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1401 [D loss: 0.601872, acc.: 81.25%] [G loss: 1.506832]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1402 [D loss: 0.456981, acc.: 79.69%] [G loss: 1.446698]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1403 [D loss: 0.369273, acc.: 83.59%] [G loss: 1.714645]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1404 [D loss: 0.379683, acc.: 85.94%] [G loss: 1.431457]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1405 [D loss: 0.380206, acc.: 85.16%] [G loss: 1.534811]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1406 [D loss: 0.366620, acc.: 86.72%] [G loss: 1.479903]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1407 [D loss: 0.634416, acc.: 78.91%] [G loss: 1.566750]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1408 [D loss: 0.323562, acc.: 90.62%] [G loss: 1.780753]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1409 [D loss: 0.576262, acc.: 84.38%] [G loss: 1.423481]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1410 [D loss: 0.430094, acc.: 82.03%] [G loss: 1.750946]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1411 [D loss: 0.370025, acc.: 89.84%] [G loss: 1.926789]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1412 [D loss: 0.487688, acc.: 88.28%] [G loss: 1.348723]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1413 [D loss: 0.416259, acc.: 82.81%] [G loss: 1.554738]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1414 [D loss: 0.367965, acc.: 91.41%] [G loss: 2.080663]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1415 [D loss: 0.389308, acc.: 85.94%] [G loss: 2.048985]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1416 [D loss: 0.437688, acc.: 81.25%] [G loss: 1.406470]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1417 [D loss: 0.545112, acc.: 81.25%] [G loss: 1.637338]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1418 [D loss: 0.464890, acc.: 82.81%] [G loss: 1.354207]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1419 [D loss: 0.455837, acc.: 88.28%] [G loss: 1.451504]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1420 [D loss: 0.361519, acc.: 85.94%] [G loss: 1.629841]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1421 [D loss: 0.452584, acc.: 82.03%] [G loss: 1.614544]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1422 [D loss: 0.480405, acc.: 84.38%] [G loss: 1.617604]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1423 [D loss: 0.491484, acc.: 83.59%] [G loss: 1.760455]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1424 [D loss: 0.378592, acc.: 88.28%] [G loss: 1.404000]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1425 [D loss: 0.463506, acc.: 82.81%] [G loss: 1.603227]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1426 [D loss: 0.412561, acc.: 81.25%] [G loss: 1.514569]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1427 [D loss: 0.272647, acc.: 89.84%] [G loss: 2.172426]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1428 [D loss: 0.445713, acc.: 86.72%] [G loss: 1.701276]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1429 [D loss: 0.361616, acc.: 89.06%] [G loss: 1.627057]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1430 [D loss: 0.395364, acc.: 83.59%] [G loss: 1.755985]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1431 [D loss: 0.464492, acc.: 78.91%] [G loss: 1.474871]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1432 [D loss: 0.280030, acc.: 89.84%] [G loss: 1.836128]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1433 [D loss: 0.337085, acc.: 91.41%] [G loss: 1.449787]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1434 [D loss: 0.289082, acc.: 89.84%] [G loss: 1.811186]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1435 [D loss: 0.482619, acc.: 78.91%] [G loss: 1.500127]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1436 [D loss: 0.509092, acc.: 85.16%] [G loss: 1.710496]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1437 [D loss: 0.473714, acc.: 83.59%] [G loss: 1.613857]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1438 [D loss: 0.346447, acc.: 86.72%] [G loss: 1.368636]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1439 [D loss: 0.419915, acc.: 87.50%] [G loss: 1.587734]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1440 [D loss: 0.354509, acc.: 85.16%] [G loss: 1.566175]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1441 [D loss: 0.524314, acc.: 82.03%] [G loss: 1.740490]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1442 [D loss: 0.603071, acc.: 78.12%] [G loss: 1.500417]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1443 [D loss: 0.415076, acc.: 78.91%] [G loss: 1.750815]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1444 [D loss: 0.359818, acc.: 82.81%] [G loss: 1.477026]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1445 [D loss: 0.385602, acc.: 88.28%] [G loss: 1.732624]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1446 [D loss: 0.320243, acc.: 90.62%] [G loss: 1.675406]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1447 [D loss: 0.386437, acc.: 85.16%] [G loss: 1.634096]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1448 [D loss: 0.367643, acc.: 88.28%] [G loss: 1.538063]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1449 [D loss: 0.473063, acc.: 87.50%] [G loss: 1.478669]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1450 [D loss: 0.365736, acc.: 86.72%] [G loss: 1.741567]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1451 [D loss: 0.498696, acc.: 78.12%] [G loss: 1.754914]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1452 [D loss: 0.578710, acc.: 79.69%] [G loss: 1.344121]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1453 [D loss: 0.387640, acc.: 88.28%] [G loss: 1.497723]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1454 [D loss: 0.455699, acc.: 83.59%] [G loss: 1.547242]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1455 [D loss: 0.452007, acc.: 88.28%] [G loss: 1.645711]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1456 [D loss: 0.414301, acc.: 88.28%] [G loss: 1.860278]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1457 [D loss: 0.453465, acc.: 85.94%] [G loss: 1.321117]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1458 [D loss: 0.298238, acc.: 85.94%] [G loss: 1.698490]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1459 [D loss: 0.330995, acc.: 89.84%] [G loss: 1.808599]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1460 [D loss: 0.420011, acc.: 83.59%] [G loss: 1.867319]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1461 [D loss: 0.352724, acc.: 92.19%] [G loss: 1.619589]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1462 [D loss: 0.267355, acc.: 88.28%] [G loss: 1.648736]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1463 [D loss: 0.600451, acc.: 86.72%] [G loss: 1.495987]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1464 [D loss: 0.403176, acc.: 89.06%] [G loss: 1.514852]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1465 [D loss: 0.344044, acc.: 88.28%] [G loss: 1.830876]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1466 [D loss: 0.269294, acc.: 89.84%] [G loss: 1.879935]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1467 [D loss: 0.539769, acc.: 80.47%] [G loss: 1.576800]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1468 [D loss: 0.255111, acc.: 92.19%] [G loss: 1.782037]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1469 [D loss: 0.429653, acc.: 82.81%] [G loss: 1.639217]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1470 [D loss: 0.550285, acc.: 75.00%] [G loss: 1.375656]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1471 [D loss: 0.398158, acc.: 82.81%] [G loss: 1.556787]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1472 [D loss: 0.375264, acc.: 85.94%] [G loss: 1.536167]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1473 [D loss: 0.332794, acc.: 85.16%] [G loss: 1.532768]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1474 [D loss: 0.450601, acc.: 82.81%] [G loss: 1.505866]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1475 [D loss: 0.308976, acc.: 89.84%] [G loss: 1.603556]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1476 [D loss: 0.263954, acc.: 92.97%] [G loss: 1.766574]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1477 [D loss: 0.412359, acc.: 85.94%] [G loss: 1.615431]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1478 [D loss: 0.468171, acc.: 85.16%] [G loss: 1.388476]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1479 [D loss: 0.380116, acc.: 85.94%] [G loss: 1.516332]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1480 [D loss: 0.534424, acc.: 82.81%] [G loss: 1.649002]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1481 [D loss: 0.376988, acc.: 89.06%] [G loss: 1.596757]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1482 [D loss: 0.578555, acc.: 84.38%] [G loss: 1.659824]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1483 [D loss: 0.406417, acc.: 85.16%] [G loss: 1.471277]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1484 [D loss: 0.425055, acc.: 86.72%] [G loss: 1.597453]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1485 [D loss: 0.350465, acc.: 86.72%] [G loss: 1.639015]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1486 [D loss: 0.432495, acc.: 86.72%] [G loss: 1.516522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1487 [D loss: 0.384639, acc.: 85.94%] [G loss: 1.662499]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1488 [D loss: 0.390785, acc.: 83.59%] [G loss: 1.794086]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1489 [D loss: 0.298194, acc.: 89.84%] [G loss: 1.628477]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1490 [D loss: 0.361515, acc.: 87.50%] [G loss: 1.609014]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1491 [D loss: 0.533180, acc.: 79.69%] [G loss: 1.486961]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1492 [D loss: 0.498053, acc.: 83.59%] [G loss: 1.380970]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1493 [D loss: 0.477320, acc.: 85.16%] [G loss: 1.489010]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1494 [D loss: 0.461670, acc.: 82.03%] [G loss: 1.470216]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1495 [D loss: 0.643676, acc.: 80.47%] [G loss: 1.400748]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1496 [D loss: 0.315000, acc.: 89.06%] [G loss: 1.737454]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1497 [D loss: 0.442623, acc.: 78.91%] [G loss: 1.407700]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1498 [D loss: 0.458398, acc.: 85.94%] [G loss: 1.710440]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1499 [D loss: 0.587290, acc.: 86.72%] [G loss: 1.730703]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1500 [D loss: 0.387449, acc.: 85.94%] [G loss: 1.682315]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1501 [D loss: 0.382988, acc.: 84.38%] [G loss: 1.510278]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1502 [D loss: 0.485348, acc.: 81.25%] [G loss: 1.308586]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1503 [D loss: 0.416481, acc.: 88.28%] [G loss: 1.538865]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1504 [D loss: 0.349180, acc.: 85.94%] [G loss: 1.560334]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1505 [D loss: 0.369974, acc.: 86.72%] [G loss: 1.414590]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1506 [D loss: 0.318214, acc.: 91.41%] [G loss: 1.432608]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1507 [D loss: 0.496690, acc.: 83.59%] [G loss: 1.445495]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1508 [D loss: 0.423745, acc.: 81.25%] [G loss: 1.593155]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1509 [D loss: 0.306909, acc.: 90.62%] [G loss: 1.642020]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1510 [D loss: 0.396706, acc.: 88.28%] [G loss: 1.452102]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1511 [D loss: 0.432394, acc.: 83.59%] [G loss: 1.463079]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1512 [D loss: 0.365877, acc.: 87.50%] [G loss: 1.619230]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1513 [D loss: 0.345109, acc.: 85.94%] [G loss: 1.781709]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1514 [D loss: 0.336390, acc.: 86.72%] [G loss: 1.773527]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1515 [D loss: 0.515743, acc.: 82.03%] [G loss: 1.295687]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1516 [D loss: 0.393640, acc.: 85.94%] [G loss: 1.713849]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1517 [D loss: 0.433153, acc.: 83.59%] [G loss: 1.476862]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1518 [D loss: 0.475636, acc.: 85.94%] [G loss: 1.650399]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1519 [D loss: 0.388175, acc.: 85.94%] [G loss: 1.688567]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1520 [D loss: 0.314092, acc.: 85.94%] [G loss: 1.758031]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1521 [D loss: 0.498815, acc.: 83.59%] [G loss: 1.530478]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1522 [D loss: 0.455239, acc.: 83.59%] [G loss: 1.755359]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1523 [D loss: 0.298636, acc.: 90.62%] [G loss: 1.831545]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1524 [D loss: 0.218652, acc.: 92.97%] [G loss: 2.015799]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1525 [D loss: 0.479514, acc.: 84.38%] [G loss: 1.608375]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1526 [D loss: 0.411748, acc.: 83.59%] [G loss: 2.183629]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1527 [D loss: 0.324762, acc.: 86.72%] [G loss: 1.703911]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1528 [D loss: 0.390008, acc.: 92.19%] [G loss: 1.906469]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1529 [D loss: 0.662967, acc.: 79.69%] [G loss: 1.626176]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1530 [D loss: 0.415610, acc.: 88.28%] [G loss: 1.813658]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1531 [D loss: 0.413980, acc.: 90.62%] [G loss: 1.799972]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1532 [D loss: 0.509927, acc.: 89.06%] [G loss: 1.566842]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1533 [D loss: 0.350194, acc.: 85.16%] [G loss: 1.971153]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1534 [D loss: 0.450323, acc.: 87.50%] [G loss: 1.632479]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1535 [D loss: 0.602642, acc.: 73.44%] [G loss: 2.100835]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1536 [D loss: 0.446581, acc.: 85.16%] [G loss: 2.015599]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1537 [D loss: 0.662874, acc.: 82.03%] [G loss: 1.326099]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1538 [D loss: 0.433815, acc.: 83.59%] [G loss: 1.392838]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1539 [D loss: 0.460747, acc.: 79.69%] [G loss: 1.487136]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1540 [D loss: 0.416966, acc.: 85.94%] [G loss: 1.549660]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1541 [D loss: 0.428088, acc.: 81.25%] [G loss: 1.642841]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1542 [D loss: 0.477449, acc.: 82.81%] [G loss: 1.729991]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1543 [D loss: 0.340658, acc.: 87.50%] [G loss: 1.586857]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1544 [D loss: 0.381593, acc.: 89.84%] [G loss: 1.612678]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1545 [D loss: 0.396083, acc.: 85.16%] [G loss: 1.730229]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1546 [D loss: 0.287029, acc.: 90.62%] [G loss: 2.072278]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1547 [D loss: 0.290733, acc.: 90.62%] [G loss: 1.900522]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1548 [D loss: 0.431475, acc.: 85.94%] [G loss: 1.739051]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1549 [D loss: 0.283846, acc.: 92.19%] [G loss: 1.941639]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1550 [D loss: 0.587836, acc.: 77.34%] [G loss: 1.411898]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1551 [D loss: 0.507910, acc.: 82.81%] [G loss: 1.794341]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1552 [D loss: 0.494577, acc.: 85.94%] [G loss: 1.466930]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1553 [D loss: 0.486321, acc.: 84.38%] [G loss: 1.506788]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1554 [D loss: 0.398029, acc.: 87.50%] [G loss: 1.437548]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1555 [D loss: 0.378529, acc.: 85.94%] [G loss: 1.638933]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1556 [D loss: 0.327048, acc.: 89.84%] [G loss: 1.574749]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1557 [D loss: 0.477055, acc.: 82.03%] [G loss: 1.621588]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1558 [D loss: 0.427285, acc.: 82.03%] [G loss: 1.404738]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1559 [D loss: 0.336960, acc.: 89.06%] [G loss: 1.439228]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1560 [D loss: 0.302313, acc.: 91.41%] [G loss: 1.741864]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1561 [D loss: 0.335234, acc.: 89.06%] [G loss: 1.853607]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1562 [D loss: 0.342343, acc.: 88.28%] [G loss: 2.015739]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1563 [D loss: 0.344856, acc.: 86.72%] [G loss: 1.748292]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1564 [D loss: 0.307024, acc.: 88.28%] [G loss: 1.805245]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1565 [D loss: 0.283024, acc.: 91.41%] [G loss: 2.015341]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1566 [D loss: 0.414644, acc.: 89.06%] [G loss: 1.624689]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1567 [D loss: 0.498310, acc.: 84.38%] [G loss: 1.519308]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1568 [D loss: 0.294820, acc.: 90.62%] [G loss: 1.606258]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1569 [D loss: 0.396903, acc.: 85.94%] [G loss: 1.593220]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1570 [D loss: 0.250656, acc.: 93.75%] [G loss: 1.770727]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1571 [D loss: 0.352565, acc.: 91.41%] [G loss: 1.532136]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1572 [D loss: 0.349380, acc.: 88.28%] [G loss: 1.656464]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1573 [D loss: 0.418314, acc.: 89.06%] [G loss: 1.988222]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1574 [D loss: 0.304666, acc.: 90.62%] [G loss: 1.844666]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1575 [D loss: 0.347125, acc.: 85.94%] [G loss: 1.666676]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1576 [D loss: 0.513917, acc.: 80.47%] [G loss: 1.324287]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1577 [D loss: 0.383015, acc.: 85.16%] [G loss: 1.616702]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1578 [D loss: 0.420461, acc.: 85.94%] [G loss: 1.439720]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1579 [D loss: 0.457430, acc.: 78.91%] [G loss: 1.530790]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1580 [D loss: 0.377521, acc.: 84.38%] [G loss: 1.548571]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1581 [D loss: 0.382194, acc.: 85.94%] [G loss: 1.501909]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1582 [D loss: 0.316646, acc.: 86.72%] [G loss: 1.592917]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1583 [D loss: 0.523119, acc.: 85.16%] [G loss: 1.423409]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1584 [D loss: 0.606917, acc.: 85.16%] [G loss: 1.356396]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1585 [D loss: 0.466783, acc.: 83.59%] [G loss: 1.563233]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1586 [D loss: 0.280343, acc.: 92.19%] [G loss: 1.768004]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1587 [D loss: 0.375864, acc.: 87.50%] [G loss: 1.641690]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1588 [D loss: 0.425855, acc.: 85.94%] [G loss: 1.520714]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1589 [D loss: 0.372077, acc.: 87.50%] [G loss: 1.526629]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1590 [D loss: 0.480560, acc.: 81.25%] [G loss: 1.696791]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1591 [D loss: 0.350742, acc.: 90.62%] [G loss: 1.552401]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1592 [D loss: 0.319498, acc.: 88.28%] [G loss: 1.694018]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1593 [D loss: 0.379171, acc.: 89.06%] [G loss: 1.818676]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1594 [D loss: 0.456476, acc.: 83.59%] [G loss: 1.792053]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1595 [D loss: 0.293783, acc.: 91.41%] [G loss: 1.812302]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1596 [D loss: 0.365343, acc.: 89.06%] [G loss: 1.607871]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1597 [D loss: 0.328061, acc.: 92.19%] [G loss: 1.737516]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1598 [D loss: 0.446482, acc.: 88.28%] [G loss: 1.659534]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1599 [D loss: 0.327084, acc.: 89.84%] [G loss: 1.892483]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1600 [D loss: 0.381019, acc.: 87.50%] [G loss: 1.693450]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1601 [D loss: 0.490434, acc.: 80.47%] [G loss: 1.496464]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1602 [D loss: 0.384705, acc.: 88.28%] [G loss: 1.564330]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1603 [D loss: 0.404756, acc.: 85.94%] [G loss: 1.661479]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1604 [D loss: 0.383274, acc.: 84.38%] [G loss: 1.442191]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1605 [D loss: 0.351156, acc.: 89.06%] [G loss: 1.653868]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1606 [D loss: 0.417360, acc.: 82.03%] [G loss: 1.512568]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1607 [D loss: 0.309135, acc.: 89.06%] [G loss: 1.650021]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1608 [D loss: 0.546059, acc.: 83.59%] [G loss: 1.587919]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1609 [D loss: 0.430349, acc.: 89.06%] [G loss: 1.634566]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1610 [D loss: 0.382198, acc.: 88.28%] [G loss: 1.526672]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1611 [D loss: 0.259817, acc.: 90.62%] [G loss: 1.930051]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1612 [D loss: 0.296482, acc.: 92.19%] [G loss: 1.916436]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1613 [D loss: 0.331873, acc.: 89.06%] [G loss: 1.733128]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1614 [D loss: 0.423616, acc.: 82.81%] [G loss: 1.589556]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1615 [D loss: 0.276510, acc.: 90.62%] [G loss: 1.756052]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1616 [D loss: 0.470589, acc.: 85.94%] [G loss: 1.834073]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1617 [D loss: 0.478417, acc.: 83.59%] [G loss: 1.660305]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1618 [D loss: 0.460668, acc.: 78.12%] [G loss: 1.721752]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1619 [D loss: 0.503635, acc.: 80.47%] [G loss: 1.696998]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1620 [D loss: 0.462072, acc.: 82.03%] [G loss: 1.543087]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1621 [D loss: 0.417905, acc.: 79.69%] [G loss: 1.543067]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1622 [D loss: 0.258557, acc.: 91.41%] [G loss: 1.830335]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1623 [D loss: 0.429414, acc.: 83.59%] [G loss: 1.575575]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1624 [D loss: 0.347581, acc.: 86.72%] [G loss: 1.516275]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1625 [D loss: 0.435966, acc.: 91.41%] [G loss: 1.615145]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1626 [D loss: 0.335951, acc.: 85.94%] [G loss: 1.477066]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1627 [D loss: 0.304603, acc.: 89.84%] [G loss: 1.911958]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1628 [D loss: 0.408083, acc.: 85.16%] [G loss: 1.877622]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1629 [D loss: 0.397006, acc.: 85.94%] [G loss: 1.724263]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1630 [D loss: 0.362195, acc.: 85.16%] [G loss: 2.009629]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1631 [D loss: 0.424097, acc.: 83.59%] [G loss: 2.017438]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1632 [D loss: 0.369251, acc.: 88.28%] [G loss: 2.175803]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1633 [D loss: 0.352736, acc.: 83.59%] [G loss: 1.800575]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1634 [D loss: 0.468252, acc.: 82.81%] [G loss: 1.850439]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1635 [D loss: 0.423981, acc.: 83.59%] [G loss: 1.644948]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1636 [D loss: 0.392196, acc.: 85.16%] [G loss: 1.797405]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1637 [D loss: 0.296149, acc.: 89.06%] [G loss: 1.923196]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1638 [D loss: 0.343980, acc.: 88.28%] [G loss: 1.880558]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1639 [D loss: 0.439020, acc.: 90.62%] [G loss: 1.567911]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1640 [D loss: 0.383058, acc.: 89.06%] [G loss: 1.557536]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1641 [D loss: 0.422126, acc.: 88.28%] [G loss: 1.591535]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1642 [D loss: 0.417178, acc.: 89.06%] [G loss: 1.774523]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1643 [D loss: 0.359306, acc.: 88.28%] [G loss: 1.655969]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1644 [D loss: 0.373247, acc.: 85.94%] [G loss: 1.632456]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1645 [D loss: 0.310978, acc.: 85.94%] [G loss: 1.701986]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1646 [D loss: 0.410558, acc.: 89.06%] [G loss: 1.347740]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1647 [D loss: 0.333846, acc.: 90.62%] [G loss: 1.817696]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1648 [D loss: 0.514313, acc.: 81.25%] [G loss: 1.624346]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1649 [D loss: 0.271345, acc.: 93.75%] [G loss: 1.591373]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1650 [D loss: 0.358103, acc.: 89.84%] [G loss: 1.661153]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1651 [D loss: 0.262581, acc.: 93.75%] [G loss: 1.708594]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1652 [D loss: 0.203804, acc.: 92.97%] [G loss: 1.977781]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1653 [D loss: 0.255494, acc.: 92.97%] [G loss: 1.745071]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1654 [D loss: 0.285592, acc.: 88.28%] [G loss: 1.459483]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1655 [D loss: 0.405695, acc.: 84.38%] [G loss: 1.651416]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1656 [D loss: 0.309929, acc.: 89.84%] [G loss: 1.785836]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1657 [D loss: 0.321289, acc.: 88.28%] [G loss: 1.751653]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1658 [D loss: 0.358567, acc.: 92.19%] [G loss: 1.811417]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1659 [D loss: 0.356908, acc.: 87.50%] [G loss: 1.632676]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1660 [D loss: 0.374063, acc.: 87.50%] [G loss: 1.592240]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1661 [D loss: 0.382299, acc.: 88.28%] [G loss: 1.599154]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1662 [D loss: 0.322605, acc.: 89.84%] [G loss: 1.587395]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1663 [D loss: 0.542865, acc.: 82.81%] [G loss: 1.487721]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1664 [D loss: 0.355768, acc.: 88.28%] [G loss: 1.697644]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1665 [D loss: 0.327126, acc.: 88.28%] [G loss: 1.790041]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1666 [D loss: 0.391538, acc.: 85.16%] [G loss: 1.514389]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1667 [D loss: 0.314623, acc.: 89.06%] [G loss: 1.696896]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1668 [D loss: 0.405618, acc.: 88.28%] [G loss: 1.506306]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1669 [D loss: 0.411038, acc.: 81.25%] [G loss: 1.457922]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1670 [D loss: 0.254428, acc.: 93.75%] [G loss: 1.701805]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1671 [D loss: 0.317498, acc.: 91.41%] [G loss: 1.542289]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1672 [D loss: 0.308275, acc.: 88.28%] [G loss: 1.625481]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1673 [D loss: 0.587408, acc.: 85.94%] [G loss: 1.445164]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1674 [D loss: 0.321448, acc.: 93.75%] [G loss: 1.724576]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1675 [D loss: 0.279325, acc.: 92.97%] [G loss: 1.891411]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1676 [D loss: 0.263181, acc.: 92.19%] [G loss: 1.715214]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1677 [D loss: 0.465073, acc.: 82.81%] [G loss: 1.683312]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1678 [D loss: 0.416117, acc.: 78.12%] [G loss: 1.613882]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1679 [D loss: 0.315429, acc.: 89.06%] [G loss: 1.593345]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1680 [D loss: 0.439624, acc.: 82.81%] [G loss: 1.662558]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1681 [D loss: 0.338772, acc.: 86.72%] [G loss: 1.748783]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1682 [D loss: 0.334480, acc.: 86.72%] [G loss: 1.474929]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1683 [D loss: 0.363347, acc.: 84.38%] [G loss: 1.749312]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1684 [D loss: 0.300314, acc.: 89.84%] [G loss: 1.619688]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1685 [D loss: 0.509907, acc.: 82.81%] [G loss: 1.652199]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1686 [D loss: 0.400288, acc.: 86.72%] [G loss: 1.935449]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1687 [D loss: 0.507235, acc.: 82.03%] [G loss: 1.479747]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1688 [D loss: 0.339242, acc.: 89.84%] [G loss: 1.620600]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1689 [D loss: 0.314417, acc.: 87.50%] [G loss: 1.861208]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1690 [D loss: 0.310072, acc.: 93.75%] [G loss: 2.010566]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1691 [D loss: 0.366097, acc.: 89.06%] [G loss: 1.705178]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1692 [D loss: 0.353723, acc.: 89.84%] [G loss: 1.694170]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1693 [D loss: 0.299293, acc.: 92.19%] [G loss: 1.656471]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1694 [D loss: 0.230860, acc.: 93.75%] [G loss: 1.778168]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1695 [D loss: 0.318834, acc.: 90.62%] [G loss: 1.890122]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1696 [D loss: 0.295341, acc.: 89.06%] [G loss: 1.956592]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1697 [D loss: 0.372791, acc.: 88.28%] [G loss: 1.899376]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1698 [D loss: 0.302331, acc.: 88.28%] [G loss: 2.109248]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1699 [D loss: 0.341261, acc.: 89.84%] [G loss: 1.732634]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1700 [D loss: 0.414249, acc.: 85.16%] [G loss: 1.962036]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1701 [D loss: 0.360012, acc.: 85.16%] [G loss: 1.916797]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1702 [D loss: 0.450303, acc.: 86.72%] [G loss: 1.721890]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1703 [D loss: 0.328189, acc.: 89.84%] [G loss: 1.692446]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1704 [D loss: 0.306348, acc.: 88.28%] [G loss: 1.657679]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1705 [D loss: 0.400034, acc.: 86.72%] [G loss: 1.853506]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1706 [D loss: 0.359640, acc.: 88.28%] [G loss: 1.767225]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1707 [D loss: 0.465358, acc.: 82.03%] [G loss: 1.951223]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1708 [D loss: 0.274627, acc.: 92.19%] [G loss: 1.612373]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1709 [D loss: 0.416197, acc.: 82.03%] [G loss: 1.495700]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1710 [D loss: 0.313174, acc.: 91.41%] [G loss: 1.552213]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1711 [D loss: 0.370972, acc.: 83.59%] [G loss: 1.744389]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1712 [D loss: 0.285583, acc.: 88.28%] [G loss: 1.818793]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1713 [D loss: 0.379000, acc.: 86.72%] [G loss: 1.943036]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1714 [D loss: 0.341089, acc.: 86.72%] [G loss: 1.748075]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1715 [D loss: 0.470160, acc.: 85.94%] [G loss: 2.034945]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1716 [D loss: 0.290162, acc.: 91.41%] [G loss: 1.710386]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1717 [D loss: 0.452410, acc.: 83.59%] [G loss: 1.613582]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1718 [D loss: 0.451157, acc.: 87.50%] [G loss: 1.690257]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1719 [D loss: 0.286569, acc.: 89.84%] [G loss: 1.604023]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1720 [D loss: 0.290986, acc.: 90.62%] [G loss: 1.702547]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1721 [D loss: 0.494657, acc.: 82.03%] [G loss: 1.454388]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1722 [D loss: 0.262745, acc.: 92.97%] [G loss: 1.924408]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1723 [D loss: 0.387233, acc.: 85.94%] [G loss: 1.585164]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1724 [D loss: 0.452395, acc.: 85.94%] [G loss: 1.582408]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1725 [D loss: 0.346831, acc.: 86.72%] [G loss: 1.597101]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1726 [D loss: 0.372219, acc.: 82.81%] [G loss: 1.638320]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1727 [D loss: 0.348711, acc.: 88.28%] [G loss: 1.661392]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1728 [D loss: 0.301253, acc.: 89.84%] [G loss: 1.756068]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1729 [D loss: 0.352541, acc.: 87.50%] [G loss: 1.933507]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1730 [D loss: 0.358456, acc.: 88.28%] [G loss: 1.681465]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1731 [D loss: 0.345994, acc.: 87.50%] [G loss: 1.732407]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1732 [D loss: 0.416922, acc.: 84.38%] [G loss: 1.768223]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1733 [D loss: 0.358213, acc.: 89.06%] [G loss: 1.510181]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1734 [D loss: 0.411795, acc.: 86.72%] [G loss: 1.695331]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1735 [D loss: 0.232234, acc.: 93.75%] [G loss: 1.679251]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1736 [D loss: 0.270985, acc.: 91.41%] [G loss: 1.792536]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1737 [D loss: 0.341725, acc.: 87.50%] [G loss: 1.568784]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1738 [D loss: 0.291983, acc.: 89.06%] [G loss: 1.681046]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1739 [D loss: 0.367591, acc.: 89.84%] [G loss: 1.644025]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1740 [D loss: 0.413686, acc.: 87.50%] [G loss: 1.600660]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1741 [D loss: 0.464825, acc.: 87.50%] [G loss: 1.657069]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1742 [D loss: 0.338013, acc.: 89.84%] [G loss: 1.903638]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1743 [D loss: 0.284578, acc.: 91.41%] [G loss: 2.264443]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1744 [D loss: 0.319172, acc.: 87.50%] [G loss: 1.938536]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1745 [D loss: 0.398238, acc.: 85.16%] [G loss: 1.646126]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1746 [D loss: 0.250706, acc.: 92.97%] [G loss: 1.724079]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1747 [D loss: 0.225146, acc.: 92.97%] [G loss: 1.896597]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1748 [D loss: 0.339535, acc.: 91.41%] [G loss: 1.820180]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1749 [D loss: 0.224552, acc.: 91.41%] [G loss: 2.110682]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1750 [D loss: 0.252197, acc.: 88.28%] [G loss: 2.314932]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1751 [D loss: 0.306322, acc.: 94.53%] [G loss: 2.323301]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1752 [D loss: 0.303162, acc.: 92.19%] [G loss: 1.576809]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1753 [D loss: 0.443941, acc.: 81.25%] [G loss: 2.204744]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1754 [D loss: 0.513233, acc.: 83.59%] [G loss: 1.987530]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1755 [D loss: 0.310568, acc.: 91.41%] [G loss: 1.658479]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1756 [D loss: 0.436768, acc.: 77.34%] [G loss: 1.770124]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1757 [D loss: 0.403762, acc.: 85.94%] [G loss: 1.743237]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1758 [D loss: 0.327213, acc.: 89.06%] [G loss: 1.624222]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1759 [D loss: 0.367616, acc.: 88.28%] [G loss: 1.542560]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1760 [D loss: 0.634897, acc.: 83.59%] [G loss: 1.574023]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1761 [D loss: 0.289845, acc.: 88.28%] [G loss: 1.870808]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1762 [D loss: 0.512602, acc.: 85.94%] [G loss: 1.705196]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1763 [D loss: 0.322348, acc.: 87.50%] [G loss: 1.475604]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1764 [D loss: 0.415577, acc.: 85.16%] [G loss: 1.813754]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1765 [D loss: 0.425617, acc.: 84.38%] [G loss: 1.994737]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1766 [D loss: 0.524846, acc.: 85.94%] [G loss: 1.580294]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1767 [D loss: 0.389736, acc.: 81.25%] [G loss: 1.597271]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1768 [D loss: 0.511875, acc.: 77.34%] [G loss: 1.666560]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1769 [D loss: 0.526565, acc.: 83.59%] [G loss: 1.817712]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1770 [D loss: 0.377066, acc.: 87.50%] [G loss: 1.691448]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1771 [D loss: 0.466808, acc.: 84.38%] [G loss: 1.578808]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1772 [D loss: 0.394563, acc.: 87.50%] [G loss: 1.543201]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1773 [D loss: 0.264593, acc.: 91.41%] [G loss: 1.846947]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1774 [D loss: 0.513121, acc.: 84.38%] [G loss: 1.767238]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1775 [D loss: 0.419379, acc.: 86.72%] [G loss: 1.772567]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1776 [D loss: 0.323399, acc.: 89.06%] [G loss: 1.812118]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1777 [D loss: 0.272233, acc.: 89.06%] [G loss: 1.972129]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1778 [D loss: 0.382021, acc.: 86.72%] [G loss: 2.039006]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1779 [D loss: 0.335847, acc.: 90.62%] [G loss: 1.909539]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1780 [D loss: 0.277433, acc.: 95.31%] [G loss: 2.133525]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1781 [D loss: 0.283584, acc.: 92.97%] [G loss: 1.947631]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1782 [D loss: 0.179524, acc.: 93.75%] [G loss: 2.178109]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1783 [D loss: 0.312141, acc.: 91.41%] [G loss: 2.001201]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1784 [D loss: 0.366863, acc.: 87.50%] [G loss: 1.941931]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1785 [D loss: 0.282884, acc.: 89.84%] [G loss: 2.470732]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1786 [D loss: 0.440890, acc.: 85.16%] [G loss: 2.019682]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1787 [D loss: 0.520814, acc.: 75.78%] [G loss: 2.170935]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1788 [D loss: 0.408808, acc.: 86.72%] [G loss: 1.767920]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1789 [D loss: 0.423568, acc.: 82.03%] [G loss: 1.656696]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1790 [D loss: 0.520163, acc.: 87.50%] [G loss: 1.697248]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1791 [D loss: 0.295462, acc.: 86.72%] [G loss: 1.662153]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1792 [D loss: 0.300466, acc.: 89.06%] [G loss: 1.637562]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1793 [D loss: 0.443362, acc.: 81.25%] [G loss: 1.553711]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1794 [D loss: 0.423658, acc.: 89.84%] [G loss: 1.657866]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1795 [D loss: 0.365378, acc.: 86.72%] [G loss: 1.983860]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1796 [D loss: 0.317478, acc.: 92.19%] [G loss: 2.046823]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1797 [D loss: 0.266280, acc.: 92.97%] [G loss: 1.786455]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1798 [D loss: 0.244619, acc.: 92.97%] [G loss: 1.877743]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1799 [D loss: 0.277588, acc.: 88.28%] [G loss: 1.676234]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1800 [D loss: 0.289061, acc.: 90.62%] [G loss: 2.150921]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1801 [D loss: 0.379396, acc.: 91.41%] [G loss: 1.987538]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1802 [D loss: 0.328423, acc.: 89.06%] [G loss: 1.897831]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1803 [D loss: 0.441005, acc.: 83.59%] [G loss: 1.829363]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1804 [D loss: 0.360628, acc.: 85.94%] [G loss: 1.666712]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1805 [D loss: 0.456543, acc.: 78.91%] [G loss: 1.585456]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1806 [D loss: 0.317169, acc.: 87.50%] [G loss: 1.736997]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1807 [D loss: 0.379753, acc.: 88.28%] [G loss: 1.636919]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1808 [D loss: 0.280019, acc.: 90.62%] [G loss: 1.642113]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1809 [D loss: 0.340139, acc.: 86.72%] [G loss: 1.865890]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1810 [D loss: 0.372731, acc.: 85.94%] [G loss: 1.889322]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1811 [D loss: 0.287986, acc.: 91.41%] [G loss: 1.636563]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1812 [D loss: 0.396171, acc.: 85.16%] [G loss: 1.659457]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1813 [D loss: 0.369822, acc.: 87.50%] [G loss: 1.858331]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1814 [D loss: 0.238093, acc.: 92.97%] [G loss: 1.870312]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1815 [D loss: 0.331275, acc.: 89.84%] [G loss: 1.629517]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1816 [D loss: 0.291804, acc.: 90.62%] [G loss: 1.498253]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1817 [D loss: 0.299092, acc.: 90.62%] [G loss: 1.613673]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1818 [D loss: 0.288964, acc.: 90.62%] [G loss: 1.728436]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1819 [D loss: 0.228498, acc.: 94.53%] [G loss: 1.817688]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1820 [D loss: 0.266522, acc.: 90.62%] [G loss: 2.013315]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1821 [D loss: 0.214834, acc.: 92.19%] [G loss: 2.082705]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1822 [D loss: 0.401230, acc.: 92.19%] [G loss: 1.790123]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1823 [D loss: 0.258151, acc.: 92.97%] [G loss: 1.903445]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1824 [D loss: 0.332090, acc.: 88.28%] [G loss: 2.127566]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1825 [D loss: 0.295862, acc.: 91.41%] [G loss: 1.816064]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1826 [D loss: 0.356461, acc.: 85.94%] [G loss: 2.140456]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1827 [D loss: 0.411729, acc.: 85.16%] [G loss: 1.910405]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1828 [D loss: 0.434844, acc.: 82.81%] [G loss: 1.684549]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1829 [D loss: 0.451159, acc.: 81.25%] [G loss: 1.820821]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1830 [D loss: 0.424790, acc.: 83.59%] [G loss: 1.984855]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1831 [D loss: 0.376279, acc.: 85.94%] [G loss: 1.778761]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1832 [D loss: 0.380785, acc.: 89.06%] [G loss: 1.670259]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1833 [D loss: 0.373796, acc.: 88.28%] [G loss: 1.603904]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1834 [D loss: 0.326980, acc.: 85.16%] [G loss: 1.675751]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1835 [D loss: 0.373898, acc.: 89.84%] [G loss: 1.795918]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1836 [D loss: 0.295475, acc.: 89.84%] [G loss: 1.735455]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1837 [D loss: 0.209884, acc.: 96.88%] [G loss: 1.759277]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1838 [D loss: 0.386089, acc.: 90.62%] [G loss: 1.710557]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1839 [D loss: 0.283289, acc.: 91.41%] [G loss: 1.803508]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1840 [D loss: 0.347330, acc.: 89.84%] [G loss: 1.798336]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1841 [D loss: 0.430967, acc.: 87.50%] [G loss: 1.739760]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1842 [D loss: 0.293323, acc.: 89.06%] [G loss: 1.845384]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1843 [D loss: 0.333695, acc.: 87.50%] [G loss: 2.164598]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1844 [D loss: 0.404049, acc.: 89.06%] [G loss: 1.857496]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1845 [D loss: 0.684758, acc.: 75.00%] [G loss: 1.671825]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1846 [D loss: 0.324747, acc.: 89.84%] [G loss: 1.703589]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1847 [D loss: 0.375716, acc.: 88.28%] [G loss: 1.735998]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1848 [D loss: 0.484655, acc.: 78.91%] [G loss: 1.680929]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1849 [D loss: 0.382513, acc.: 86.72%] [G loss: 1.604628]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1850 [D loss: 0.259095, acc.: 92.19%] [G loss: 1.679679]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1851 [D loss: 0.396330, acc.: 82.03%] [G loss: 1.606431]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1852 [D loss: 0.579442, acc.: 82.81%] [G loss: 1.696589]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1853 [D loss: 0.327459, acc.: 92.19%] [G loss: 2.295023]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1854 [D loss: 0.212298, acc.: 91.41%] [G loss: 9.923419]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1855 [D loss: 2.966836, acc.: 64.84%] [G loss: 1.216138]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1856 [D loss: 0.270398, acc.: 90.62%] [G loss: 1.561374]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1857 [D loss: 0.208440, acc.: 97.66%] [G loss: 2.275542]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1858 [D loss: 0.438662, acc.: 89.06%] [G loss: 1.927363]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1859 [D loss: 0.505177, acc.: 87.50%] [G loss: 1.839428]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1860 [D loss: 0.278283, acc.: 91.41%] [G loss: 2.245822]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1861 [D loss: 0.348051, acc.: 87.50%] [G loss: 2.094063]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1862 [D loss: 0.280399, acc.: 90.62%] [G loss: 2.404850]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1863 [D loss: 0.227829, acc.: 96.09%] [G loss: 2.225470]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1864 [D loss: 0.222067, acc.: 92.19%] [G loss: 1.991803]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1865 [D loss: 0.235418, acc.: 93.75%] [G loss: 2.279992]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1866 [D loss: 0.247693, acc.: 92.19%] [G loss: 1.982209]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1867 [D loss: 0.201947, acc.: 92.19%] [G loss: 1.992775]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1868 [D loss: 0.493088, acc.: 83.59%] [G loss: 1.929770]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1869 [D loss: 0.470595, acc.: 85.16%] [G loss: 1.965818]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1870 [D loss: 0.681062, acc.: 79.69%] [G loss: 1.864446]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1871 [D loss: 0.352630, acc.: 91.41%] [G loss: 1.809880]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1872 [D loss: 0.349728, acc.: 89.06%] [G loss: 1.694453]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1873 [D loss: 0.233764, acc.: 91.41%] [G loss: 1.802301]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1874 [D loss: 0.222920, acc.: 94.53%] [G loss: 1.774200]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1875 [D loss: 0.242146, acc.: 94.53%] [G loss: 2.008543]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1876 [D loss: 0.239051, acc.: 94.53%] [G loss: 2.018083]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1877 [D loss: 0.253777, acc.: 92.97%] [G loss: 2.013886]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1878 [D loss: 0.255460, acc.: 92.19%] [G loss: 1.866721]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1879 [D loss: 0.202528, acc.: 94.53%] [G loss: 2.059681]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1880 [D loss: 0.241116, acc.: 90.62%] [G loss: 1.945689]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1881 [D loss: 0.232303, acc.: 94.53%] [G loss: 1.888864]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1882 [D loss: 0.161433, acc.: 97.66%] [G loss: 1.940407]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1883 [D loss: 0.241371, acc.: 93.75%] [G loss: 2.028772]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1884 [D loss: 0.224202, acc.: 92.97%] [G loss: 2.152637]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1885 [D loss: 0.279037, acc.: 93.75%] [G loss: 2.174572]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1886 [D loss: 0.194667, acc.: 94.53%] [G loss: 2.231279]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1887 [D loss: 0.235258, acc.: 93.75%] [G loss: 2.123629]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1888 [D loss: 0.224575, acc.: 92.19%] [G loss: 2.132957]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1889 [D loss: 0.243930, acc.: 92.19%] [G loss: 1.814360]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1890 [D loss: 0.363600, acc.: 84.38%] [G loss: 2.585390]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1891 [D loss: 0.302581, acc.: 92.19%] [G loss: 1.985099]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1892 [D loss: 0.320424, acc.: 90.62%] [G loss: 1.699263]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1893 [D loss: 0.356128, acc.: 92.19%] [G loss: 1.805705]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1894 [D loss: 0.360940, acc.: 91.41%] [G loss: 1.660892]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1895 [D loss: 0.242279, acc.: 91.41%] [G loss: 1.864493]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1896 [D loss: 0.314669, acc.: 90.62%] [G loss: 1.753452]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1897 [D loss: 0.179557, acc.: 95.31%] [G loss: 2.184653]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1898 [D loss: 0.243337, acc.: 94.53%] [G loss: 2.066269]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1899 [D loss: 0.297043, acc.: 93.75%] [G loss: 1.856740]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1900 [D loss: 0.288505, acc.: 89.84%] [G loss: 1.741343]\n",
      "generated_data\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1901 [D loss: 0.304259, acc.: 93.75%] [G loss: 1.904390]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1902 [D loss: 0.260235, acc.: 91.41%] [G loss: 1.965064]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1903 [D loss: 0.302609, acc.: 89.06%] [G loss: 1.945533]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1904 [D loss: 0.162397, acc.: 97.66%] [G loss: 2.042567]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1905 [D loss: 0.354106, acc.: 89.84%] [G loss: 1.741523]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1906 [D loss: 0.211324, acc.: 94.53%] [G loss: 1.895478]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1907 [D loss: 0.158616, acc.: 94.53%] [G loss: 2.014919]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1908 [D loss: 0.274739, acc.: 92.97%] [G loss: 1.854882]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1909 [D loss: 0.374716, acc.: 88.28%] [G loss: 1.744197]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1910 [D loss: 0.223337, acc.: 93.75%] [G loss: 1.979464]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1911 [D loss: 0.400833, acc.: 89.84%] [G loss: 1.931516]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1912 [D loss: 0.347142, acc.: 88.28%] [G loss: 2.015845]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1913 [D loss: 0.436006, acc.: 84.38%] [G loss: 1.790502]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1914 [D loss: 0.284721, acc.: 91.41%] [G loss: 1.868887]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1915 [D loss: 0.231705, acc.: 92.97%] [G loss: 2.076795]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1916 [D loss: 0.302338, acc.: 88.28%] [G loss: 2.013248]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1917 [D loss: 0.293820, acc.: 94.53%] [G loss: 1.854077]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1918 [D loss: 0.209383, acc.: 95.31%] [G loss: 1.934125]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1919 [D loss: 0.218949, acc.: 94.53%] [G loss: 1.962283]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1920 [D loss: 0.254826, acc.: 91.41%] [G loss: 1.989561]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1921 [D loss: 0.266711, acc.: 90.62%] [G loss: 1.964251]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1922 [D loss: 0.219031, acc.: 94.53%] [G loss: 1.860509]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1923 [D loss: 0.241970, acc.: 91.41%] [G loss: 2.032010]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1924 [D loss: 0.284020, acc.: 91.41%] [G loss: 1.799680]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1925 [D loss: 0.196501, acc.: 94.53%] [G loss: 1.924756]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1926 [D loss: 0.261905, acc.: 89.84%] [G loss: 1.866677]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1927 [D loss: 0.297569, acc.: 91.41%] [G loss: 1.956754]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1928 [D loss: 0.396563, acc.: 84.38%] [G loss: 1.910476]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1929 [D loss: 0.320182, acc.: 86.72%] [G loss: 1.887485]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1930 [D loss: 0.333668, acc.: 84.38%] [G loss: 2.089115]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1931 [D loss: 0.403492, acc.: 88.28%] [G loss: 1.794412]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1932 [D loss: 0.349933, acc.: 86.72%] [G loss: 1.559313]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1933 [D loss: 0.405382, acc.: 85.94%] [G loss: 1.622558]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1934 [D loss: 0.271496, acc.: 90.62%] [G loss: 1.691102]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1935 [D loss: 0.385837, acc.: 89.84%] [G loss: 1.636474]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1936 [D loss: 0.368631, acc.: 88.28%] [G loss: 1.567554]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1937 [D loss: 0.252535, acc.: 92.97%] [G loss: 2.096330]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1938 [D loss: 0.215726, acc.: 93.75%] [G loss: 1.958965]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1939 [D loss: 0.246466, acc.: 93.75%] [G loss: 1.900945]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1940 [D loss: 0.230139, acc.: 93.75%] [G loss: 1.907027]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1941 [D loss: 0.202959, acc.: 93.75%] [G loss: 1.952363]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1942 [D loss: 0.390799, acc.: 85.94%] [G loss: 1.577757]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1943 [D loss: 0.327198, acc.: 92.97%] [G loss: 1.664640]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1944 [D loss: 0.275001, acc.: 92.97%] [G loss: 1.856345]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1945 [D loss: 0.259660, acc.: 94.53%] [G loss: 1.929437]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1946 [D loss: 0.420319, acc.: 80.47%] [G loss: 1.794961]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1947 [D loss: 0.333979, acc.: 84.38%] [G loss: 1.737143]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1948 [D loss: 0.377740, acc.: 89.84%] [G loss: 1.463518]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1949 [D loss: 0.380867, acc.: 89.84%] [G loss: 1.602386]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1950 [D loss: 0.363544, acc.: 84.38%] [G loss: 1.509872]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1951 [D loss: 0.331957, acc.: 90.62%] [G loss: 1.869434]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1952 [D loss: 0.308747, acc.: 88.28%] [G loss: 1.794657]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1953 [D loss: 0.334022, acc.: 89.84%] [G loss: 1.633728]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1954 [D loss: 0.327511, acc.: 90.62%] [G loss: 1.560671]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1955 [D loss: 0.250997, acc.: 95.31%] [G loss: 1.605958]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1956 [D loss: 0.279313, acc.: 89.06%] [G loss: 1.692793]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1957 [D loss: 0.244782, acc.: 91.41%] [G loss: 1.691772]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1958 [D loss: 0.336014, acc.: 91.41%] [G loss: 1.500461]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1959 [D loss: 0.416224, acc.: 89.06%] [G loss: 1.557387]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1960 [D loss: 0.332228, acc.: 86.72%] [G loss: 1.642079]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1961 [D loss: 0.362029, acc.: 88.28%] [G loss: 1.539883]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1962 [D loss: 0.285546, acc.: 90.62%] [G loss: 1.623087]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1963 [D loss: 0.306539, acc.: 89.84%] [G loss: 1.690787]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1964 [D loss: 0.338463, acc.: 84.38%] [G loss: 1.677400]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1965 [D loss: 0.273741, acc.: 90.62%] [G loss: 1.855263]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1966 [D loss: 0.410654, acc.: 87.50%] [G loss: 1.638705]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1967 [D loss: 0.343644, acc.: 84.38%] [G loss: 1.666673]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1968 [D loss: 0.320263, acc.: 89.06%] [G loss: 1.868987]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1969 [D loss: 0.467211, acc.: 84.38%] [G loss: 1.426758]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1970 [D loss: 0.247103, acc.: 93.75%] [G loss: 1.591940]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1971 [D loss: 0.389600, acc.: 85.94%] [G loss: 1.561690]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1972 [D loss: 0.356970, acc.: 87.50%] [G loss: 1.774921]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1973 [D loss: 0.345616, acc.: 83.59%] [G loss: 1.712616]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1974 [D loss: 0.235924, acc.: 91.41%] [G loss: 1.937000]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1975 [D loss: 0.331564, acc.: 88.28%] [G loss: 1.534931]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1976 [D loss: 0.255745, acc.: 93.75%] [G loss: 1.849926]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1977 [D loss: 0.366945, acc.: 89.84%] [G loss: 1.586541]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1978 [D loss: 0.237618, acc.: 94.53%] [G loss: 1.667130]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1979 [D loss: 0.244052, acc.: 89.84%] [G loss: 1.745350]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1980 [D loss: 0.315273, acc.: 87.50%] [G loss: 1.624945]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1981 [D loss: 0.329663, acc.: 89.06%] [G loss: 1.585261]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1982 [D loss: 0.343477, acc.: 88.28%] [G loss: 1.820861]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1983 [D loss: 0.304574, acc.: 90.62%] [G loss: 1.713896]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1984 [D loss: 0.313611, acc.: 87.50%] [G loss: 1.664153]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1985 [D loss: 0.361937, acc.: 87.50%] [G loss: 1.522197]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1986 [D loss: 0.365969, acc.: 88.28%] [G loss: 1.632788]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1987 [D loss: 0.286668, acc.: 92.97%] [G loss: 1.521800]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1988 [D loss: 0.265284, acc.: 93.75%] [G loss: 1.562008]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1989 [D loss: 0.295019, acc.: 89.84%] [G loss: 1.686239]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1990 [D loss: 0.307782, acc.: 90.62%] [G loss: 1.675921]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1991 [D loss: 0.361084, acc.: 87.50%] [G loss: 1.476495]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1992 [D loss: 0.289113, acc.: 88.28%] [G loss: 1.766677]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1993 [D loss: 0.340423, acc.: 90.62%] [G loss: 1.458301]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1994 [D loss: 0.292803, acc.: 88.28%] [G loss: 1.640994]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1995 [D loss: 0.359308, acc.: 85.16%] [G loss: 1.511032]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1996 [D loss: 0.303089, acc.: 90.62%] [G loss: 1.474435]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1997 [D loss: 0.269074, acc.: 88.28%] [G loss: 1.667670]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1998 [D loss: 0.359962, acc.: 86.72%] [G loss: 1.674328]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1999 [D loss: 0.374671, acc.: 86.72%] [G loss: 1.626900]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2000 [D loss: 0.307962, acc.: 88.28%] [G loss: 1.593223]\n",
      "generated_data\n"
     ]
    }
   ],
   "source": [
    "synthesizer.train(train_data_4_pd[catCols_enc], train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4933cc-236b-4c94-9d3e-eaeda33606ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0685c1d-5deb-4d19-8b9c-019d8ae51772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca11ad-0bc7-4c88-ae49-f0c3a8399fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634d58a-f2fd-4538-b014-8a0f04c6b08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9275f1-a32d-4a49-b3fc-1db84d2c7dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "71dc465c-29db-4ebe-bb78-156e98878ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can easily save the trained generator and loaded it aftwerwards\n",
    "synthesizer.save('model-' + str(model_loop_count) + '/gan/saved', 'generator_claims')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c3791-87bd-4ee6-970e-0b84a66f6b79",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Just printing generator and discriminator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "747259cd-e9d1-4e32-a000-c86dc25d912f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(64, 100)]               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (64, 128)                 12928     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (64, 256)                 33024     \n",
      "                                                                 \n",
      " dense_58 (Dense)            (64, 512)                 131584    \n",
      "                                                                 \n",
      " dense_59 (Dense)            (64, 8)                   4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181640 (709.53 KB)\n",
      "Trainable params: 181640 (709.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "synthesizer.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5634b36b-bfc6-4113-bf03-e8dce0babe65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(64, 8)]                 0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (64, 512)                 4608      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (64, 512)                 0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (64, 256)                 131328    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (64, 256)                 0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (64, 128)                 32896     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (64, 1)                   129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168961 (660.00 KB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 168961 (660.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "synthesizer.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "abb01bee-89cc-4493-b8ae-44ca6c4a965f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GAN': ['GAN',\n",
       "  False,\n",
       "  <keras.src.engine.functional.Functional at 0x7f4ef64ed8a0>]}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'GAN': ['GAN', False, synthesizer.generator]}\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa9d6ba-a9f5-46de-a9fe-0775d7918116",
   "metadata": {},
   "source": [
    "### Test data predictions using GAN discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7806c3ca-5572-4068-bd8a-20d324332998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912480, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbmt_proc_cd_label_enc</th>\n",
       "      <th>sbmt_proc_mod_1_cd_label_enc</th>\n",
       "      <th>sbmt_proc_mod_2_cd_label_enc</th>\n",
       "      <th>diag_cd1_label_enc</th>\n",
       "      <th>bil_prov_txnmy_cd_label_enc</th>\n",
       "      <th>bill_amount_category_label_enc</th>\n",
       "      <th>aso_buyup_label_enc</th>\n",
       "      <th>clm_pl_of_srvc_cd_label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4655</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2829</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>4655</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4782</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4937</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>522</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>4937</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3554</td>\n",
       "      <td>395</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbmt_proc_cd_label_enc  sbmt_proc_mod_1_cd_label_enc  \\\n",
       "0                    4782                             0   \n",
       "1                    2829                           154   \n",
       "2                    4782                            14   \n",
       "3                     522                           191   \n",
       "4                    4529                             0   \n",
       "\n",
       "   sbmt_proc_mod_2_cd_label_enc  diag_cd1_label_enc  \\\n",
       "0                             0                4655   \n",
       "1                             0                4655   \n",
       "2                             0                4937   \n",
       "3                             0                4937   \n",
       "4                             0                3554   \n",
       "\n",
       "   bil_prov_txnmy_cd_label_enc  bill_amount_category_label_enc  \\\n",
       "0                          200                               6   \n",
       "1                          200                               4   \n",
       "2                          200                               6   \n",
       "3                          200                               3   \n",
       "4                          395                               6   \n",
       "\n",
       "   aso_buyup_label_enc  clm_pl_of_srvc_cd_label_enc  \n",
       "0                    1                            7  \n",
       "1                    1                            7  \n",
       "2                    1                            7  \n",
       "3                    1                            7  \n",
       "4                    1                            7  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data features (for passing into discriminator, for generating predictions)\n",
    "x_test = test_data_3_pd[catCols_enc]\n",
    "print(x_test.shape)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "57cc3b2f-035f-45cf-a2f4-445ac2e8f083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28515/28515 [==============================] - 25s 872us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (912480, 1))"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating test data line level predictions\n",
    "y_pred = synthesizer.discriminator.predict(x_test)\n",
    "type(y_pred), y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "8b848972-19ba-4b3b-8a2d-4f866cad4aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>cli_clm_id</th>\n",
       "      <th>map_fwae_disposition</th>\n",
       "      <th>sbmt_proc_cd</th>\n",
       "      <th>sbmt_proc_mod_1_cd</th>\n",
       "      <th>sbmt_proc_mod_2_cd</th>\n",
       "      <th>diag_cd1</th>\n",
       "      <th>bil_prov_txnmy_cd</th>\n",
       "      <th>ln_bil_amt</th>\n",
       "      <th>aso_buyup</th>\n",
       "      <th>...</th>\n",
       "      <th>sbmt_proc_cd_label_enc</th>\n",
       "      <th>sbmt_proc_mod_1_cd_label_enc</th>\n",
       "      <th>sbmt_proc_mod_2_cd_label_enc</th>\n",
       "      <th>diag_cd1_label_enc</th>\n",
       "      <th>bil_prov_txnmy_cd_label_enc</th>\n",
       "      <th>bill_amount_category_label_enc</th>\n",
       "      <th>aso_buyup_label_enc</th>\n",
       "      <th>clm_pl_of_srvc_cd_label_enc</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>912475</th>\n",
       "      <td>917223288571300</td>\n",
       "      <td>917223288571300</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "      <td>J7298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z30430</td>\n",
       "      <td>261QM1300X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10697</td>\n",
       "      <td>395</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912476</th>\n",
       "      <td>917223288571300</td>\n",
       "      <td>917223288571300</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "      <td>J1885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Z30430</td>\n",
       "      <td>261QM1300X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10697</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912477</th>\n",
       "      <td>918223287282400</td>\n",
       "      <td>918223287282400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "      <td>97162</td>\n",
       "      <td>GP</td>\n",
       "      <td>0</td>\n",
       "      <td>M169</td>\n",
       "      <td>207X00000X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4700</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>4651</td>\n",
       "      <td>196</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912478</th>\n",
       "      <td>918223287282400</td>\n",
       "      <td>918223287282400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "      <td>97110</td>\n",
       "      <td>GP</td>\n",
       "      <td>0</td>\n",
       "      <td>M169</td>\n",
       "      <td>207X00000X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4689</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>4651</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912479</th>\n",
       "      <td>918223287282400</td>\n",
       "      <td>918223287282400</td>\n",
       "      <td>Paid after Investigation</td>\n",
       "      <td>97140</td>\n",
       "      <td>GP</td>\n",
       "      <td>0</td>\n",
       "      <td>M169</td>\n",
       "      <td>207X00000X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4697</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>4651</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ufe_claim_id       cli_clm_id      map_fwae_disposition  \\\n",
       "912475  917223288571300  917223288571300  Paid after Investigation   \n",
       "912476  917223288571300  917223288571300  Paid after Investigation   \n",
       "912477  918223287282400  918223287282400  Paid after Investigation   \n",
       "912478  918223287282400  918223287282400  Paid after Investigation   \n",
       "912479  918223287282400  918223287282400  Paid after Investigation   \n",
       "\n",
       "       sbmt_proc_cd sbmt_proc_mod_1_cd sbmt_proc_mod_2_cd diag_cd1  \\\n",
       "912475        J7298                  0                  0   Z30430   \n",
       "912476        J1885                  0                  0   Z30430   \n",
       "912477        97162                 GP                  0     M169   \n",
       "912478        97110                 GP                  0     M169   \n",
       "912479        97140                 GP                  0     M169   \n",
       "\n",
       "       bil_prov_txnmy_cd  ln_bil_amt  aso_buyup  ...  sbmt_proc_cd_label_enc  \\\n",
       "912475        261QM1300X         NaN          1  ...                    5973   \n",
       "912476        261QM1300X         NaN          1  ...                    5870   \n",
       "912477        207X00000X         NaN          1  ...                    4700   \n",
       "912478        207X00000X         NaN          1  ...                    4689   \n",
       "912479        207X00000X         NaN          1  ...                    4697   \n",
       "\n",
       "       sbmt_proc_mod_1_cd_label_enc  sbmt_proc_mod_2_cd_label_enc  \\\n",
       "912475                            0                             0   \n",
       "912476                            0                             0   \n",
       "912477                          122                             0   \n",
       "912478                          122                             0   \n",
       "912479                          122                             0   \n",
       "\n",
       "        diag_cd1_label_enc  bil_prov_txnmy_cd_label_enc  \\\n",
       "912475               10697                          395   \n",
       "912476               10697                          395   \n",
       "912477                4651                          196   \n",
       "912478                4651                          196   \n",
       "912479                4651                          196   \n",
       "\n",
       "        bill_amount_category_label_enc  aso_buyup_label_enc  \\\n",
       "912475                               1                    1   \n",
       "912476                               0                    1   \n",
       "912477                               6                    1   \n",
       "912478                               2                    1   \n",
       "912479                               2                    1   \n",
       "\n",
       "        clm_pl_of_srvc_cd_label_enc  target  prediction  \n",
       "912475                            7       1    1.000000  \n",
       "912476                            7       1    0.999995  \n",
       "912477                            7       1    1.000000  \n",
       "912478                            7       1    1.000000  \n",
       "912479                            7       1    1.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending discriminator predictions in original test data dataframe\n",
    "test_data_3_pd = test_data_3_pd.reset_index(drop=True)\n",
    "test_data_3_pd['prediction'] = y_pred\n",
    "test_data_3_pd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b7d6c61a-c13f-4aba-b6fd-b780611cb992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912480, 259798, 0, 652682)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing predictions range wise count, just to see any wierd behaviour\n",
    "len(y_pred), \\\n",
    "len([x for x in y_pred if (x > 0) and (x < 1)]), \\\n",
    "len([x for x in y_pred if (x == 0)]), \\\n",
    "len([x for x in y_pred if (x == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4db29-ecc4-422b-b671-dcc75fab08f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a1474f4-30a8-4cf7-baa7-976e5530ff91",
   "metadata": {},
   "source": [
    "### Final Evaluation\n",
    "Here we are grouping by ufe_claim_id, and for each claim, the claim level probability is taken as minimum of the probability on all the lines. \n",
    "\n",
    "In test data:\n",
    "<br>'target' is the claim level ground truth.\n",
    "<br>'prediction' is discriminator's prediction (probability) for each line. Discriminator prediction is the probability of a line being clean.\n",
    "\n",
    "So we will decide the claim being clean or not using the worst case scenario line.\n",
    "<br>So if the discriminator says that even if one line is bad line then we will say that particular claim is fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "114b8353-e525-42f3-aa63-9e45ed5db92c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7152836226547431"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3_pd[test_data_3_pd['prediction'] == 1].shape[0]/912480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "728d77ec-7dfc-445f-8a48-32ae2756b474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521418551639488"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3_pd[test_data_3_pd['target'] == 1].shape[0]/912480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "af9c5fc3-cf6d-4344-ac91-d27d1a0883b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "912480"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3_pd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "48a01f9d-4ea8-4034-a5f9-08a14864df12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273786"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "912480 - 638694"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f1f37-fc15-472e-b874-c27dfdcc2bad",
   "metadata": {},
   "source": [
    "##### Taking min probability of all lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "592c0702-99a1-453f-848d-72d22841388e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105223050202600</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105223140222600</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105223390228600</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105223620208100</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115223140508700</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target  prediction\n",
       "ufe_claim_id                       \n",
       "105223050202600       1    1.000000\n",
       "105223140222600       0    0.999972\n",
       "105223390228600       1    1.000000\n",
       "105223620208100       0    1.000000\n",
       "115223140508700       1    0.999993"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = test_data_3_pd.groupby('ufe_claim_id')[['target', 'prediction']].min()\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "81bcd5c9-8456-4ef7-a37c-ee4175c984e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105223050202600</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105223140222600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105223390228600</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105223620208100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115223140508700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ufe_claim_id  target  prediction\n",
       "0  105223050202600       1    1.000000\n",
       "1  105223140222600       0    0.999972\n",
       "2  105223390228600       1    1.000000\n",
       "3  105223620208100       0    1.000000\n",
       "4  115223140508700       1    0.999993"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = test_predictions.reset_index()\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f314aad-3325-4d84-8f1a-da9fa8ab7c12",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Deciding claim level tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "1f962681-33ba-408a-a01c-4521dcc4872c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresh = 0.9 # Classifier threshold\n",
    "\n",
    "def final_decision(x):\n",
    "    if x >= thresh: # If probabiliy of claim being clean is more than threshold, then we will say that claim is clean\n",
    "        return 1\n",
    "    if x < thresh:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "925024b6-b6e8-4ef8-8373-0f1a328f0131",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>final_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105223050202600</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105223140222600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105223390228600</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105223620208100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115223140508700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ufe_claim_id  target  prediction  final_prediction\n",
       "0  105223050202600       1    1.000000                 1\n",
       "1  105223140222600       0    0.999972                 1\n",
       "2  105223390228600       1    1.000000                 1\n",
       "3  105223620208100       0    1.000000                 1\n",
       "4  115223140508700       1    0.999993                 1"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying final_decision fucntion on 'prediction' column\n",
    "test_predictions['final_prediction'] = test_predictions['prediction'].apply(final_decision)\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5350bb-6b08-4389-b465-922f904c4162",
   "metadata": {},
   "source": [
    "### Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "bebb0822-1d13-4bf3-b726-41b1c425d920",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5664130935915168\n",
      "Precision (Positive Class): 0.6136248478019194\n",
      "Recall (Positive Class): 0.770660587928005\n",
      "F1 score (Positive Class): 0.6832355145380904\n",
      "Precision (Negative class): 0.41522365648688575\n",
      "Recall (Negative class): 0.25126401406902615\n",
      "F1 score (Negative class): 0.31307634716870875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5664130935915168,\n",
       " 0.6136248478019194,\n",
       " 0.770660587928005,\n",
       " 0.6832355145380904,\n",
       " 0.41522365648688575,\n",
       " 0.25126401406902615,\n",
       " 0.31307634716870875]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating final classification metrics\n",
    "calc_cf_metrics(list(test_predictions['target']), list(test_predictions['final_prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "963f55d5-910d-430e-8366-6d7ed0c5a725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1b9ffeb7-40f8-4921-8680-0f0ac03147c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173520, 4)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "a9a6b76e-e021-452d-ab9d-fcefd5086e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>final_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105223050202600</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105223140222600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105223390228600</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105223620208100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115223140508700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ufe_claim_id  target  prediction  final_prediction\n",
       "0  105223050202600       1    1.000000                 1\n",
       "1  105223140222600       0    0.999972                 1\n",
       "2  105223390228600       1    1.000000                 1\n",
       "3  105223620208100       0    1.000000                 1\n",
       "4  115223140508700       1    0.999993                 1"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "9548149b-a588-467a-937e-a7d9f8907b56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31696058091286305"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[test_predictions['prediction']<0.999].shape[0]/173520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "22bf5cf8-18f3-4be7-a33c-d06bf011e018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5711906408483172"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[test_predictions['prediction']==1].shape[0]/173520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "8e6d7fdb-9cb1-41aa-a8bd-9f93bd332664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.357757030889811"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[(test_predictions['prediction']==1) & (test_predictions['target']==1)].shape[0]/173520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a334b764-631c-4da6-9b9d-69d431de29e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21343360995850622"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[(test_predictions['prediction']==1) & (test_predictions['target']==0)].shape[0]/173520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "87834d7f-b9bc-4af2-878a-328d13c14311",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6067600276625172"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[(test_predictions['target']==1)].shape[0]/173520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a22229-ee33-45d9-92a3-349882933f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "191947b3-193f-4e28-b619-442571f0ae3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4288093591516828"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[test_predictions['prediction']<1].shape[0]/173520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "3f21c928-190b-4817-a377-7e2c593ba2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8092438911940987"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[test_predictions['prediction']>=0.5].shape[0]/173520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "382da135-fd48-4382-8a7b-443142959ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.hist(test_predictions['prediction'], bins = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f6b68a47-974d-4d73-b0c4-0008be43577b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173520, 4)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac790168-d24a-405d-b0c7-1ac45a3d4fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "50671b70-8be2-41c4-9584-50692c274183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    173520.000000\n",
       "mean          0.850422\n",
       "std           0.277594\n",
       "min           0.009201\n",
       "25%           0.955181\n",
       "50%           1.000000\n",
       "75%           1.000000\n",
       "max           1.000000\n",
       "Name: prediction, dtype: float64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions['prediction'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "41430fbe-1439-4221-aeef-f30ecc124c33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_predictions['prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "e074d3db-bebc-481d-8d40-ba2161d1afc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.415224</td>\n",
       "      <td>0.251264</td>\n",
       "      <td>0.313076</td>\n",
       "      <td>68235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613625</td>\n",
       "      <td>0.770661</td>\n",
       "      <td>0.683236</td>\n",
       "      <td>105285.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.566413</td>\n",
       "      <td>0.566413</td>\n",
       "      <td>0.566413</td>\n",
       "      <td>0.566413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.514424</td>\n",
       "      <td>0.510962</td>\n",
       "      <td>0.498156</td>\n",
       "      <td>173520.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.535606</td>\n",
       "      <td>0.566413</td>\n",
       "      <td>0.537674</td>\n",
       "      <td>173520.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score        support\n",
       "0              0.415224  0.251264  0.313076   68235.000000\n",
       "1              0.613625  0.770661  0.683236  105285.000000\n",
       "accuracy       0.566413  0.566413  0.566413       0.566413\n",
       "macro avg      0.514424  0.510962  0.498156  173520.000000\n",
       "weighted avg   0.535606  0.566413  0.537674  173520.000000"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(test_predictions['target'], test_predictions['final_prediction'], output_dict=True)\n",
    "cl = pd.DataFrame(report).transpose()\n",
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c2bfeee0-3cce-48e2-89ad-ce046fb017fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cl.iloc[:3,].to_csv('cl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "dd692b2a-0c52-4eed-84e0-9375fb33d08a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17145, 51090],\n",
       "       [24146, 81139]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_predictions['target'], test_predictions['final_prediction'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02766d8c-8e2d-4361-96dd-77d92c907e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9049fd2-381b-450a-a0a4-ef8e418347b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06325e46-9c79-4c43-b3d6-02d0765f56b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503be8ca-8c98-4f2e-9ce1-48d78b643f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d736d-f091-463d-85bd-b3c370a2a821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
